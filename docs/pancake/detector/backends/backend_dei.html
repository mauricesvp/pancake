<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pancake.detector.backends.backend_dei API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pancake.detector.backends.backend_dei</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from typing import Type, Tuple, List, Union
import math
import time
from functools import lru_cache

import cv2
import imutils
import numpy as np
import torch

from shapely.geometry import Polygon

from .backend import Backend
from ..detector import Detector
from pancake.logger import setup_logger

l = setup_logger(__name__)


# Helper functions


def locate(
    subframes: List[np.ndarray], x0: int, y0: int, x1: int, y1: int
) -&gt; List[int]:
    &#34;&#34;&#34;Return all subframe ids the obj is present in.

    This function assumes the coordinates are laid out like this:
    x0, y0 ------------
       |               |
       |               |
       |               |
        ------------ x1, y1

    Args:
        subframes (List[np.ndarray]): Subframes
        x0 (int): upper-left x-value
        y0 (int): upper-left y-value
        x1 (int): lower-right x-value
        y1 (int): lower-right y-value

    Returns:
        List[int]: List of subframe ids
    &#34;&#34;&#34;
    locations = []
    if x0 &lt;= 0 or y0 &lt;= 0:
        return locations
    for i, subframe in enumerate(subframes):
        tlx, tly, brx, bry = subframe[:4]
        # Check if any corner is in the subframe
        if x0 &gt;= tlx and x0 &lt;= brx and y0 &gt;= tly and y0 &lt;= bry:  # tl
            locations.append(i)
            continue
        if x1 &gt;= tlx and x1 &lt;= brx and y0 &gt;= tly and y0 &lt;= bry:  # tr
            locations.append(i)
            continue
        if x1 &gt;= tlx and x1 &lt;= brx and y1 &gt;= tly and y1 &lt;= bry:  # br
            locations.append(i)
            continue
        if y1 &gt;= tly and y1 &lt;= bry and x0 &gt;= tlx and x0 &lt;= brx:  # bl
            locations.append(i)
            continue
    return locations


def hconcat(source: Union[np.ndarray, List[np.ndarray]]) -&gt; np.ndarray:
    &#34;&#34;&#34;Concatenate images horizontally

    Args:
        source (Union[np.ndarray, List[np.ndarray]]): Image or list of images

    Returns:
        np.ndarray: Concatenated image
    &#34;&#34;&#34;
    if type(source) != list:
        source = [source]
    return cv2.hconcat(source)


def rev_rotate_bound(
    img: np.ndarray, result: Tuple[int, int, int, int, int, int], angle: int, side: int
) -&gt; Tuple[int, int, int, int, int, int]:
    &#34;&#34;&#34;Reverse bounded (non-cropping) image rotation

    Args:
        img (np.ndarray): Image to be rotated back
        result (Tuple[int, int, int, int, int, int]): Result tuple
        angle (int): Angle in degree measure
        side (int): Side width

    Returns:
        Tuple[int, int, int, int, int, int]: Result tuple with adjusted coordinates
    &#34;&#34;&#34;
    h, w, _ = img.shape
    center = (w // 2, h // 2)

    x0, y0, x1, y1, cf, cl = result
    # Reverse rotation using rotation matrix
    # Note that we will from this point on use all four corners!
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    ntl = M.dot([x0, y0, 1])
    nbr = M.dot([x1, y1, 1])
    ntr = M.dot([x1, y0, 1])
    nbl = M.dot([x0, y1, 1])

    points = [*ntl, *nbr, *ntr, *nbl]
    xmax = max(list(points[:8:2]))
    xmin = min(list(points[:8:2]))
    ymax = max(list(points[1:8:2]))
    ymin = min(list(points[1:8:2]))

    diff = (w - side) // 2

    tlx, tly = int(xmin - diff), int(ymin - diff)
    brx, bry = int(xmax - diff), int(ymax - diff)

    return (tlx, tly, brx, bry, cf, cl)


def rotate_cpu(image: np.ndarray, angle: int):
    &#34;&#34;&#34;Rotate image using CPU only

    Args:
        image (np.ndarray): Image to be rotated
        angle (float): Angle in degree measure

    Returns:
        np.ndarray: Rotated image
    &#34;&#34;&#34;
    # grab the dimensions of the image
    (h, w) = image.shape[:2]

    center = (w // 2, h // 2)

    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    return cv2.warpAffine(image, M, (w, h))


def rotate(image: np.ndarray, angle: int):
    &#34;&#34;&#34;Rotate image

    Args:
        image (np.ndarray): Image to be rotated
        angle (float): Angle in degree measure

    Returns:
        np.ndarray: Rotated image
    &#34;&#34;&#34;
    # grab the dimensions of the image
    (h, w) = image.shape[:2]

    center = (w // 2, h // 2)

    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    img_cuda = cv2.cuda_GpuMat()
    img_cuda.upload(image)

    rotated = cv2.cuda.warpAffine(img_cuda, M, (w, h))
    return rotated.download()


def rotate_bound_cpu(img: np.ndarray, angle: int) -&gt; np.ndarray:
    &#34;&#34;&#34;Rotate image bounded (non-cropping) using CPU only
    Source:
        github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.

    Args:
        img (np.ndarray): Image to be rotated
        angle (int): Angle in degree measure

    Returns:
        np.ndarray: Rotated image
    &#34;&#34;&#34;
    # grab the dimensions of the image and then determine the
    # center
    (h, w) = img.shape[:2]
    (cX, cY) = (w / 2, h / 2)

    # grab the rotation matrix (applying the negative of the
    # angle to rotate clockwise), then grab the sine and cosine
    # (i.e., the rotation components of the matrix)
    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])

    # compute the new bounding dimensions of the image
    nW = int((h * sin) + (w * cos))
    nH = int((h * cos) + (w * sin))

    # adjust the rotation matrix to take into account translation
    M[0, 2] += (nW / 2) - cX
    M[1, 2] += (nH / 2) - cY

    # perform the actual rotation and return the image
    return cv2.warpAffine(img, M, (nW, nH))


def rotate_bound(img: np.ndarray, angle: int) -&gt; np.ndarray:
    &#34;&#34;&#34;Rotate image bounded (non-cropping)
    Source:
        github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.

    Args:
        img (np.ndarray): Image to be rotated
        angle (int): Angle in degree measure

    Returns:
        np.ndarray: Rotated image
    &#34;&#34;&#34;
    # grab the dimensions of the image and then determine the
    # center
    (h, w) = img.shape[:2]
    (cX, cY) = (w / 2, h / 2)

    # grab the rotation matrix (applying the negative of the
    # angle to rotate clockwise), then grab the sine and cosine
    # (i.e., the rotation components of the matrix)
    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])

    # compute the new bounding dimensions of the image
    nW = int((h * sin) + (w * cos))
    nH = int((h * cos) + (w * sin))

    # adjust the rotation matrix to take into account translation
    M[0, 2] += (nW / 2) - cX
    M[1, 2] += (nH / 2) - cY

    # perform the actual rotation and return the image
    img_cuda = cv2.cuda_GpuMat()
    img_cuda.upload(img)

    res = cv2.cuda.warpAffine(img_cuda, M, (nW, nH))
    return res.download()


# Constants


@lru_cache(maxsize=None)
def f(x: int) -&gt; Tuple[int, int, int]:
    &#34;&#34;&#34;Returns y value, angle of rotation, width for x along centre strip

    Args:
        x (int): x-value

    Returns:
        Tuple[int, int, int]: y, angle, width
    &#34;&#34;&#34;
    if x &lt; 3840:
        y = int(-0.047 * x + 1100)
        angle = int(-0.015 * x + 57)
        w = int(0.216 * x + 172)
    elif x &lt; 7627:
        y = 920
        angle = 0
        w = 1000
    else:
        y = int(0.054 * x + 510.8)
        angle = 360 - int(0.013 * x - 100.3)
        w = int(-0.213 * x + 2626)
    return y, angle, w // 2


CONST = {
    &#34;START_X&#34;: 1280,
    &#34;END_X&#34;: 10515,
    &#34;STEPS&#34;: 21,  # Deprecated
    &#34;F&#34;: f,
}


class DEI(Backend):
    def __init__(
        self,
        detector: Type[Detector],
        roi: list = None,
        simple: bool = False,
        cache: bool = True,
        config: dict = {},
        *args,
        **kwargs,
    ) -&gt; None:
        &#34;&#34;&#34;DEI Backend
        For more information see https://github.com/mauricesvp/pancake/blob/main/docs/modules/backends.md .

        Args:
            detector (Type[Detector]): Detector instance which provides &#34;detect&#34; method
            roi (list, optional): Region of interest. Defaults to None.
            simple (bool, optional): Simple flag (will use less subframes). Defaults to False.
            cache (bool, optional): Cache flag. Defaults to True.
            config (dict, optional): Config options. Defaults to {}.
        &#34;&#34;&#34;
        self.detector = detector
        self.simple = simple

        if roi:
            self.roi = roi

        # Check if we can use cv2.cuda
        if cv2.cuda.getCudaEnabledDeviceCount() &gt; 0:
            self.rotate = rotate
            self.rotate_bound = rotate_bound
        else:
            self.rotate = rotate_cpu
            self.rotate_bound = rotate_bound_cpu
        # Note that rotate(_cpu) is not used as of now

        if config:
            self.simple = config[&#34;SIMPLE&#34;]

        self.cache = cache
        if cache:
            xyas = []
            x = CONST[&#34;START_X&#34;]
            y, angle, side = f(x)
            if self.simple:
                side = int(1.7 * side)
            xyas.append([x, y, angle, side])
            while x &lt; (CONST[&#34;END_X&#34;] + side):
                x = x + int(1.5 * side)
                y, angle, side = f(x)
                if self.simple:
                    side = int(1.7 * side)
                xyas.append([x, y, angle, side])
            self.xyas = xyas

    def rotate(self):
        pass

    def rotate_bound(self):
        pass

    def detect(
        self,
        source: List[np.ndarray],
    ) -&gt; Tuple[torch.Tensor, np.ndarray]:
        &#34;&#34;&#34;Detect objects on images by splitting and merging.

        Description:
            The tuples of the return list have 6 values:
            x0: x-value top left corner
            y0: y-value top left corner
            x1: x-value bottom right corner
            y1: y-value bottom right corner
            conf: Confidence of detection, float values between 0 and 1
            class id: Integer indicating the detected object type

            Modus operandi:
            * Stitch images
            * Divide image into subframes
            * Rotate subframes (without cropping, i.e. adding padding)
            * Detect objects on each subframe, saving classes and coordinates
            * Calculate coordinates on original frame
            * Filter and merge objects

        Args:
            source (List[np.ndarray]): List of images

        Returns:
            Tuple[torch.Tensor, np.ndarray]: Tuple with list of objects and their coordinates,
                             stitched panorama image

        &#34;&#34;&#34;
        assert all(x.shape == source[0].shape for x in source[1:])

        # Crop center (fix overlapping)
        h, w, _ = source[1].shape
        crop = round(0.007 * w)  # Width to remove left and right
        source[1] = source[1][0:h, crop : w - crop]

        img = hconcat(source)

        subframes = []
        if self.cache:
            for x, y, angle, side in self.xyas:
                tlx, tly, brx, bry = x - side, y - side, x + side, y + side
                # TODO: ROI
                # tly = max(500, tly)
                # bry = min(1350, bry)
                subframe = img[tly:bry, tlx:brx]
                rot = self.rotate_bound(subframe, angle)
                subframes.append((rot, tlx, tly, brx, bry, angle, side))
        else:
            x = CONST[&#34;START_X&#34;]
            y, angle, side = f(x)
            while x &lt; (CONST[&#34;END_X&#34;] + side):
                if self.simple:
                    side = int(1.7 * side)
                tlx, tly, brx, bry = x - side, y - side, x + side, y + side
                subframe = img[tly:bry, tlx:brx]
                rot = self.rotate_bound(subframe, angle)
                subframes.append((rot, tlx, tly, brx, bry, angle, side))
                x = x + int(1.5 * side)
                y, angle, side = f(x)

        imgs = [x[0] for x in subframes]

        result = self.detector.detect(imgs)

        objs = []
        for i, sub in enumerate(result):
            tlx, tly = subframes[i][1:3]
            for obj in sub:
                if subframes[i][5] != 0:  # angle
                    obj = rev_rotate_bound(
                        subframes[i][0], obj, subframes[i][5], subframes[i][6] * 2
                    )
                x0, y0, x1, y1, conf, classid = obj
                x0, y0, x1, y1, conf, classid = (
                    int(x0),
                    int(y0),
                    int(x1),
                    int(y1),
                    float(conf),
                    int(classid),
                )
                # top left
                rtlx, rtly = tlx + x0, tly + y0
                # bottom right
                rbrx, rbry = tlx + x1, tly + y1
                # save coords, conf, class
                objs.append((rtlx, rtly, rbrx, rbry, conf, classid, i))

        subcoords = [x[1:5] for x in subframes]
        results = self.merge(objs, subcoords)

        for i, x in enumerate(results):
            results[i] = torch.FloatTensor(list(x[:6]))

        results = torch.stack(results, dim=0) if results else torch.empty((0, 6))
        return results, img

    def merge(
        self, objs: List[Tuple], subframes: List[np.ndarray] = None, ratio: float = 0.8
    ) -&gt; List[Tuple]:
        &#34;&#34;&#34;Merge all detected objects of subframes.

        Description:
            Right now we use a single heuristic:
            If obj is embedded in another object with 80% or more of its area, discard it.

            TODO:
                This simple heuristic is by no means perfect yet.
                Especially when an object is right at the border of a subframe,
                the results can get inaccurate.
                Further filtering has to be done here
                Example:
                * If obj is at the border of a subframe, check if it is in the middle
                  of another one (and discard if so)

            The objects are expected to have the x,y coordinates of the top left and bottom right corner
            as the first four entries (x0, y0, x1, y1).

        Args:
            objs (List[Tuple]): List of objects
            subframes (List[np.ndarray]): List of subframes
            ratio (float): Embedded threshold

        Returns:
            List[Tuple]: List of filtered objects
        &#34;&#34;&#34;
        results = []
        while objs:
            obj = objs.pop(0)
            # First, check if obj is present in multiple subframes
            # If not, we can add it directly
            if subframes:
                locations = locate(subframes, *obj[:4])
                if len(locations) == 0:  # This should _never_ happen
                    l.warn(&#34;Object not located in any subframe!&#34;)
                    continue
                if len(locations) == 1:
                    results.append(obj)
                    continue
            # If yes, we need to do some filtering

            def intersect_area(a: tuple, b: tuple):
                dx = np.minimum(a[2], b[2]) - np.maximum(a[0], b[0])
                dy = np.minimum(a[3], b[3]) - np.maximum(a[1], b[1])
                if dx &gt;= 0 and dy &gt;= 0:
                    return np.maximum(0, dx * dy)
                return 0

            def embedded(obj: tuple, objs: list, results: list):
                # Check if object is embedded in other object (with &gt;80% of its area)
                x0, y0, x1, y1 = obj[:4]
                subframe = obj[6]
                rect1 = Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)])
                objarea = (x1 - x0) * (y1 - y0)
                skip = False
                for objtemp in objs + results:
                    if np.abs(objtemp[6] - subframe) &gt; 1:
                        continue
                    ia = intersect_area(obj[:4], objtemp[:4])
                    if ia &gt;= (ratio * objarea):
                        # Our current obj is embedded, skip
                        return True
                return False

            skip = embedded(obj, objs, results)

            if not skip:
                results.append(obj)

        return results</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pancake.detector.backends.backend_dei.f"><code class="name flex">
<span>def <span class="ident">f</span></span>(<span>x: int) ‑> Tuple[int, int, int]</span>
</code></dt>
<dd>
<div class="desc"><p>Returns y value, angle of rotation, width for x along centre strip</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>int</code></dt>
<dd>x-value</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[int, int, int]</code></dt>
<dd>y, angle, width</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@lru_cache(maxsize=None)
def f(x: int) -&gt; Tuple[int, int, int]:
    &#34;&#34;&#34;Returns y value, angle of rotation, width for x along centre strip

    Args:
        x (int): x-value

    Returns:
        Tuple[int, int, int]: y, angle, width
    &#34;&#34;&#34;
    if x &lt; 3840:
        y = int(-0.047 * x + 1100)
        angle = int(-0.015 * x + 57)
        w = int(0.216 * x + 172)
    elif x &lt; 7627:
        y = 920
        angle = 0
        w = 1000
    else:
        y = int(0.054 * x + 510.8)
        angle = 360 - int(0.013 * x - 100.3)
        w = int(-0.213 * x + 2626)
    return y, angle, w // 2</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.hconcat"><code class="name flex">
<span>def <span class="ident">hconcat</span></span>(<span>source: Union[numpy.ndarray, List[numpy.ndarray]]) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Concatenate images horizontally</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>source</code></strong> :&ensp;<code>Union[np.ndarray, List[np.ndarray]]</code></dt>
<dd>Image or list of images</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Concatenated image</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hconcat(source: Union[np.ndarray, List[np.ndarray]]) -&gt; np.ndarray:
    &#34;&#34;&#34;Concatenate images horizontally

    Args:
        source (Union[np.ndarray, List[np.ndarray]]): Image or list of images

    Returns:
        np.ndarray: Concatenated image
    &#34;&#34;&#34;
    if type(source) != list:
        source = [source]
    return cv2.hconcat(source)</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.locate"><code class="name flex">
<span>def <span class="ident">locate</span></span>(<span>subframes: List[numpy.ndarray], x0: int, y0: int, x1: int, y1: int) ‑> List[int]</span>
</code></dt>
<dd>
<div class="desc"><p>Return all subframe ids the obj is present in.</p>
<p>This function assumes the coordinates are laid out like this:
x0, y0 ------------
|
|
|
|
|
|
------------ x1, y1</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>subframes</code></strong> :&ensp;<code>List[np.ndarray]</code></dt>
<dd>Subframes</dd>
<dt><strong><code>x0</code></strong> :&ensp;<code>int</code></dt>
<dd>upper-left x-value</dd>
<dt><strong><code>y0</code></strong> :&ensp;<code>int</code></dt>
<dd>upper-left y-value</dd>
<dt><strong><code>x1</code></strong> :&ensp;<code>int</code></dt>
<dd>lower-right x-value</dd>
<dt><strong><code>y1</code></strong> :&ensp;<code>int</code></dt>
<dd>lower-right y-value</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[int]</code></dt>
<dd>List of subframe ids</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def locate(
    subframes: List[np.ndarray], x0: int, y0: int, x1: int, y1: int
) -&gt; List[int]:
    &#34;&#34;&#34;Return all subframe ids the obj is present in.

    This function assumes the coordinates are laid out like this:
    x0, y0 ------------
       |               |
       |               |
       |               |
        ------------ x1, y1

    Args:
        subframes (List[np.ndarray]): Subframes
        x0 (int): upper-left x-value
        y0 (int): upper-left y-value
        x1 (int): lower-right x-value
        y1 (int): lower-right y-value

    Returns:
        List[int]: List of subframe ids
    &#34;&#34;&#34;
    locations = []
    if x0 &lt;= 0 or y0 &lt;= 0:
        return locations
    for i, subframe in enumerate(subframes):
        tlx, tly, brx, bry = subframe[:4]
        # Check if any corner is in the subframe
        if x0 &gt;= tlx and x0 &lt;= brx and y0 &gt;= tly and y0 &lt;= bry:  # tl
            locations.append(i)
            continue
        if x1 &gt;= tlx and x1 &lt;= brx and y0 &gt;= tly and y0 &lt;= bry:  # tr
            locations.append(i)
            continue
        if x1 &gt;= tlx and x1 &lt;= brx and y1 &gt;= tly and y1 &lt;= bry:  # br
            locations.append(i)
            continue
        if y1 &gt;= tly and y1 &lt;= bry and x0 &gt;= tlx and x0 &lt;= brx:  # bl
            locations.append(i)
            continue
    return locations</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.rev_rotate_bound"><code class="name flex">
<span>def <span class="ident">rev_rotate_bound</span></span>(<span>img: numpy.ndarray, result: Tuple[int, int, int, int, int, int], angle: int, side: int) ‑> Tuple[int, int, int, int, int, int]</span>
</code></dt>
<dd>
<div class="desc"><p>Reverse bounded (non-cropping) image rotation</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>img</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image to be rotated back</dd>
<dt><strong><code>result</code></strong> :&ensp;<code>Tuple[int, int, int, int, int, int]</code></dt>
<dd>Result tuple</dd>
<dt><strong><code>angle</code></strong> :&ensp;<code>int</code></dt>
<dd>Angle in degree measure</dd>
<dt><strong><code>side</code></strong> :&ensp;<code>int</code></dt>
<dd>Side width</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[int, int, int, int, int, int]</code></dt>
<dd>Result tuple with adjusted coordinates</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rev_rotate_bound(
    img: np.ndarray, result: Tuple[int, int, int, int, int, int], angle: int, side: int
) -&gt; Tuple[int, int, int, int, int, int]:
    &#34;&#34;&#34;Reverse bounded (non-cropping) image rotation

    Args:
        img (np.ndarray): Image to be rotated back
        result (Tuple[int, int, int, int, int, int]): Result tuple
        angle (int): Angle in degree measure
        side (int): Side width

    Returns:
        Tuple[int, int, int, int, int, int]: Result tuple with adjusted coordinates
    &#34;&#34;&#34;
    h, w, _ = img.shape
    center = (w // 2, h // 2)

    x0, y0, x1, y1, cf, cl = result
    # Reverse rotation using rotation matrix
    # Note that we will from this point on use all four corners!
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    ntl = M.dot([x0, y0, 1])
    nbr = M.dot([x1, y1, 1])
    ntr = M.dot([x1, y0, 1])
    nbl = M.dot([x0, y1, 1])

    points = [*ntl, *nbr, *ntr, *nbl]
    xmax = max(list(points[:8:2]))
    xmin = min(list(points[:8:2]))
    ymax = max(list(points[1:8:2]))
    ymin = min(list(points[1:8:2]))

    diff = (w - side) // 2

    tlx, tly = int(xmin - diff), int(ymin - diff)
    brx, bry = int(xmax - diff), int(ymax - diff)

    return (tlx, tly, brx, bry, cf, cl)</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.rotate"><code class="name flex">
<span>def <span class="ident">rotate</span></span>(<span>image: numpy.ndarray, angle: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Rotate image</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image to be rotated</dd>
<dt><strong><code>angle</code></strong> :&ensp;<code>float</code></dt>
<dd>Angle in degree measure</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Rotated image</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate(image: np.ndarray, angle: int):
    &#34;&#34;&#34;Rotate image

    Args:
        image (np.ndarray): Image to be rotated
        angle (float): Angle in degree measure

    Returns:
        np.ndarray: Rotated image
    &#34;&#34;&#34;
    # grab the dimensions of the image
    (h, w) = image.shape[:2]

    center = (w // 2, h // 2)

    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    img_cuda = cv2.cuda_GpuMat()
    img_cuda.upload(image)

    rotated = cv2.cuda.warpAffine(img_cuda, M, (w, h))
    return rotated.download()</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.rotate_bound"><code class="name flex">
<span>def <span class="ident">rotate_bound</span></span>(<span>img: numpy.ndarray, angle: int) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Rotate image bounded (non-cropping)</p>
<h2 id="source">Source</h2>
<p>github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>img</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image to be rotated</dd>
<dt><strong><code>angle</code></strong> :&ensp;<code>int</code></dt>
<dd>Angle in degree measure</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Rotated image</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate_bound(img: np.ndarray, angle: int) -&gt; np.ndarray:
    &#34;&#34;&#34;Rotate image bounded (non-cropping)
    Source:
        github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.

    Args:
        img (np.ndarray): Image to be rotated
        angle (int): Angle in degree measure

    Returns:
        np.ndarray: Rotated image
    &#34;&#34;&#34;
    # grab the dimensions of the image and then determine the
    # center
    (h, w) = img.shape[:2]
    (cX, cY) = (w / 2, h / 2)

    # grab the rotation matrix (applying the negative of the
    # angle to rotate clockwise), then grab the sine and cosine
    # (i.e., the rotation components of the matrix)
    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])

    # compute the new bounding dimensions of the image
    nW = int((h * sin) + (w * cos))
    nH = int((h * cos) + (w * sin))

    # adjust the rotation matrix to take into account translation
    M[0, 2] += (nW / 2) - cX
    M[1, 2] += (nH / 2) - cY

    # perform the actual rotation and return the image
    img_cuda = cv2.cuda_GpuMat()
    img_cuda.upload(img)

    res = cv2.cuda.warpAffine(img_cuda, M, (nW, nH))
    return res.download()</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.rotate_bound_cpu"><code class="name flex">
<span>def <span class="ident">rotate_bound_cpu</span></span>(<span>img: numpy.ndarray, angle: int) ‑> numpy.ndarray</span>
</code></dt>
<dd>
<div class="desc"><p>Rotate image bounded (non-cropping) using CPU only</p>
<h2 id="source">Source</h2>
<p>github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>img</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image to be rotated</dd>
<dt><strong><code>angle</code></strong> :&ensp;<code>int</code></dt>
<dd>Angle in degree measure</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Rotated image</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate_bound_cpu(img: np.ndarray, angle: int) -&gt; np.ndarray:
    &#34;&#34;&#34;Rotate image bounded (non-cropping) using CPU only
    Source:
        github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.

    Args:
        img (np.ndarray): Image to be rotated
        angle (int): Angle in degree measure

    Returns:
        np.ndarray: Rotated image
    &#34;&#34;&#34;
    # grab the dimensions of the image and then determine the
    # center
    (h, w) = img.shape[:2]
    (cX, cY) = (w / 2, h / 2)

    # grab the rotation matrix (applying the negative of the
    # angle to rotate clockwise), then grab the sine and cosine
    # (i.e., the rotation components of the matrix)
    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])

    # compute the new bounding dimensions of the image
    nW = int((h * sin) + (w * cos))
    nH = int((h * cos) + (w * sin))

    # adjust the rotation matrix to take into account translation
    M[0, 2] += (nW / 2) - cX
    M[1, 2] += (nH / 2) - cY

    # perform the actual rotation and return the image
    return cv2.warpAffine(img, M, (nW, nH))</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.rotate_cpu"><code class="name flex">
<span>def <span class="ident">rotate_cpu</span></span>(<span>image: numpy.ndarray, angle: int)</span>
</code></dt>
<dd>
<div class="desc"><p>Rotate image using CPU only</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>image</code></strong> :&ensp;<code>np.ndarray</code></dt>
<dd>Image to be rotated</dd>
<dt><strong><code>angle</code></strong> :&ensp;<code>float</code></dt>
<dd>Angle in degree measure</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>np.ndarray</code></dt>
<dd>Rotated image</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate_cpu(image: np.ndarray, angle: int):
    &#34;&#34;&#34;Rotate image using CPU only

    Args:
        image (np.ndarray): Image to be rotated
        angle (float): Angle in degree measure

    Returns:
        np.ndarray: Rotated image
    &#34;&#34;&#34;
    # grab the dimensions of the image
    (h, w) = image.shape[:2]

    center = (w // 2, h // 2)

    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    return cv2.warpAffine(image, M, (w, h))</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pancake.detector.backends.backend_dei.DEI"><code class="flex name class">
<span>class <span class="ident">DEI</span></span>
<span>(</span><span>detector: Type[<a title="pancake.detector.detector.Detector" href="../detector.html#pancake.detector.detector.Detector">Detector</a>], roi: list = None, simple: bool = False, cache: bool = True, config: dict = {}, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>[<em>Abstract Class</em>] Base class of the Backends</p>
<p><strong>Base Class</strong>:
All Backends to be used within this framework have to inherit from this class.
The inheritance will automatically register every subclass into the registry thus
allowing for modular access to the backend strategies.
For more information see <a href="https://github.com/mauricesvp/pancake/blob/main/docs/modules/backends.md">https://github.com/mauricesvp/pancake/blob/main/docs/modules/backends.md</a> .</p>
<p>DEI Backend
For more information see <a href="https://github.com/mauricesvp/pancake/blob/main/docs/modules/backends.md">https://github.com/mauricesvp/pancake/blob/main/docs/modules/backends.md</a> .</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>detector</code></strong> :&ensp;<code>Type[Detector]</code></dt>
<dd>Detector instance which provides "detect" method</dd>
<dt><strong><code>roi</code></strong> :&ensp;<code>list</code>, optional</dt>
<dd>Region of interest. Defaults to None.</dd>
<dt><strong><code>simple</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Simple flag (will use less subframes). Defaults to False.</dd>
<dt><strong><code>cache</code></strong> :&ensp;<code>bool</code>, optional</dt>
<dd>Cache flag. Defaults to True.</dd>
<dt><strong><code>config</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>Config options. Defaults to {}.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DEI(Backend):
    def __init__(
        self,
        detector: Type[Detector],
        roi: list = None,
        simple: bool = False,
        cache: bool = True,
        config: dict = {},
        *args,
        **kwargs,
    ) -&gt; None:
        &#34;&#34;&#34;DEI Backend
        For more information see https://github.com/mauricesvp/pancake/blob/main/docs/modules/backends.md .

        Args:
            detector (Type[Detector]): Detector instance which provides &#34;detect&#34; method
            roi (list, optional): Region of interest. Defaults to None.
            simple (bool, optional): Simple flag (will use less subframes). Defaults to False.
            cache (bool, optional): Cache flag. Defaults to True.
            config (dict, optional): Config options. Defaults to {}.
        &#34;&#34;&#34;
        self.detector = detector
        self.simple = simple

        if roi:
            self.roi = roi

        # Check if we can use cv2.cuda
        if cv2.cuda.getCudaEnabledDeviceCount() &gt; 0:
            self.rotate = rotate
            self.rotate_bound = rotate_bound
        else:
            self.rotate = rotate_cpu
            self.rotate_bound = rotate_bound_cpu
        # Note that rotate(_cpu) is not used as of now

        if config:
            self.simple = config[&#34;SIMPLE&#34;]

        self.cache = cache
        if cache:
            xyas = []
            x = CONST[&#34;START_X&#34;]
            y, angle, side = f(x)
            if self.simple:
                side = int(1.7 * side)
            xyas.append([x, y, angle, side])
            while x &lt; (CONST[&#34;END_X&#34;] + side):
                x = x + int(1.5 * side)
                y, angle, side = f(x)
                if self.simple:
                    side = int(1.7 * side)
                xyas.append([x, y, angle, side])
            self.xyas = xyas

    def rotate(self):
        pass

    def rotate_bound(self):
        pass

    def detect(
        self,
        source: List[np.ndarray],
    ) -&gt; Tuple[torch.Tensor, np.ndarray]:
        &#34;&#34;&#34;Detect objects on images by splitting and merging.

        Description:
            The tuples of the return list have 6 values:
            x0: x-value top left corner
            y0: y-value top left corner
            x1: x-value bottom right corner
            y1: y-value bottom right corner
            conf: Confidence of detection, float values between 0 and 1
            class id: Integer indicating the detected object type

            Modus operandi:
            * Stitch images
            * Divide image into subframes
            * Rotate subframes (without cropping, i.e. adding padding)
            * Detect objects on each subframe, saving classes and coordinates
            * Calculate coordinates on original frame
            * Filter and merge objects

        Args:
            source (List[np.ndarray]): List of images

        Returns:
            Tuple[torch.Tensor, np.ndarray]: Tuple with list of objects and their coordinates,
                             stitched panorama image

        &#34;&#34;&#34;
        assert all(x.shape == source[0].shape for x in source[1:])

        # Crop center (fix overlapping)
        h, w, _ = source[1].shape
        crop = round(0.007 * w)  # Width to remove left and right
        source[1] = source[1][0:h, crop : w - crop]

        img = hconcat(source)

        subframes = []
        if self.cache:
            for x, y, angle, side in self.xyas:
                tlx, tly, brx, bry = x - side, y - side, x + side, y + side
                # TODO: ROI
                # tly = max(500, tly)
                # bry = min(1350, bry)
                subframe = img[tly:bry, tlx:brx]
                rot = self.rotate_bound(subframe, angle)
                subframes.append((rot, tlx, tly, brx, bry, angle, side))
        else:
            x = CONST[&#34;START_X&#34;]
            y, angle, side = f(x)
            while x &lt; (CONST[&#34;END_X&#34;] + side):
                if self.simple:
                    side = int(1.7 * side)
                tlx, tly, brx, bry = x - side, y - side, x + side, y + side
                subframe = img[tly:bry, tlx:brx]
                rot = self.rotate_bound(subframe, angle)
                subframes.append((rot, tlx, tly, brx, bry, angle, side))
                x = x + int(1.5 * side)
                y, angle, side = f(x)

        imgs = [x[0] for x in subframes]

        result = self.detector.detect(imgs)

        objs = []
        for i, sub in enumerate(result):
            tlx, tly = subframes[i][1:3]
            for obj in sub:
                if subframes[i][5] != 0:  # angle
                    obj = rev_rotate_bound(
                        subframes[i][0], obj, subframes[i][5], subframes[i][6] * 2
                    )
                x0, y0, x1, y1, conf, classid = obj
                x0, y0, x1, y1, conf, classid = (
                    int(x0),
                    int(y0),
                    int(x1),
                    int(y1),
                    float(conf),
                    int(classid),
                )
                # top left
                rtlx, rtly = tlx + x0, tly + y0
                # bottom right
                rbrx, rbry = tlx + x1, tly + y1
                # save coords, conf, class
                objs.append((rtlx, rtly, rbrx, rbry, conf, classid, i))

        subcoords = [x[1:5] for x in subframes]
        results = self.merge(objs, subcoords)

        for i, x in enumerate(results):
            results[i] = torch.FloatTensor(list(x[:6]))

        results = torch.stack(results, dim=0) if results else torch.empty((0, 6))
        return results, img

    def merge(
        self, objs: List[Tuple], subframes: List[np.ndarray] = None, ratio: float = 0.8
    ) -&gt; List[Tuple]:
        &#34;&#34;&#34;Merge all detected objects of subframes.

        Description:
            Right now we use a single heuristic:
            If obj is embedded in another object with 80% or more of its area, discard it.

            TODO:
                This simple heuristic is by no means perfect yet.
                Especially when an object is right at the border of a subframe,
                the results can get inaccurate.
                Further filtering has to be done here
                Example:
                * If obj is at the border of a subframe, check if it is in the middle
                  of another one (and discard if so)

            The objects are expected to have the x,y coordinates of the top left and bottom right corner
            as the first four entries (x0, y0, x1, y1).

        Args:
            objs (List[Tuple]): List of objects
            subframes (List[np.ndarray]): List of subframes
            ratio (float): Embedded threshold

        Returns:
            List[Tuple]: List of filtered objects
        &#34;&#34;&#34;
        results = []
        while objs:
            obj = objs.pop(0)
            # First, check if obj is present in multiple subframes
            # If not, we can add it directly
            if subframes:
                locations = locate(subframes, *obj[:4])
                if len(locations) == 0:  # This should _never_ happen
                    l.warn(&#34;Object not located in any subframe!&#34;)
                    continue
                if len(locations) == 1:
                    results.append(obj)
                    continue
            # If yes, we need to do some filtering

            def intersect_area(a: tuple, b: tuple):
                dx = np.minimum(a[2], b[2]) - np.maximum(a[0], b[0])
                dy = np.minimum(a[3], b[3]) - np.maximum(a[1], b[1])
                if dx &gt;= 0 and dy &gt;= 0:
                    return np.maximum(0, dx * dy)
                return 0

            def embedded(obj: tuple, objs: list, results: list):
                # Check if object is embedded in other object (with &gt;80% of its area)
                x0, y0, x1, y1 = obj[:4]
                subframe = obj[6]
                rect1 = Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)])
                objarea = (x1 - x0) * (y1 - y0)
                skip = False
                for objtemp in objs + results:
                    if np.abs(objtemp[6] - subframe) &gt; 1:
                        continue
                    ia = intersect_area(obj[:4], objtemp[:4])
                    if ia &gt;= (ratio * objarea):
                        # Our current obj is embedded, skip
                        return True
                return False

            skip = embedded(obj, objs, results)

            if not skip:
                results.append(obj)

        return results</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pancake.detector.backends.backend.Backend" href="backend.html#pancake.detector.backends.backend.Backend">Backend</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pancake.detector.backends.backend_dei.DEI.detect"><code class="name flex">
<span>def <span class="ident">detect</span></span>(<span>self, source: List[numpy.ndarray]) ‑> Tuple[torch.Tensor, numpy.ndarray]</span>
</code></dt>
<dd>
<div class="desc"><p>Detect objects on images by splitting and merging.</p>
<h2 id="description">Description</h2>
<p>The tuples of the return list have 6 values:
x0: x-value top left corner
y0: y-value top left corner
x1: x-value bottom right corner
y1: y-value bottom right corner
conf: Confidence of detection, float values between 0 and 1
class id: Integer indicating the detected object type</p>
<p>Modus operandi:
* Stitch images
* Divide image into subframes
* Rotate subframes (without cropping, i.e. adding padding)
* Detect objects on each subframe, saving classes and coordinates
* Calculate coordinates on original frame
* Filter and merge objects</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>source</code></strong> :&ensp;<code>List[np.ndarray]</code></dt>
<dd>List of images</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>Tuple[torch.Tensor, np.ndarray]</code></dt>
<dd>Tuple with list of objects and their coordinates,
stitched panorama image</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def detect(
    self,
    source: List[np.ndarray],
) -&gt; Tuple[torch.Tensor, np.ndarray]:
    &#34;&#34;&#34;Detect objects on images by splitting and merging.

    Description:
        The tuples of the return list have 6 values:
        x0: x-value top left corner
        y0: y-value top left corner
        x1: x-value bottom right corner
        y1: y-value bottom right corner
        conf: Confidence of detection, float values between 0 and 1
        class id: Integer indicating the detected object type

        Modus operandi:
        * Stitch images
        * Divide image into subframes
        * Rotate subframes (without cropping, i.e. adding padding)
        * Detect objects on each subframe, saving classes and coordinates
        * Calculate coordinates on original frame
        * Filter and merge objects

    Args:
        source (List[np.ndarray]): List of images

    Returns:
        Tuple[torch.Tensor, np.ndarray]: Tuple with list of objects and their coordinates,
                         stitched panorama image

    &#34;&#34;&#34;
    assert all(x.shape == source[0].shape for x in source[1:])

    # Crop center (fix overlapping)
    h, w, _ = source[1].shape
    crop = round(0.007 * w)  # Width to remove left and right
    source[1] = source[1][0:h, crop : w - crop]

    img = hconcat(source)

    subframes = []
    if self.cache:
        for x, y, angle, side in self.xyas:
            tlx, tly, brx, bry = x - side, y - side, x + side, y + side
            # TODO: ROI
            # tly = max(500, tly)
            # bry = min(1350, bry)
            subframe = img[tly:bry, tlx:brx]
            rot = self.rotate_bound(subframe, angle)
            subframes.append((rot, tlx, tly, brx, bry, angle, side))
    else:
        x = CONST[&#34;START_X&#34;]
        y, angle, side = f(x)
        while x &lt; (CONST[&#34;END_X&#34;] + side):
            if self.simple:
                side = int(1.7 * side)
            tlx, tly, brx, bry = x - side, y - side, x + side, y + side
            subframe = img[tly:bry, tlx:brx]
            rot = self.rotate_bound(subframe, angle)
            subframes.append((rot, tlx, tly, brx, bry, angle, side))
            x = x + int(1.5 * side)
            y, angle, side = f(x)

    imgs = [x[0] for x in subframes]

    result = self.detector.detect(imgs)

    objs = []
    for i, sub in enumerate(result):
        tlx, tly = subframes[i][1:3]
        for obj in sub:
            if subframes[i][5] != 0:  # angle
                obj = rev_rotate_bound(
                    subframes[i][0], obj, subframes[i][5], subframes[i][6] * 2
                )
            x0, y0, x1, y1, conf, classid = obj
            x0, y0, x1, y1, conf, classid = (
                int(x0),
                int(y0),
                int(x1),
                int(y1),
                float(conf),
                int(classid),
            )
            # top left
            rtlx, rtly = tlx + x0, tly + y0
            # bottom right
            rbrx, rbry = tlx + x1, tly + y1
            # save coords, conf, class
            objs.append((rtlx, rtly, rbrx, rbry, conf, classid, i))

    subcoords = [x[1:5] for x in subframes]
    results = self.merge(objs, subcoords)

    for i, x in enumerate(results):
        results[i] = torch.FloatTensor(list(x[:6]))

    results = torch.stack(results, dim=0) if results else torch.empty((0, 6))
    return results, img</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.DEI.merge"><code class="name flex">
<span>def <span class="ident">merge</span></span>(<span>self, objs: List[Tuple], subframes: List[numpy.ndarray] = None, ratio: float = 0.8) ‑> List[Tuple]</span>
</code></dt>
<dd>
<div class="desc"><p>Merge all detected objects of subframes.</p>
<h2 id="description">Description</h2>
<p>Right now we use a single heuristic:
If obj is embedded in another object with 80% or more of its area, discard it.</p>
<p>TODO:
This simple heuristic is by no means perfect yet.
Especially when an object is right at the border of a subframe,
the results can get inaccurate.
Further filtering has to be done here
Example:
* If obj is at the border of a subframe, check if it is in the middle
of another one (and discard if so)</p>
<p>The objects are expected to have the x,y coordinates of the top left and bottom right corner
as the first four entries (x0, y0, x1, y1).</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>objs</code></strong> :&ensp;<code>List[Tuple]</code></dt>
<dd>List of objects</dd>
<dt><strong><code>subframes</code></strong> :&ensp;<code>List[np.ndarray]</code></dt>
<dd>List of subframes</dd>
<dt><strong><code>ratio</code></strong> :&ensp;<code>float</code></dt>
<dd>Embedded threshold</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[Tuple]</code></dt>
<dd>List of filtered objects</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge(
    self, objs: List[Tuple], subframes: List[np.ndarray] = None, ratio: float = 0.8
) -&gt; List[Tuple]:
    &#34;&#34;&#34;Merge all detected objects of subframes.

    Description:
        Right now we use a single heuristic:
        If obj is embedded in another object with 80% or more of its area, discard it.

        TODO:
            This simple heuristic is by no means perfect yet.
            Especially when an object is right at the border of a subframe,
            the results can get inaccurate.
            Further filtering has to be done here
            Example:
            * If obj is at the border of a subframe, check if it is in the middle
              of another one (and discard if so)

        The objects are expected to have the x,y coordinates of the top left and bottom right corner
        as the first four entries (x0, y0, x1, y1).

    Args:
        objs (List[Tuple]): List of objects
        subframes (List[np.ndarray]): List of subframes
        ratio (float): Embedded threshold

    Returns:
        List[Tuple]: List of filtered objects
    &#34;&#34;&#34;
    results = []
    while objs:
        obj = objs.pop(0)
        # First, check if obj is present in multiple subframes
        # If not, we can add it directly
        if subframes:
            locations = locate(subframes, *obj[:4])
            if len(locations) == 0:  # This should _never_ happen
                l.warn(&#34;Object not located in any subframe!&#34;)
                continue
            if len(locations) == 1:
                results.append(obj)
                continue
        # If yes, we need to do some filtering

        def intersect_area(a: tuple, b: tuple):
            dx = np.minimum(a[2], b[2]) - np.maximum(a[0], b[0])
            dy = np.minimum(a[3], b[3]) - np.maximum(a[1], b[1])
            if dx &gt;= 0 and dy &gt;= 0:
                return np.maximum(0, dx * dy)
            return 0

        def embedded(obj: tuple, objs: list, results: list):
            # Check if object is embedded in other object (with &gt;80% of its area)
            x0, y0, x1, y1 = obj[:4]
            subframe = obj[6]
            rect1 = Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)])
            objarea = (x1 - x0) * (y1 - y0)
            skip = False
            for objtemp in objs + results:
                if np.abs(objtemp[6] - subframe) &gt; 1:
                    continue
                ia = intersect_area(obj[:4], objtemp[:4])
                if ia &gt;= (ratio * objarea):
                    # Our current obj is embedded, skip
                    return True
            return False

        skip = embedded(obj, objs, results)

        if not skip:
            results.append(obj)

    return results</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.DEI.rotate"><code class="name flex">
<span>def <span class="ident">rotate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate(self):
    pass</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.DEI.rotate_bound"><code class="name flex">
<span>def <span class="ident">rotate_bound</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate_bound(self):
    pass</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="pancake.detector.backends.backend.Backend" href="backend.html#pancake.detector.backends.backend.Backend">Backend</a></b></code>:
<ul class="hlist">
<li><code><a title="pancake.detector.backends.backend.Backend.get_subclasses" href="backend.html#pancake.detector.backends.backend.Backend.get_subclasses">get_subclasses</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pancake.detector.backends" href="index.html">pancake.detector.backends</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="pancake.detector.backends.backend_dei.f" href="#pancake.detector.backends.backend_dei.f">f</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.hconcat" href="#pancake.detector.backends.backend_dei.hconcat">hconcat</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.locate" href="#pancake.detector.backends.backend_dei.locate">locate</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.rev_rotate_bound" href="#pancake.detector.backends.backend_dei.rev_rotate_bound">rev_rotate_bound</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.rotate" href="#pancake.detector.backends.backend_dei.rotate">rotate</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.rotate_bound" href="#pancake.detector.backends.backend_dei.rotate_bound">rotate_bound</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.rotate_bound_cpu" href="#pancake.detector.backends.backend_dei.rotate_bound_cpu">rotate_bound_cpu</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.rotate_cpu" href="#pancake.detector.backends.backend_dei.rotate_cpu">rotate_cpu</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pancake.detector.backends.backend_dei.DEI" href="#pancake.detector.backends.backend_dei.DEI">DEI</a></code></h4>
<ul class="">
<li><code><a title="pancake.detector.backends.backend_dei.DEI.detect" href="#pancake.detector.backends.backend_dei.DEI.detect">detect</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.DEI.merge" href="#pancake.detector.backends.backend_dei.DEI.merge">merge</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.DEI.rotate" href="#pancake.detector.backends.backend_dei.DEI.rotate">rotate</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.DEI.rotate_bound" href="#pancake.detector.backends.backend_dei.DEI.rotate_bound">rotate_bound</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>