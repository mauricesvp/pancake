<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pancake.detector.backends.backend_dei API documentation</title>
<meta name="description" content="Divide Et Impera (Divide And Conquer) Backend
TODOs:
* Apply ROIs
* Filter by object class id
(this could be done in the detector as â€¦" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pancake.detector.backends.backend_dei</code></h1>
</header>
<section id="section-intro">
<h2 id="divide-et-impera-divide-and-conquer-backend">Divide Et Impera (Divide And Conquer) Backend</h2>
<h2 id="todos">Todos</h2>
<ul>
<li>Apply ROIs</li>
<li>Filter by object class id
(this could be done in the detector as well)</li>
</ul>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34;
Divide Et Impera (Divide And Conquer) Backend
----------------
TODOs:
    * Apply ROIs
    * Filter by object class id
      (this could be done in the detector as well)

&#34;&#34;&#34;
import math
import time
from functools import lru_cache

import cv2
import imutils
import numpy as np
import torch

from shapely.geometry import Polygon

from .backend import Backend
from pancake.logger import setup_logger

l = setup_logger(__name__)


# Helper functions


def locate(subframes, x0, y0, x1, y1) -&gt; list:
    &#34;&#34;&#34;Return all subframe ids the obj is present in.

    This function assumes the coordinates are laid out like this:
    x0, y0 ------------
       |               |
       |               |
       |               |
        ------------ x1, y1
    &#34;&#34;&#34;
    locations = []
    if not (x0 &gt; 0 and y0 &gt; 0):
        return locations
    for i, subframe in enumerate(subframes):
        tlx, tly, brx, bry = subframe[:4]
        # Check if any corner is in the subframe
        if x0 &gt;= tlx and x0 &lt;= brx and y0 &gt;= tly and y0 &lt;= bry:  # tl
            locations.append(i)
            continue
        if x1 &gt;= tlx and x1 &lt;= brx and y0 &gt;= tly and y0 &lt;= bry:  # tr
            locations.append(i)
            continue
        if x1 &gt;= tlx and x1 &lt;= brx and y1 &gt;= tly and y1 &lt;= bry:  # br
            locations.append(i)
            continue
        if y1 &gt;= tly and y1 &lt;= bry and x0 &gt;= tlx and x0 &lt;= brx:  # bl
            locations.append(i)
            continue
    return locations


def hconcat(source):
    &#34;&#34;&#34;Concat images horizontally&#34;&#34;&#34;
    if type(source) != list:
        source = [source]
    return cv2.hconcat(source)


def rev_rotate_bound(img: np.ndarray, result: tuple, angle: int, side: int) -&gt; list:
    h, w, _ = img.shape
    center = (w // 2, h // 2)

    x0, y0, x1, y1, cf, cl = result
    # Reverse rotation using rotation matrix
    # Note that we will from this point on use all four corners!
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    ntl = M.dot([x0, y0, 1])
    nbr = M.dot([x1, y1, 1])
    ntr = M.dot([x1, y0, 1])
    nbl = M.dot([x0, y1, 1])

    points = [*ntl, *nbr, *ntr, *nbl]
    xmax = max(list(points[:8:2]))
    xmin = min(list(points[:8:2]))
    ymax = max(list(points[1:8:2]))
    ymin = min(list(points[1:8:2]))

    diff = (w - side) // 2

    tlx, tly = int(xmin - diff), int(ymin - diff)
    brx, bry = int(xmax - diff), int(ymax - diff)

    return (tlx, tly, brx, bry, cf, cl)


def rotate_cpu(image, angle):
    # grab the dimensions of the image
    (h, w) = image.shape[:2]

    center = (w // 2, h // 2)

    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h))

    return rotated


def rotate(image, angle):
    # grab the dimensions of the image
    (h, w) = image.shape[:2]

    center = (w // 2, h // 2)

    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    img_cuda = cv2.cuda_GpuMat()
    img_cuda.upload(image)

    rotated = cv2.cuda.warpAffine(img_cuda, M, (w, h))
    return rotated.download()


def rotate_bound_cpu(img: np.ndarray, angle: int):
    &#34;&#34;&#34;
    Source:
        github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.
    &#34;&#34;&#34;
    # grab the dimensions of the image and then determine the
    # center
    (h, w) = img.shape[:2]
    (cX, cY) = (w / 2, h / 2)

    # grab the rotation matrix (applying the negative of the
    # angle to rotate clockwise), then grab the sine and cosine
    # (i.e., the rotation components of the matrix)
    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])

    # compute the new bounding dimensions of the image
    nW = int((h * sin) + (w * cos))
    nH = int((h * cos) + (w * sin))

    # adjust the rotation matrix to take into account translation
    M[0, 2] += (nW / 2) - cX
    M[1, 2] += (nH / 2) - cY

    # perform the actual rotation and return the image
    return cv2.warpAffine(img, M, (nW, nH))


def rotate_bound(img: np.ndarray, angle: int):
    &#34;&#34;&#34;
    Source:
        github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.
    &#34;&#34;&#34;
    # grab the dimensions of the image and then determine the
    # center
    (h, w) = img.shape[:2]
    (cX, cY) = (w / 2, h / 2)

    # grab the rotation matrix (applying the negative of the
    # angle to rotate clockwise), then grab the sine and cosine
    # (i.e., the rotation components of the matrix)
    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])

    # compute the new bounding dimensions of the image
    nW = int((h * sin) + (w * cos))
    nH = int((h * cos) + (w * sin))

    # adjust the rotation matrix to take into account translation
    M[0, 2] += (nW / 2) - cX
    M[1, 2] += (nH / 2) - cY

    # perform the actual rotation and return the image
    img_cuda = cv2.cuda_GpuMat()
    img_cuda.upload(img)

    res = cv2.cuda.warpAffine(img_cuda, M, (nW, nH))
    return res.download()


# Constants


@lru_cache(maxsize=None)
def f(x: int) -&gt; (int, int):
    &#34;&#34;&#34;Returns y value, angle of rotation, width for x along centre strip.&#34;&#34;&#34;
    if x &lt; 3840:
        y = int(-0.047 * x + 1100)
        angle = int(-0.015 * x + 57)
        w = int(0.216 * x + 172)
    elif x &lt; 7627:
        y = 920
        angle = 0
        w = 1000
    else:
        y = int(0.054 * x + 510.8)
        angle = 360 - int(0.013 * x - 100.3)
        w = int(-0.213 * x + 2626)
    return y, angle, w // 2


CONST = {
    &#34;START_X&#34;: 1280,
    &#34;END_X&#34;: 10515,
    &#34;STEPS&#34;: 21,  # Deprecated
    &#34;F&#34;: f,
}


class DEI(Backend):
    def __init__(
        self,
        detector,
        roi: list = None,
        simple: bool = False,
        cache: bool = True,
        config: dict = {},
        *args,
        **kwargs,
    ) -&gt; None:
        &#34;&#34;&#34;

        :param detector: Detector which provides &#39;detect&#39; method,
                         which can take one or multiple images.
        :param simple (bool): Use less subframes

        &#34;&#34;&#34;
        self.detector = detector
        self.simple = simple

        if roi:
            self.roi = roi

        # Check if we can use cv2.cuda
        if cv2.cuda.getCudaEnabledDeviceCount() &gt; 0:
            self.rotate = rotate
            self.rotate_bound = rotate_bound
        else:
            self.rotate = rotate_cpu
            self.rotate_bound = rotate_bound_cpu
        # Note that rotate(_cpu) is not used as of now

        if config:
            self.simple = config[&#34;SIMPLE&#34;]

        self.cache = cache
        if cache:
            xyas = []
            x = CONST[&#34;START_X&#34;]
            y, angle, side = f(x)
            if self.simple:
                side = int(1.7 * side)
            xyas.append([x, y, angle, side])
            while x &lt; (CONST[&#34;END_X&#34;] + side):
                x = x + int(1.5 * side)
                y, angle, side = f(x)
                if self.simple:
                    side = int(1.7 * side)
                xyas.append([x, y, angle, side])
            self.xyas = xyas

    def rotate(self):
        pass

    def rotate_bound(self):
        pass

    def detect(
        self,
        source,
    ) -&gt; (list, np.ndarray):
        &#34;&#34;&#34;
        Detect objects on image by splitting and merging.

        :param source: filename or np.ndarray

        :return (objs, img): list of tuples with objects and their coordinates,
                             stitched panorama image

        The tuples of the return list have 6 values:
        x0: x-value top left corner
        y0: y-value top left corner
        x1: x-value bottom right corner
        y1: y-value bottom right corner
        conf: Confidence of detection, values between 0 and 1
        class id: Integer indicating the detected object type

        Modus operandi:
        * Stitch images
        * Divide image into subframes
        * Rotate subframes (without cropping, i.e. adding padding)
        * Detect objects on each subframe, saving classes and coordinates
        * Calculate coordinates on original frame
        * Filter and merge objects
        &#34;&#34;&#34;
        assert all(x.shape == source[0].shape for x in source[1:])

        # Crop center (fix overlapping)
        h, w, _ = source[1].shape
        crop = round(0.007 * w)  # Width to remove left and right
        source[1] = source[1][0:h, crop : w - crop]

        img = hconcat(source)

        if self.cache:
            subframes = []
            for x, y, angle, side in self.xyas:
                tlx, tly, brx, bry = x - side, y - side, x + side, y + side
                # TODO: ROI
                # tly = max(500, tly)
                # bry = min(1350, bry)
                subframe = img[tly:bry, tlx:brx]
                rot = self.rotate_bound(subframe, angle)
                subframes.append((rot, tlx, tly, brx, bry, angle, side))
        else:
            x = CONST[&#34;START_X&#34;]
            y, angle, side = f(x)
            subframes = []
            while x &lt; (CONST[&#34;END_X&#34;] + side):
                if self.simple:
                    side = int(1.7 * side)
                tlx, tly, brx, bry = x - side, y - side, x + side, y + side
                subframe = img[tly:bry, tlx:brx]
                rot = self.rotate_bound(subframe, angle)
                subframes.append((rot, tlx, tly, brx, bry, angle, side))
                x = x + int(1.5 * side)
                y, angle, side = f(x)

        imgs = [x[0] for x in subframes]

        result = self.detector.detect(imgs)

        objs = []
        for i, sub in enumerate(result):
            tlx, tly = subframes[i][1:3]
            for obj in sub:
                if subframes[i][5] != 0:  # angle
                    obj = rev_rotate_bound(
                        subframes[i][0], obj, subframes[i][5], subframes[i][6] * 2
                    )
                x0, y0, x1, y1, conf, classid = obj
                x0, y0, x1, y1, conf, classid = (
                    int(x0),
                    int(y0),
                    int(x1),
                    int(y1),
                    float(conf),
                    int(classid),
                )
                # top left
                rtlx, rtly = tlx + x0, tly + y0
                # bottom right
                rbrx, rbry = tlx + x1, tly + y1
                # save coords, conf, class
                objs.append((rtlx, rtly, rbrx, rbry, conf, classid, i))

        subcoords = [x[1:5] for x in subframes]
        results = self.merge(objs, subcoords)

        if False:  # Debugging
            for obj in results:
                x0, y0, x1, y1, *_ = obj
                cv2.rectangle(img, (x0, y0), (x1, y1), (255, 0, 0), 2)
            for subf in subframes:
                x0, y0, x1, y1 = subf[1:5]
                cv2.rectangle(img, (x0, y0), (x1, y1), (255, 0, 0), 2)
            cv2.imwrite(&#34;stuff.jpg&#34;, img)

        for i, x in enumerate(results):
            results[i] = torch.FloatTensor(list(x[:6]))

        results = torch.stack(results, dim=0) if results else torch.empty((0, 6))
        return results, img

    def merge(self, objs: list, subframes: list = None, ratio=0.8) -&gt; list:
        &#34;&#34;&#34;
        Merge all detected objects of subframes.

        Right now we use a single heuristic:
        If obj is embedded in another object with 90% or more of its area, discard it.

        TODO:
            This simple heuristic is by no means perfect yet.
            Especially when an object is right at the border of a subframe,
            the results can get inaccurate.
            Further filtering has to be done here
            Example:
            * If obj is at the border of a subframe, check if it is in the middle
              of another one (and discard if so)
        &#34;&#34;&#34;
        results = []
        while objs:
            obj = objs.pop(0)
            # First, check if obj is present in multiple subframes
            # If not, we can add it directly
            if subframes:
                locations = locate(subframes, *obj[:4])
                if len(locations) == 0:  # This should _never_ happen
                    l.warn(&#34;Object not located in any subframe!&#34;)
                    continue
                if len(locations) == 1:
                    results.append(obj)
                    continue
            # If yes, we need to do some filtering

            def intersect_area(a: tuple, b: tuple):
                dx = np.minimum(a[2], b[2]) - np.maximum(a[0], b[0])
                dy = np.minimum(a[3], b[3]) - np.maximum(a[1], b[1])
                if dx &gt;= 0 and dy &gt;= 0:
                    return np.maximum(0, dx * dy)
                return 0

            def embedded(obj: tuple, objs: list, results: list):
                # Check if object is embedded in other object (with &gt;80% of its area)
                x0, y0, x1, y1 = obj[:4]
                subframe = obj[6]
                rect1 = Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)])
                objarea = (x1 - x0) * (y1 - y0)
                skip = False
                for objtemp in objs + results:
                    if np.abs(objtemp[6] - subframe) &gt; 1:
                        continue
                    ia = intersect_area(obj[:4], objtemp[:4])
                    if ia &gt;= (ratio * objarea):
                        # Our current obj is embedded, skip
                        return True
                return False

            skip = embedded(obj, objs, results)

            if not skip:
                results.append(obj)

        return results</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pancake.detector.backends.backend_dei.f"><code class="name flex">
<span>def <span class="ident">f</span></span>(<span>x:Â int) â€‘>Â (<classÂ 'int'>,Â <classÂ 'int'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Returns y value, angle of rotation, width for x along centre strip.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@lru_cache(maxsize=None)
def f(x: int) -&gt; (int, int):
    &#34;&#34;&#34;Returns y value, angle of rotation, width for x along centre strip.&#34;&#34;&#34;
    if x &lt; 3840:
        y = int(-0.047 * x + 1100)
        angle = int(-0.015 * x + 57)
        w = int(0.216 * x + 172)
    elif x &lt; 7627:
        y = 920
        angle = 0
        w = 1000
    else:
        y = int(0.054 * x + 510.8)
        angle = 360 - int(0.013 * x - 100.3)
        w = int(-0.213 * x + 2626)
    return y, angle, w // 2</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.hconcat"><code class="name flex">
<span>def <span class="ident">hconcat</span></span>(<span>source)</span>
</code></dt>
<dd>
<div class="desc"><p>Concat images horizontally</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def hconcat(source):
    &#34;&#34;&#34;Concat images horizontally&#34;&#34;&#34;
    if type(source) != list:
        source = [source]
    return cv2.hconcat(source)</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.locate"><code class="name flex">
<span>def <span class="ident">locate</span></span>(<span>subframes, x0, y0, x1, y1) â€‘>Â list</span>
</code></dt>
<dd>
<div class="desc"><p>Return all subframe ids the obj is present in.</p>
<p>This function assumes the coordinates are laid out like this:
x0, y0 ------------
|
|
|
|
|
|
------------ x1, y1</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def locate(subframes, x0, y0, x1, y1) -&gt; list:
    &#34;&#34;&#34;Return all subframe ids the obj is present in.

    This function assumes the coordinates are laid out like this:
    x0, y0 ------------
       |               |
       |               |
       |               |
        ------------ x1, y1
    &#34;&#34;&#34;
    locations = []
    if not (x0 &gt; 0 and y0 &gt; 0):
        return locations
    for i, subframe in enumerate(subframes):
        tlx, tly, brx, bry = subframe[:4]
        # Check if any corner is in the subframe
        if x0 &gt;= tlx and x0 &lt;= brx and y0 &gt;= tly and y0 &lt;= bry:  # tl
            locations.append(i)
            continue
        if x1 &gt;= tlx and x1 &lt;= brx and y0 &gt;= tly and y0 &lt;= bry:  # tr
            locations.append(i)
            continue
        if x1 &gt;= tlx and x1 &lt;= brx and y1 &gt;= tly and y1 &lt;= bry:  # br
            locations.append(i)
            continue
        if y1 &gt;= tly and y1 &lt;= bry and x0 &gt;= tlx and x0 &lt;= brx:  # bl
            locations.append(i)
            continue
    return locations</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.rev_rotate_bound"><code class="name flex">
<span>def <span class="ident">rev_rotate_bound</span></span>(<span>img:Â numpy.ndarray, result:Â tuple, angle:Â int, side:Â int) â€‘>Â list</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rev_rotate_bound(img: np.ndarray, result: tuple, angle: int, side: int) -&gt; list:
    h, w, _ = img.shape
    center = (w // 2, h // 2)

    x0, y0, x1, y1, cf, cl = result
    # Reverse rotation using rotation matrix
    # Note that we will from this point on use all four corners!
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    ntl = M.dot([x0, y0, 1])
    nbr = M.dot([x1, y1, 1])
    ntr = M.dot([x1, y0, 1])
    nbl = M.dot([x0, y1, 1])

    points = [*ntl, *nbr, *ntr, *nbl]
    xmax = max(list(points[:8:2]))
    xmin = min(list(points[:8:2]))
    ymax = max(list(points[1:8:2]))
    ymin = min(list(points[1:8:2]))

    diff = (w - side) // 2

    tlx, tly = int(xmin - diff), int(ymin - diff)
    brx, bry = int(xmax - diff), int(ymax - diff)

    return (tlx, tly, brx, bry, cf, cl)</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.rotate"><code class="name flex">
<span>def <span class="ident">rotate</span></span>(<span>image, angle)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate(image, angle):
    # grab the dimensions of the image
    (h, w) = image.shape[:2]

    center = (w // 2, h // 2)

    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    img_cuda = cv2.cuda_GpuMat()
    img_cuda.upload(image)

    rotated = cv2.cuda.warpAffine(img_cuda, M, (w, h))
    return rotated.download()</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.rotate_bound"><code class="name flex">
<span>def <span class="ident">rotate_bound</span></span>(<span>img:Â numpy.ndarray, angle:Â int)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="source">Source</h2>
<p>github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate_bound(img: np.ndarray, angle: int):
    &#34;&#34;&#34;
    Source:
        github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.
    &#34;&#34;&#34;
    # grab the dimensions of the image and then determine the
    # center
    (h, w) = img.shape[:2]
    (cX, cY) = (w / 2, h / 2)

    # grab the rotation matrix (applying the negative of the
    # angle to rotate clockwise), then grab the sine and cosine
    # (i.e., the rotation components of the matrix)
    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])

    # compute the new bounding dimensions of the image
    nW = int((h * sin) + (w * cos))
    nH = int((h * cos) + (w * sin))

    # adjust the rotation matrix to take into account translation
    M[0, 2] += (nW / 2) - cX
    M[1, 2] += (nH / 2) - cY

    # perform the actual rotation and return the image
    img_cuda = cv2.cuda_GpuMat()
    img_cuda.upload(img)

    res = cv2.cuda.warpAffine(img_cuda, M, (nW, nH))
    return res.download()</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.rotate_bound_cpu"><code class="name flex">
<span>def <span class="ident">rotate_bound_cpu</span></span>(<span>img:Â numpy.ndarray, angle:Â int)</span>
</code></dt>
<dd>
<div class="desc"><h2 id="source">Source</h2>
<p>github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate_bound_cpu(img: np.ndarray, angle: int):
    &#34;&#34;&#34;
    Source:
        github.com/jrosebr1/imutils/blob/master/imutils/convenience.py#L41-L63.
    &#34;&#34;&#34;
    # grab the dimensions of the image and then determine the
    # center
    (h, w) = img.shape[:2]
    (cX, cY) = (w / 2, h / 2)

    # grab the rotation matrix (applying the negative of the
    # angle to rotate clockwise), then grab the sine and cosine
    # (i.e., the rotation components of the matrix)
    M = cv2.getRotationMatrix2D((cX, cY), -angle, 1.0)
    cos = np.abs(M[0, 0])
    sin = np.abs(M[0, 1])

    # compute the new bounding dimensions of the image
    nW = int((h * sin) + (w * cos))
    nH = int((h * cos) + (w * sin))

    # adjust the rotation matrix to take into account translation
    M[0, 2] += (nW / 2) - cX
    M[1, 2] += (nH / 2) - cY

    # perform the actual rotation and return the image
    return cv2.warpAffine(img, M, (nW, nH))</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.rotate_cpu"><code class="name flex">
<span>def <span class="ident">rotate_cpu</span></span>(<span>image, angle)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate_cpu(image, angle):
    # grab the dimensions of the image
    (h, w) = image.shape[:2]

    center = (w // 2, h // 2)

    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    rotated = cv2.warpAffine(image, M, (w, h))

    return rotated</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pancake.detector.backends.backend_dei.DEI"><code class="flex name class">
<span>class <span class="ident">DEI</span></span>
<span>(</span><span>detector, roi:Â listÂ =Â None, simple:Â boolÂ =Â False, cache:Â boolÂ =Â True, config:Â dictÂ =Â {}, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>[<em>Abstract Class</em>] Base class of the Backends</p>
<p><strong>Base Class</strong>:
All Backends to be used within this framework have to inherit from this class.
The inheritance will automatically register every subclass into the registry thus
allowing for modular access to the detectors.</p>
<p>:param detector: Detector which provides 'detect' method,
which can take one or multiple images.
:param simple (bool): Use less subframes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DEI(Backend):
    def __init__(
        self,
        detector,
        roi: list = None,
        simple: bool = False,
        cache: bool = True,
        config: dict = {},
        *args,
        **kwargs,
    ) -&gt; None:
        &#34;&#34;&#34;

        :param detector: Detector which provides &#39;detect&#39; method,
                         which can take one or multiple images.
        :param simple (bool): Use less subframes

        &#34;&#34;&#34;
        self.detector = detector
        self.simple = simple

        if roi:
            self.roi = roi

        # Check if we can use cv2.cuda
        if cv2.cuda.getCudaEnabledDeviceCount() &gt; 0:
            self.rotate = rotate
            self.rotate_bound = rotate_bound
        else:
            self.rotate = rotate_cpu
            self.rotate_bound = rotate_bound_cpu
        # Note that rotate(_cpu) is not used as of now

        if config:
            self.simple = config[&#34;SIMPLE&#34;]

        self.cache = cache
        if cache:
            xyas = []
            x = CONST[&#34;START_X&#34;]
            y, angle, side = f(x)
            if self.simple:
                side = int(1.7 * side)
            xyas.append([x, y, angle, side])
            while x &lt; (CONST[&#34;END_X&#34;] + side):
                x = x + int(1.5 * side)
                y, angle, side = f(x)
                if self.simple:
                    side = int(1.7 * side)
                xyas.append([x, y, angle, side])
            self.xyas = xyas

    def rotate(self):
        pass

    def rotate_bound(self):
        pass

    def detect(
        self,
        source,
    ) -&gt; (list, np.ndarray):
        &#34;&#34;&#34;
        Detect objects on image by splitting and merging.

        :param source: filename or np.ndarray

        :return (objs, img): list of tuples with objects and their coordinates,
                             stitched panorama image

        The tuples of the return list have 6 values:
        x0: x-value top left corner
        y0: y-value top left corner
        x1: x-value bottom right corner
        y1: y-value bottom right corner
        conf: Confidence of detection, values between 0 and 1
        class id: Integer indicating the detected object type

        Modus operandi:
        * Stitch images
        * Divide image into subframes
        * Rotate subframes (without cropping, i.e. adding padding)
        * Detect objects on each subframe, saving classes and coordinates
        * Calculate coordinates on original frame
        * Filter and merge objects
        &#34;&#34;&#34;
        assert all(x.shape == source[0].shape for x in source[1:])

        # Crop center (fix overlapping)
        h, w, _ = source[1].shape
        crop = round(0.007 * w)  # Width to remove left and right
        source[1] = source[1][0:h, crop : w - crop]

        img = hconcat(source)

        if self.cache:
            subframes = []
            for x, y, angle, side in self.xyas:
                tlx, tly, brx, bry = x - side, y - side, x + side, y + side
                # TODO: ROI
                # tly = max(500, tly)
                # bry = min(1350, bry)
                subframe = img[tly:bry, tlx:brx]
                rot = self.rotate_bound(subframe, angle)
                subframes.append((rot, tlx, tly, brx, bry, angle, side))
        else:
            x = CONST[&#34;START_X&#34;]
            y, angle, side = f(x)
            subframes = []
            while x &lt; (CONST[&#34;END_X&#34;] + side):
                if self.simple:
                    side = int(1.7 * side)
                tlx, tly, brx, bry = x - side, y - side, x + side, y + side
                subframe = img[tly:bry, tlx:brx]
                rot = self.rotate_bound(subframe, angle)
                subframes.append((rot, tlx, tly, brx, bry, angle, side))
                x = x + int(1.5 * side)
                y, angle, side = f(x)

        imgs = [x[0] for x in subframes]

        result = self.detector.detect(imgs)

        objs = []
        for i, sub in enumerate(result):
            tlx, tly = subframes[i][1:3]
            for obj in sub:
                if subframes[i][5] != 0:  # angle
                    obj = rev_rotate_bound(
                        subframes[i][0], obj, subframes[i][5], subframes[i][6] * 2
                    )
                x0, y0, x1, y1, conf, classid = obj
                x0, y0, x1, y1, conf, classid = (
                    int(x0),
                    int(y0),
                    int(x1),
                    int(y1),
                    float(conf),
                    int(classid),
                )
                # top left
                rtlx, rtly = tlx + x0, tly + y0
                # bottom right
                rbrx, rbry = tlx + x1, tly + y1
                # save coords, conf, class
                objs.append((rtlx, rtly, rbrx, rbry, conf, classid, i))

        subcoords = [x[1:5] for x in subframes]
        results = self.merge(objs, subcoords)

        if False:  # Debugging
            for obj in results:
                x0, y0, x1, y1, *_ = obj
                cv2.rectangle(img, (x0, y0), (x1, y1), (255, 0, 0), 2)
            for subf in subframes:
                x0, y0, x1, y1 = subf[1:5]
                cv2.rectangle(img, (x0, y0), (x1, y1), (255, 0, 0), 2)
            cv2.imwrite(&#34;stuff.jpg&#34;, img)

        for i, x in enumerate(results):
            results[i] = torch.FloatTensor(list(x[:6]))

        results = torch.stack(results, dim=0) if results else torch.empty((0, 6))
        return results, img

    def merge(self, objs: list, subframes: list = None, ratio=0.8) -&gt; list:
        &#34;&#34;&#34;
        Merge all detected objects of subframes.

        Right now we use a single heuristic:
        If obj is embedded in another object with 90% or more of its area, discard it.

        TODO:
            This simple heuristic is by no means perfect yet.
            Especially when an object is right at the border of a subframe,
            the results can get inaccurate.
            Further filtering has to be done here
            Example:
            * If obj is at the border of a subframe, check if it is in the middle
              of another one (and discard if so)
        &#34;&#34;&#34;
        results = []
        while objs:
            obj = objs.pop(0)
            # First, check if obj is present in multiple subframes
            # If not, we can add it directly
            if subframes:
                locations = locate(subframes, *obj[:4])
                if len(locations) == 0:  # This should _never_ happen
                    l.warn(&#34;Object not located in any subframe!&#34;)
                    continue
                if len(locations) == 1:
                    results.append(obj)
                    continue
            # If yes, we need to do some filtering

            def intersect_area(a: tuple, b: tuple):
                dx = np.minimum(a[2], b[2]) - np.maximum(a[0], b[0])
                dy = np.minimum(a[3], b[3]) - np.maximum(a[1], b[1])
                if dx &gt;= 0 and dy &gt;= 0:
                    return np.maximum(0, dx * dy)
                return 0

            def embedded(obj: tuple, objs: list, results: list):
                # Check if object is embedded in other object (with &gt;80% of its area)
                x0, y0, x1, y1 = obj[:4]
                subframe = obj[6]
                rect1 = Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)])
                objarea = (x1 - x0) * (y1 - y0)
                skip = False
                for objtemp in objs + results:
                    if np.abs(objtemp[6] - subframe) &gt; 1:
                        continue
                    ia = intersect_area(obj[:4], objtemp[:4])
                    if ia &gt;= (ratio * objarea):
                        # Our current obj is embedded, skip
                        return True
                return False

            skip = embedded(obj, objs, results)

            if not skip:
                results.append(obj)

        return results</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pancake.detector.backends.backend.Backend" href="backend.html#pancake.detector.backends.backend.Backend">Backend</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pancake.detector.backends.backend_dei.DEI.detect"><code class="name flex">
<span>def <span class="ident">detect</span></span>(<span>self, source) â€‘>Â (<classÂ 'list'>,Â <classÂ 'numpy.ndarray'>)</span>
</code></dt>
<dd>
<div class="desc"><p>Detect objects on image by splitting and merging.</p>
<p>:param source: filename or np.ndarray</p>
<p>:return (objs, img): list of tuples with objects and their coordinates,
stitched panorama image</p>
<p>The tuples of the return list have 6 values:
x0: x-value top left corner
y0: y-value top left corner
x1: x-value bottom right corner
y1: y-value bottom right corner
conf: Confidence of detection, values between 0 and 1
class id: Integer indicating the detected object type</p>
<p>Modus operandi:
* Stitch images
* Divide image into subframes
* Rotate subframes (without cropping, i.e. adding padding)
* Detect objects on each subframe, saving classes and coordinates
* Calculate coordinates on original frame
* Filter and merge objects</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def detect(
    self,
    source,
) -&gt; (list, np.ndarray):
    &#34;&#34;&#34;
    Detect objects on image by splitting and merging.

    :param source: filename or np.ndarray

    :return (objs, img): list of tuples with objects and their coordinates,
                         stitched panorama image

    The tuples of the return list have 6 values:
    x0: x-value top left corner
    y0: y-value top left corner
    x1: x-value bottom right corner
    y1: y-value bottom right corner
    conf: Confidence of detection, values between 0 and 1
    class id: Integer indicating the detected object type

    Modus operandi:
    * Stitch images
    * Divide image into subframes
    * Rotate subframes (without cropping, i.e. adding padding)
    * Detect objects on each subframe, saving classes and coordinates
    * Calculate coordinates on original frame
    * Filter and merge objects
    &#34;&#34;&#34;
    assert all(x.shape == source[0].shape for x in source[1:])

    # Crop center (fix overlapping)
    h, w, _ = source[1].shape
    crop = round(0.007 * w)  # Width to remove left and right
    source[1] = source[1][0:h, crop : w - crop]

    img = hconcat(source)

    if self.cache:
        subframes = []
        for x, y, angle, side in self.xyas:
            tlx, tly, brx, bry = x - side, y - side, x + side, y + side
            # TODO: ROI
            # tly = max(500, tly)
            # bry = min(1350, bry)
            subframe = img[tly:bry, tlx:brx]
            rot = self.rotate_bound(subframe, angle)
            subframes.append((rot, tlx, tly, brx, bry, angle, side))
    else:
        x = CONST[&#34;START_X&#34;]
        y, angle, side = f(x)
        subframes = []
        while x &lt; (CONST[&#34;END_X&#34;] + side):
            if self.simple:
                side = int(1.7 * side)
            tlx, tly, brx, bry = x - side, y - side, x + side, y + side
            subframe = img[tly:bry, tlx:brx]
            rot = self.rotate_bound(subframe, angle)
            subframes.append((rot, tlx, tly, brx, bry, angle, side))
            x = x + int(1.5 * side)
            y, angle, side = f(x)

    imgs = [x[0] for x in subframes]

    result = self.detector.detect(imgs)

    objs = []
    for i, sub in enumerate(result):
        tlx, tly = subframes[i][1:3]
        for obj in sub:
            if subframes[i][5] != 0:  # angle
                obj = rev_rotate_bound(
                    subframes[i][0], obj, subframes[i][5], subframes[i][6] * 2
                )
            x0, y0, x1, y1, conf, classid = obj
            x0, y0, x1, y1, conf, classid = (
                int(x0),
                int(y0),
                int(x1),
                int(y1),
                float(conf),
                int(classid),
            )
            # top left
            rtlx, rtly = tlx + x0, tly + y0
            # bottom right
            rbrx, rbry = tlx + x1, tly + y1
            # save coords, conf, class
            objs.append((rtlx, rtly, rbrx, rbry, conf, classid, i))

    subcoords = [x[1:5] for x in subframes]
    results = self.merge(objs, subcoords)

    if False:  # Debugging
        for obj in results:
            x0, y0, x1, y1, *_ = obj
            cv2.rectangle(img, (x0, y0), (x1, y1), (255, 0, 0), 2)
        for subf in subframes:
            x0, y0, x1, y1 = subf[1:5]
            cv2.rectangle(img, (x0, y0), (x1, y1), (255, 0, 0), 2)
        cv2.imwrite(&#34;stuff.jpg&#34;, img)

    for i, x in enumerate(results):
        results[i] = torch.FloatTensor(list(x[:6]))

    results = torch.stack(results, dim=0) if results else torch.empty((0, 6))
    return results, img</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.DEI.merge"><code class="name flex">
<span>def <span class="ident">merge</span></span>(<span>self, objs:Â list, subframes:Â listÂ =Â None, ratio=0.8) â€‘>Â list</span>
</code></dt>
<dd>
<div class="desc"><p>Merge all detected objects of subframes.</p>
<p>Right now we use a single heuristic:
If obj is embedded in another object with 90% or more of its area, discard it.</p>
<h2 id="todo">Todo</h2>
<p>This simple heuristic is by no means perfect yet.
Especially when an object is right at the border of a subframe,
the results can get inaccurate.
Further filtering has to be done here
Example:
* If obj is at the border of a subframe, check if it is in the middle
of another one (and discard if so)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def merge(self, objs: list, subframes: list = None, ratio=0.8) -&gt; list:
    &#34;&#34;&#34;
    Merge all detected objects of subframes.

    Right now we use a single heuristic:
    If obj is embedded in another object with 90% or more of its area, discard it.

    TODO:
        This simple heuristic is by no means perfect yet.
        Especially when an object is right at the border of a subframe,
        the results can get inaccurate.
        Further filtering has to be done here
        Example:
        * If obj is at the border of a subframe, check if it is in the middle
          of another one (and discard if so)
    &#34;&#34;&#34;
    results = []
    while objs:
        obj = objs.pop(0)
        # First, check if obj is present in multiple subframes
        # If not, we can add it directly
        if subframes:
            locations = locate(subframes, *obj[:4])
            if len(locations) == 0:  # This should _never_ happen
                l.warn(&#34;Object not located in any subframe!&#34;)
                continue
            if len(locations) == 1:
                results.append(obj)
                continue
        # If yes, we need to do some filtering

        def intersect_area(a: tuple, b: tuple):
            dx = np.minimum(a[2], b[2]) - np.maximum(a[0], b[0])
            dy = np.minimum(a[3], b[3]) - np.maximum(a[1], b[1])
            if dx &gt;= 0 and dy &gt;= 0:
                return np.maximum(0, dx * dy)
            return 0

        def embedded(obj: tuple, objs: list, results: list):
            # Check if object is embedded in other object (with &gt;80% of its area)
            x0, y0, x1, y1 = obj[:4]
            subframe = obj[6]
            rect1 = Polygon([(x0, y0), (x1, y0), (x1, y1), (x0, y1)])
            objarea = (x1 - x0) * (y1 - y0)
            skip = False
            for objtemp in objs + results:
                if np.abs(objtemp[6] - subframe) &gt; 1:
                    continue
                ia = intersect_area(obj[:4], objtemp[:4])
                if ia &gt;= (ratio * objarea):
                    # Our current obj is embedded, skip
                    return True
            return False

        skip = embedded(obj, objs, results)

        if not skip:
            results.append(obj)

    return results</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.DEI.rotate"><code class="name flex">
<span>def <span class="ident">rotate</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate(self):
    pass</code></pre>
</details>
</dd>
<dt id="pancake.detector.backends.backend_dei.DEI.rotate_bound"><code class="name flex">
<span>def <span class="ident">rotate_bound</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def rotate_bound(self):
    pass</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="pancake.detector.backends.backend.Backend" href="backend.html#pancake.detector.backends.backend.Backend">Backend</a></b></code>:
<ul class="hlist">
<li><code><a title="pancake.detector.backends.backend.Backend.get_subclasses" href="backend.html#pancake.detector.backends.backend.Backend.get_subclasses">get_subclasses</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul>
<li><a href="#divide-et-impera-divide-and-conquer-backend">Divide Et Impera (Divide And Conquer) Backend</a></li>
</ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pancake.detector.backends" href="index.html">pancake.detector.backends</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="pancake.detector.backends.backend_dei.f" href="#pancake.detector.backends.backend_dei.f">f</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.hconcat" href="#pancake.detector.backends.backend_dei.hconcat">hconcat</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.locate" href="#pancake.detector.backends.backend_dei.locate">locate</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.rev_rotate_bound" href="#pancake.detector.backends.backend_dei.rev_rotate_bound">rev_rotate_bound</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.rotate" href="#pancake.detector.backends.backend_dei.rotate">rotate</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.rotate_bound" href="#pancake.detector.backends.backend_dei.rotate_bound">rotate_bound</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.rotate_bound_cpu" href="#pancake.detector.backends.backend_dei.rotate_bound_cpu">rotate_bound_cpu</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.rotate_cpu" href="#pancake.detector.backends.backend_dei.rotate_cpu">rotate_cpu</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pancake.detector.backends.backend_dei.DEI" href="#pancake.detector.backends.backend_dei.DEI">DEI</a></code></h4>
<ul class="">
<li><code><a title="pancake.detector.backends.backend_dei.DEI.detect" href="#pancake.detector.backends.backend_dei.DEI.detect">detect</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.DEI.merge" href="#pancake.detector.backends.backend_dei.DEI.merge">merge</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.DEI.rotate" href="#pancake.detector.backends.backend_dei.DEI.rotate">rotate</a></code></li>
<li><code><a title="pancake.detector.backends.backend_dei.DEI.rotate_bound" href="#pancake.detector.backends.backend_dei.DEI.rotate_bound">rotate_bound</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>