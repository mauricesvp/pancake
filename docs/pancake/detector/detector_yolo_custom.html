<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pancake.detector.detector_yolo_custom API documentation</title>
<meta name="description" content="Custom Detector Class based on YOLOv5" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pancake.detector.detector_yolo_custom</code></h1>
</header>
<section id="section-intro">
<p>Custom Detector Class based on YOLOv5</p>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">&#34;&#34;&#34; Custom Detector Class based on YOLOv5 &#34;&#34;&#34;
from typing import List

import math
import numpy as np

import torch

from .detector import Detector
import pancake.models as m

# from pancake.models.tensorrt.yolov5_tensorrt import Yolov5TRT
from pancake.logger import setup_logger
from pancake.utils.common import fix_path
from pancake.utils.datasets import letterbox
from pancake.utils.general import scale_coords
from pancake.utils.function_profiler import profile
from pancake.models.yolov5_class import Yolov5Model

l = setup_logger(__name__)


class YOLOCustomDetector(Detector):
    def __init__(self, config: dict, *args, **kwargs) -&gt; None:
        &#34;&#34;&#34; This class encapsulates the YOLOv5 module.

        Description:
            During initialization the configurations are retrieved and parsed to the \
            initialization of the YOLOv5 class. \
            When the flag &#39;trt&#39; is True, self.model is overwritten by the YOLOv5 TensorRT model.

        Args:
            config (dict): Configuration dictionary
        &#34;&#34;&#34;
        self.weights = config[&#34;weights&#34;]
        weights_cfg = (
            fix_path(self.weights) if type(self.weights) is str else self.weights
        )
        model = config[&#34;model&#34;]

        trt = config[&#34;trt&#34;]
        trt_engine_path = config[&#34;trt_engine_path&#34;]
        trt_plugin_library = config[&#34;trt_plugin_library&#34;]

        conf_thres = float(config[&#34;conf_thres&#34;])
        iou_thres = float(config[&#34;iou_thres&#34;])
        classes = None if &#34;None&#34; == config[&#34;classes&#34;] else config[&#34;classes&#34;]
        agnostic_nms = True if &#34;True&#34; == config[&#34;agnostic_nms&#34;] else False
        img_size = int(config[&#34;img_size&#34;])
        device = kwargs.get(&#34;device&#34;, &#34;CPU&#34;)
        max_det = int(config[&#34;max_det&#34;])

        self.model: Yolov5Model = m.MODEL_REGISTRY[model](
            device,
            weights_cfg,
            conf_thres,
            iou_thres,
            classes,
            agnostic_nms,
            img_size,
            max_det,
        )

        try:
            if trt:
                from pancake.models.tensorrt.yolov5_trt_2 import Yolov5TRT

                self.model = (
                    Yolov5TRT(self.model, trt_engine_path, trt_plugin_library, device)
                    if trt
                    else self.model
                )
        except ModuleNotFoundError:
            l.info(f&#34;Will fallback to weights file: {self.weights}&#34;)

    def detect(self, imgs: List[np.ndarray]) -&gt; List[torch.Tensor]:
        &#34;&#34;&#34;Wrapper for detection calculation.

        Description:
            - Pads and resizes the images to conform with the model
            - Calls the infer method of underlying model in order to retrieve detections
            - Rescales the detections

        Args:
            imgs (List[np.ndarray]): List of ndarrays, images in BGR [bs, c, w, h]

        Returns:
            List[torch.Tensor]: List of tensors, detections on (,6) tensors [xyxy, conf, cls]
        &#34;&#34;&#34;
        if type(imgs) is not list:
            imgs = [imgs]

        img_sizes = [img.shape for img in imgs]

        # Inference
        pr_imgs = self._preprocess(imgs)
        # l.debug(f&#34;Inference on: {pr_imgs.shape}&#34;)
        det, _ = self.model.infer(pr_imgs)

        res = self._postprocess(det, pr_imgs, img_sizes)
        return res

    def _preprocess(self, imgs: List[np.ndarray]) -&gt; np.array:
        &#34;&#34;&#34;Pads and resizes the images, converts the images to RGB.

        Args:
            imgs (List[np.ndarray]): List of ndarrays, images in BGR [bs, c, w, h]

        Returns:
            np.array: Padded and resized images in RGB [bs, c, w, h]
        &#34;&#34;&#34;
        if type(imgs) is not list:
            imgs = [imgs]

        # Padded resize
        pr_imgs = [
            letterbox(x, self.model._required_img_size, stride=self.model._stride)[0]
            for x in imgs
        ]
        # Stack
        pr_imgs = np.stack(pr_imgs, 0)
        # Convert
        pr_imgs = pr_imgs[:, :, :, ::-1].transpose(
            0, 3, 1, 2
        )  # BGR to RGB, to bsx3x416x416
        pr_imgs = np.ascontiguousarray(pr_imgs)
        return pr_imgs

    def _postprocess(
        self, det: List[torch.Tensor], pr_imgs: np.array, img_sizes: list
    ) -&gt; list:
        &#34;&#34;&#34;Rescales the detection matrix from padded and resized to
        the original size.

        Args:
            det (List[torch.Tensor]): Tensor list of detections, on (,6) tensor [bs, xyxy, conf, cls]
            pr_imgs (np.array): Preprocessed images [bs, c, w, h]
            img_sizes (list): List of original image sizes [bs, (w, h)]

        Returns:
            list: Tensor list of rescaled detections, on (,6) tensor [bs, xyxy, conf, cls]
        &#34;&#34;&#34;
        # Rescale images from preprocessed to original
        res = [None] * len(det)
        for i, x in enumerate(det):
            x[:, :4] = scale_coords(pr_imgs.shape[2:], x[:, :4], img_sizes[i]).round()
            res[i] = x
        return res</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pancake.detector.detector_yolo_custom.YOLOCustomDetector"><code class="flex name class">
<span>class <span class="ident">YOLOCustomDetector</span></span>
<span>(</span><span>config: dict, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>[<em>Abstract Class</em>] Base class of the Detectors</p>
<p><strong>Base Class</strong>:
All Detectors to be used within this framework have to inherit from this class.
The inheritance will automatically register every subclass into the registry thus
allowing for modular access to the detectors.</p>
<p>This class encapsulates the YOLOv5 module.</p>
<h2 id="description">Description</h2>
<p>During initialization the configurations are retrieved and parsed to the
initialization of the YOLOv5 class.
When the flag 'trt' is True, self.model is overwritten by the YOLOv5 TensorRT model.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code>dict</code></dt>
<dd>Configuration dictionary</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class YOLOCustomDetector(Detector):
    def __init__(self, config: dict, *args, **kwargs) -&gt; None:
        &#34;&#34;&#34; This class encapsulates the YOLOv5 module.

        Description:
            During initialization the configurations are retrieved and parsed to the \
            initialization of the YOLOv5 class. \
            When the flag &#39;trt&#39; is True, self.model is overwritten by the YOLOv5 TensorRT model.

        Args:
            config (dict): Configuration dictionary
        &#34;&#34;&#34;
        self.weights = config[&#34;weights&#34;]
        weights_cfg = (
            fix_path(self.weights) if type(self.weights) is str else self.weights
        )
        model = config[&#34;model&#34;]

        trt = config[&#34;trt&#34;]
        trt_engine_path = config[&#34;trt_engine_path&#34;]
        trt_plugin_library = config[&#34;trt_plugin_library&#34;]

        conf_thres = float(config[&#34;conf_thres&#34;])
        iou_thres = float(config[&#34;iou_thres&#34;])
        classes = None if &#34;None&#34; == config[&#34;classes&#34;] else config[&#34;classes&#34;]
        agnostic_nms = True if &#34;True&#34; == config[&#34;agnostic_nms&#34;] else False
        img_size = int(config[&#34;img_size&#34;])
        device = kwargs.get(&#34;device&#34;, &#34;CPU&#34;)
        max_det = int(config[&#34;max_det&#34;])

        self.model: Yolov5Model = m.MODEL_REGISTRY[model](
            device,
            weights_cfg,
            conf_thres,
            iou_thres,
            classes,
            agnostic_nms,
            img_size,
            max_det,
        )

        try:
            if trt:
                from pancake.models.tensorrt.yolov5_trt_2 import Yolov5TRT

                self.model = (
                    Yolov5TRT(self.model, trt_engine_path, trt_plugin_library, device)
                    if trt
                    else self.model
                )
        except ModuleNotFoundError:
            l.info(f&#34;Will fallback to weights file: {self.weights}&#34;)

    def detect(self, imgs: List[np.ndarray]) -&gt; List[torch.Tensor]:
        &#34;&#34;&#34;Wrapper for detection calculation.

        Description:
            - Pads and resizes the images to conform with the model
            - Calls the infer method of underlying model in order to retrieve detections
            - Rescales the detections

        Args:
            imgs (List[np.ndarray]): List of ndarrays, images in BGR [bs, c, w, h]

        Returns:
            List[torch.Tensor]: List of tensors, detections on (,6) tensors [xyxy, conf, cls]
        &#34;&#34;&#34;
        if type(imgs) is not list:
            imgs = [imgs]

        img_sizes = [img.shape for img in imgs]

        # Inference
        pr_imgs = self._preprocess(imgs)
        # l.debug(f&#34;Inference on: {pr_imgs.shape}&#34;)
        det, _ = self.model.infer(pr_imgs)

        res = self._postprocess(det, pr_imgs, img_sizes)
        return res

    def _preprocess(self, imgs: List[np.ndarray]) -&gt; np.array:
        &#34;&#34;&#34;Pads and resizes the images, converts the images to RGB.

        Args:
            imgs (List[np.ndarray]): List of ndarrays, images in BGR [bs, c, w, h]

        Returns:
            np.array: Padded and resized images in RGB [bs, c, w, h]
        &#34;&#34;&#34;
        if type(imgs) is not list:
            imgs = [imgs]

        # Padded resize
        pr_imgs = [
            letterbox(x, self.model._required_img_size, stride=self.model._stride)[0]
            for x in imgs
        ]
        # Stack
        pr_imgs = np.stack(pr_imgs, 0)
        # Convert
        pr_imgs = pr_imgs[:, :, :, ::-1].transpose(
            0, 3, 1, 2
        )  # BGR to RGB, to bsx3x416x416
        pr_imgs = np.ascontiguousarray(pr_imgs)
        return pr_imgs

    def _postprocess(
        self, det: List[torch.Tensor], pr_imgs: np.array, img_sizes: list
    ) -&gt; list:
        &#34;&#34;&#34;Rescales the detection matrix from padded and resized to
        the original size.

        Args:
            det (List[torch.Tensor]): Tensor list of detections, on (,6) tensor [bs, xyxy, conf, cls]
            pr_imgs (np.array): Preprocessed images [bs, c, w, h]
            img_sizes (list): List of original image sizes [bs, (w, h)]

        Returns:
            list: Tensor list of rescaled detections, on (,6) tensor [bs, xyxy, conf, cls]
        &#34;&#34;&#34;
        # Rescale images from preprocessed to original
        res = [None] * len(det)
        for i, x in enumerate(det):
            x[:, :4] = scale_coords(pr_imgs.shape[2:], x[:, :4], img_sizes[i]).round()
            res[i] = x
        return res</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pancake.detector.detector.Detector" href="detector.html#pancake.detector.detector.Detector">Detector</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="pancake.detector.detector_yolo_custom.YOLOCustomDetector.detect"><code class="name flex">
<span>def <span class="ident">detect</span></span>(<span>self, imgs: List[numpy.ndarray]) ‑> List[torch.Tensor]</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper for detection calculation.</p>
<h2 id="description">Description</h2>
<ul>
<li>Pads and resizes the images to conform with the model</li>
<li>Calls the infer method of underlying model in order to retrieve detections</li>
<li>Rescales the detections</li>
</ul>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>imgs</code></strong> :&ensp;<code>List[np.ndarray]</code></dt>
<dd>List of ndarrays, images in BGR [bs, c, w, h]</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>List[torch.Tensor]</code></dt>
<dd>List of tensors, detections on (,6) tensors [xyxy, conf, cls]</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def detect(self, imgs: List[np.ndarray]) -&gt; List[torch.Tensor]:
    &#34;&#34;&#34;Wrapper for detection calculation.

    Description:
        - Pads and resizes the images to conform with the model
        - Calls the infer method of underlying model in order to retrieve detections
        - Rescales the detections

    Args:
        imgs (List[np.ndarray]): List of ndarrays, images in BGR [bs, c, w, h]

    Returns:
        List[torch.Tensor]: List of tensors, detections on (,6) tensors [xyxy, conf, cls]
    &#34;&#34;&#34;
    if type(imgs) is not list:
        imgs = [imgs]

    img_sizes = [img.shape for img in imgs]

    # Inference
    pr_imgs = self._preprocess(imgs)
    # l.debug(f&#34;Inference on: {pr_imgs.shape}&#34;)
    det, _ = self.model.infer(pr_imgs)

    res = self._postprocess(det, pr_imgs, img_sizes)
    return res</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="pancake.detector.detector.Detector" href="detector.html#pancake.detector.detector.Detector">Detector</a></b></code>:
<ul class="hlist">
<li><code><a title="pancake.detector.detector.Detector.get_subclasses" href="detector.html#pancake.detector.detector.Detector.get_subclasses">get_subclasses</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pancake.detector" href="index.html">pancake.detector</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pancake.detector.detector_yolo_custom.YOLOCustomDetector" href="#pancake.detector.detector_yolo_custom.YOLOCustomDetector">YOLOCustomDetector</a></code></h4>
<ul class="">
<li><code><a title="pancake.detector.detector_yolo_custom.YOLOCustomDetector.detect" href="#pancake.detector.detector_yolo_custom.YOLOCustomDetector.detect">detect</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>