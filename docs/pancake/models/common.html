<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pancake.models.common API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pancake.models.common</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># YOLOv5 common modules

import math
from copy import copy
from pathlib import Path

import numpy as np
import pandas as pd
import requests
import torch
import torch.nn as nn
from PIL import Image
from torch.cuda import amp

from pancake.utils.datasets import letterbox
from pancake.utils.general import (
    non_max_suppression,
    make_divisible,
    scale_coords,
    increment_path,
    xyxy2xywh,
    save_one_box,
)
from pancake.utils.plots import colors, plot_one_box
from pancake.utils.torch_utils import time_synchronized


def autopad(k, p=None):  # kernel, padding
    # Pad to &#39;same&#39;
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad
    return p


def DWConv(c1, c2, k=1, s=1, act=True):
    # Depthwise convolution
    return Conv(c1, c2, k, s, g=math.gcd(c1, c2), act=act)


class Conv(nn.Module):
    # Standard convolution
    def __init__(
        self, c1, c2, k=1, s=1, p=None, g=1, act=True
    ):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Conv, self).__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = (
            nn.SiLU()
            if act is True
            else (act if isinstance(act, nn.Module) else nn.Identity())
        )

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def fuseforward(self, x):
        return self.act(self.conv(x))


class TransformerLayer(nn.Module):
    # Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)
    def __init__(self, c, num_heads):
        super().__init__()
        self.q = nn.Linear(c, c, bias=False)
        self.k = nn.Linear(c, c, bias=False)
        self.v = nn.Linear(c, c, bias=False)
        self.ma = nn.MultiheadAttention(embed_dim=c, num_heads=num_heads)
        self.fc1 = nn.Linear(c, c, bias=False)
        self.fc2 = nn.Linear(c, c, bias=False)

    def forward(self, x):
        x = self.ma(self.q(x), self.k(x), self.v(x))[0] + x
        x = self.fc2(self.fc1(x)) + x
        return x


class TransformerBlock(nn.Module):
    # Vision Transformer https://arxiv.org/abs/2010.11929
    def __init__(self, c1, c2, num_heads, num_layers):
        super().__init__()
        self.conv = None
        if c1 != c2:
            self.conv = Conv(c1, c2)
        self.linear = nn.Linear(c2, c2)  # learnable position embedding
        self.tr = nn.Sequential(
            *[TransformerLayer(c2, num_heads) for _ in range(num_layers)]
        )
        self.c2 = c2

    def forward(self, x):
        if self.conv is not None:
            x = self.conv(x)
        b, _, w, h = x.shape
        p = x.flatten(2)
        p = p.unsqueeze(0)
        p = p.transpose(0, 3)
        p = p.squeeze(3)
        e = self.linear(p)
        x = p + e

        x = self.tr(x)
        x = x.unsqueeze(3)
        x = x.transpose(0, 3)
        x = x.reshape(b, self.c2, w, h)
        return x


class Bottleneck(nn.Module):
    # Standard bottleneck
    def __init__(
        self, c1, c2, shortcut=True, g=1, e=0.5
    ):  # ch_in, ch_out, shortcut, groups, expansion
        super(Bottleneck, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))


class BottleneckCSP(nn.Module):
    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(
        self, c1, c2, n=1, shortcut=True, g=1, e=0.5
    ):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(BottleneckCSP, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)
        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)
        self.cv4 = Conv(2 * c_, c2, 1, 1)
        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)
        self.act = nn.LeakyReLU(0.1, inplace=True)
        self.m = nn.Sequential(
            *[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)]
        )

    def forward(self, x):
        y1 = self.cv3(self.m(self.cv1(x)))
        y2 = self.cv2(x)
        return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))


class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(
        self, c1, c2, n=1, shortcut=True, g=1, e=0.5
    ):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(C3, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(
            *[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)]
        )
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))


class C3TR(C3):
    # C3 module with TransformerBlock()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = TransformerBlock(c_, c_, 4, n)


class SPP(nn.Module):
    # Spatial pyramid pooling layer used in YOLOv3-SPP
    def __init__(self, c1, c2, k=(5, 9, 13)):
        super(SPP, self).__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)
        self.m = nn.ModuleList(
            [nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k]
        )

    def forward(self, x):
        x = self.cv1(x)
        return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))


class Focus(nn.Module):
    # Focus wh information into c-space
    def __init__(
        self, c1, c2, k=1, s=1, p=None, g=1, act=True
    ):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Focus, self).__init__()
        self.conv = Conv(c1 * 4, c2, k, s, p, g, act)
        # self.contract = Contract(gain=2)

    def forward(self, x):  # x(b,c,w,h) -&gt; y(b,4c,w/2,h/2)
        return self.conv(
            torch.cat(
                [
                    x[..., ::2, ::2],
                    x[..., 1::2, ::2],
                    x[..., ::2, 1::2],
                    x[..., 1::2, 1::2],
                ],
                1,
            )
        )
        # return self.conv(self.contract(x))


class Contract(nn.Module):
    # Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        (
            N,
            C,
            H,
            W,
        ) = x.size()  # assert (H / s == 0) and (W / s == 0), &#39;Indivisible gain&#39;
        s = self.gain
        x = x.view(N, C, H // s, s, W // s, s)  # x(1,64,40,2,40,2)
        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # x(1,2,2,64,40,40)
        return x.view(N, C * s * s, H // s, W // s)  # x(1,256,40,40)


class Expand(nn.Module):
    # Expand channels into width-height, i.e. x(1,64,80,80) to x(1,16,160,160)
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        N, C, H, W = x.size()  # assert C / s ** 2 == 0, &#39;Indivisible gain&#39;
        s = self.gain
        x = x.view(N, s, s, C // s ** 2, H, W)  # x(1,2,2,16,80,80)
        x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # x(1,16,80,2,80,2)
        return x.view(N, C // s ** 2, H * s, W * s)  # x(1,16,160,160)


class Concat(nn.Module):
    # Concatenate a list of tensors along dimension
    def __init__(self, dimension=1):
        super(Concat, self).__init__()
        self.d = dimension

    def forward(self, x):
        return torch.cat(x, self.d)


class NMS(nn.Module):
    # Non-Maximum Suppression (NMS) module
    conf = 0.25  # confidence threshold
    iou = 0.45  # IoU threshold
    classes = None  # (optional list) filter by class

    def __init__(self):
        super(NMS, self).__init__()

    def forward(self, x):
        return non_max_suppression(
            x[0], conf_thres=self.conf, iou_thres=self.iou, classes=self.classes
        )


class autoShape(nn.Module):
    # input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS
    conf = 0.25  # NMS confidence threshold
    iou = 0.45  # NMS IoU threshold
    classes = None  # (optional list) filter by class

    def __init__(self, model):
        super(autoShape, self).__init__()
        self.model = model.eval()

    def autoshape(self):
        print(
            &#34;autoShape already enabled, skipping... &#34;
        )  # model already converted to model.autoshape()
        return self

    @torch.no_grad()
    def forward(self, imgs, size=640, augment=False, profile=False):
        # Inference from various sources. For height=640, width=1280, RGB images example inputs are:
        #   filename:   imgs = &#39;data/images/zidane.jpg&#39;
        #   URI:             = &#39;https://github.com/ultralytics/yolov5/releases/download/v1.0/zidane.jpg&#39;
        #   OpenCV:          = cv2.imread(&#39;image.jpg&#39;)[:,:,::-1]  # HWC BGR to RGB x(640,1280,3)
        #   PIL:             = Image.open(&#39;image.jpg&#39;)  # HWC x(640,1280,3)
        #   numpy:           = np.zeros((640,1280,3))  # HWC
        #   torch:           = torch.zeros(16,3,320,640)  # BCHW (scaled to size=640, 0-1 values)
        #   multiple:        = [Image.open(&#39;image1.jpg&#39;), Image.open(&#39;image2.jpg&#39;), ...]  # list of images

        t = [time_synchronized()]
        p = next(self.model.parameters())  # for device and type
        if isinstance(imgs, torch.Tensor):  # torch
            with amp.autocast(enabled=p.device.type != &#34;cpu&#34;):
                return self.model(
                    imgs.to(p.device).type_as(p), augment, profile
                )  # inference

        # Pre-process
        n, imgs = (
            (len(imgs), imgs) if isinstance(imgs, list) else (1, [imgs])
        )  # number of images, list of images
        shape0, shape1, files = [], [], []  # image and inference shapes, filenames
        for i, im in enumerate(imgs):
            f = f&#34;image{i}&#34;  # filename
            if isinstance(im, str):  # filename or uri
                im, f = (
                    np.asarray(
                        Image.open(
                            requests.get(im, stream=True).raw
                            if im.startswith(&#34;http&#34;)
                            else im
                        )
                    ),
                    im,
                )
            elif isinstance(im, Image.Image):  # PIL Image
                im, f = np.asarray(im), getattr(im, &#34;filename&#34;, f) or f
            files.append(Path(f).with_suffix(&#34;.jpg&#34;).name)
            if im.shape[0] &lt; 5:  # image in CHW
                im = im.transpose((1, 2, 0))  # reverse dataloader .transpose(2, 0, 1)
            im = (
                im[:, :, :3] if im.ndim == 3 else np.tile(im[:, :, None], 3)
            )  # enforce 3ch input
            s = im.shape[:2]  # HWC
            shape0.append(s)  # image shape
            g = size / max(s)  # gain
            shape1.append([y * g for y in s])
            imgs[i] = im if im.data.contiguous else np.ascontiguousarray(im)  # update
        shape1 = [
            make_divisible(x, int(self.stride.max()))
            for x in np.stack(shape1, 0).max(0)
        ]  # inference shape
        x = [letterbox(im, new_shape=shape1, auto=False)[0] for im in imgs]  # pad
        x = np.stack(x, 0) if n &gt; 1 else x[0][None]  # stack
        x = np.ascontiguousarray(x.transpose((0, 3, 1, 2)))  # BHWC to BCHW
        x = torch.from_numpy(x).to(p.device).type_as(p) / 255.0  # uint8 to fp16/32
        t.append(time_synchronized())

        with amp.autocast(enabled=p.device.type != &#34;cpu&#34;):
            # Inference
            y = self.model(x, augment, profile)[0]  # forward
            t.append(time_synchronized())

            # Post-process
            y = non_max_suppression(
                y, conf_thres=self.conf, iou_thres=self.iou, classes=self.classes
            )  # NMS
            for i in range(n):
                scale_coords(shape1, y[i][:, :4], shape0[i])

            t.append(time_synchronized())
            return Detections(imgs, y, files, t, self.names, x.shape)


class Detections:
    # detections class for YOLOv5 inference results
    def __init__(self, imgs, pred, files, times=None, names=None, shape=None):
        super(Detections, self).__init__()
        d = pred[0].device  # device
        gn = [
            torch.tensor([*[im.shape[i] for i in [1, 0, 1, 0]], 1.0, 1.0], device=d)
            for im in imgs
        ]  # normalizations
        self.imgs = imgs  # list of images as numpy arrays
        self.pred = pred  # list of tensors pred[0] = (xyxy, conf, cls)
        self.names = names  # class names
        self.files = files  # image filenames
        self.xyxy = pred  # xyxy pixels
        self.xywh = [xyxy2xywh(x) for x in pred]  # xywh pixels
        self.xyxyn = [x / g for x, g in zip(self.xyxy, gn)]  # xyxy normalized
        self.xywhn = [x / g for x, g in zip(self.xywh, gn)]  # xywh normalized
        self.n = len(self.pred)  # number of images (batch size)
        self.t = tuple(
            (times[i + 1] - times[i]) * 1000 / self.n for i in range(3)
        )  # timestamps (ms)
        self.s = shape  # inference BCHW shape

    def display(
        self,
        pprint=False,
        show=False,
        save=False,
        crop=False,
        render=False,
        save_dir=Path(&#34;&#34;),
    ):
        for i, (im, pred) in enumerate(zip(self.imgs, self.pred)):
            str = f&#34;image {i + 1}/{len(self.pred)}: {im.shape[0]}x{im.shape[1]} &#34;
            if pred is not None:
                for c in pred[:, -1].unique():
                    n = (pred[:, -1] == c).sum()  # detections per class
                    str += f&#34;{n} {self.names[int(c)]}{&#39;s&#39; * (n &gt; 1)}, &#34;  # add to string
                if show or save or render or crop:
                    for *box, conf, cls in pred:  # xyxy, confidence, class
                        label = f&#34;{self.names[int(cls)]} {conf:.2f}&#34;
                        if crop:
                            save_one_box(
                                box,
                                im,
                                file=save_dir
                                / &#34;crops&#34;
                                / self.names[int(cls)]
                                / self.files[i],
                            )
                        else:  # all others
                            plot_one_box(box, im, label=label, color=colors(cls))

            im = (
                Image.fromarray(im.astype(np.uint8))
                if isinstance(im, np.ndarray)
                else im
            )  # from np
            if pprint:
                print(str.rstrip(&#34;, &#34;))
            if show:
                im.show(self.files[i])  # show
            if save:
                f = self.files[i]
                im.save(save_dir / f)  # save
                print(
                    f&#34;{&#39;Saved&#39; * (i == 0)} {f}&#34;,
                    end=&#34;,&#34; if i &lt; self.n - 1 else f&#34; to {save_dir}\n&#34;,
                )
            if render:
                self.imgs[i] = np.asarray(im)

    def print(self):
        self.display(pprint=True)  # print results
        print(
            f&#34;Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {tuple(self.s)}&#34;
            % self.t
        )

    def show(self):
        self.display(show=True)  # show results

    def save(self, save_dir=&#34;runs/hub/exp&#34;):
        save_dir = increment_path(
            save_dir, exist_ok=save_dir != &#34;runs/hub/exp&#34;, mkdir=True
        )  # increment save_dir
        self.display(save=True, save_dir=save_dir)  # save results

    def crop(self, save_dir=&#34;runs/hub/exp&#34;):
        save_dir = increment_path(
            save_dir, exist_ok=save_dir != &#34;runs/hub/exp&#34;, mkdir=True
        )  # increment save_dir
        self.display(crop=True, save_dir=save_dir)  # crop results
        print(f&#34;Saved results to {save_dir}\n&#34;)

    def render(self):
        self.display(render=True)  # render results
        return self.imgs

    def pandas(self):
        # return detections as pandas DataFrames, i.e. print(results.pandas().xyxy[0])
        new = copy(self)  # return copy
        ca = (
            &#34;xmin&#34;,
            &#34;ymin&#34;,
            &#34;xmax&#34;,
            &#34;ymax&#34;,
            &#34;confidence&#34;,
            &#34;class&#34;,
            &#34;name&#34;,
        )  # xyxy columns
        cb = (
            &#34;xcenter&#34;,
            &#34;ycenter&#34;,
            &#34;width&#34;,
            &#34;height&#34;,
            &#34;confidence&#34;,
            &#34;class&#34;,
            &#34;name&#34;,
        )  # xywh columns
        for k, c in zip([&#34;xyxy&#34;, &#34;xyxyn&#34;, &#34;xywh&#34;, &#34;xywhn&#34;], [ca, ca, cb, cb]):
            a = [
                [x[:5] + [int(x[5]), self.names[int(x[5])]] for x in x.tolist()]
                for x in getattr(self, k)
            ]  # update
            setattr(new, k, [pd.DataFrame(x, columns=c) for x in a])
        return new

    def tolist(self):
        # return a list of Detections objects, i.e. &#39;for result in results.tolist():&#39;
        x = [
            Detections([self.imgs[i]], [self.pred[i]], self.names, self.s)
            for i in range(self.n)
        ]
        for d in x:
            for k in [&#34;imgs&#34;, &#34;pred&#34;, &#34;xyxy&#34;, &#34;xyxyn&#34;, &#34;xywh&#34;, &#34;xywhn&#34;]:
                setattr(d, k, getattr(d, k)[0])  # pop out of list
        return x

    def __len__(self):
        return self.n


class Classify(nn.Module):
    # Classification head, i.e. x(b,c1,20,20) to x(b,c2)
    def __init__(
        self, c1, c2, k=1, s=1, p=None, g=1
    ):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Classify, self).__init__()
        self.aap = nn.AdaptiveAvgPool2d(1)  # to x(b,c1,1,1)
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g)  # to x(b,c2,1,1)
        self.flat = nn.Flatten()

    def forward(self, x):
        z = torch.cat(
            [self.aap(y) for y in (x if isinstance(x, list) else [x])], 1
        )  # cat if list
        return self.flat(self.conv(z))  # flatten to x(b,c2)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pancake.models.common.DWConv"><code class="name flex">
<span>def <span class="ident">DWConv</span></span>(<span>c1, c2, k=1, s=1, act=True)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def DWConv(c1, c2, k=1, s=1, act=True):
    # Depthwise convolution
    return Conv(c1, c2, k, s, g=math.gcd(c1, c2), act=act)</code></pre>
</details>
</dd>
<dt id="pancake.models.common.autopad"><code class="name flex">
<span>def <span class="ident">autopad</span></span>(<span>k, p=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def autopad(k, p=None):  # kernel, padding
    # Pad to &#39;same&#39;
    if p is None:
        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad
    return p</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pancake.models.common.Bottleneck"><code class="flex name class">
<span>class <span class="ident">Bottleneck</span></span>
<span>(</span><span>c1, c2, shortcut=True, g=1, e=0.5)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Bottleneck(nn.Module):
    # Standard bottleneck
    def __init__(
        self, c1, c2, shortcut=True, g=1, e=0.5
    ):  # ch_in, ch_out, shortcut, groups, expansion
        super(Bottleneck, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.Bottleneck.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.Bottleneck.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.Bottleneck.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.BottleneckCSP"><code class="flex name class">
<span>class <span class="ident">BottleneckCSP</span></span>
<span>(</span><span>c1, c2, n=1, shortcut=True, g=1, e=0.5)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class BottleneckCSP(nn.Module):
    # CSP Bottleneck https://github.com/WongKinYiu/CrossStagePartialNetworks
    def __init__(
        self, c1, c2, n=1, shortcut=True, g=1, e=0.5
    ):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(BottleneckCSP, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = nn.Conv2d(c1, c_, 1, 1, bias=False)
        self.cv3 = nn.Conv2d(c_, c_, 1, 1, bias=False)
        self.cv4 = Conv(2 * c_, c2, 1, 1)
        self.bn = nn.BatchNorm2d(2 * c_)  # applied to cat(cv2, cv3)
        self.act = nn.LeakyReLU(0.1, inplace=True)
        self.m = nn.Sequential(
            *[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)]
        )

    def forward(self, x):
        y1 = self.cv3(self.m(self.cv1(x)))
        y2 = self.cv2(x)
        return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.BottleneckCSP.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.BottleneckCSP.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.BottleneckCSP.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    y1 = self.cv3(self.m(self.cv1(x)))
    y2 = self.cv2(x)
    return self.cv4(self.act(self.bn(torch.cat((y1, y2), dim=1))))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.C3"><code class="flex name class">
<span>class <span class="ident">C3</span></span>
<span>(</span><span>c1, c2, n=1, shortcut=True, g=1, e=0.5)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    def __init__(
        self, c1, c2, n=1, shortcut=True, g=1, e=0.5
    ):  # ch_in, ch_out, number, shortcut, groups, expansion
        super(C3, self).__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # act=FReLU(c2)
        self.m = nn.Sequential(
            *[Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n)]
        )
        # self.m = nn.Sequential(*[CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)])

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Subclasses</h3>
<ul class="hlist">
<li><a title="pancake.models.common.C3TR" href="#pancake.models.common.C3TR">C3TR</a></li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.C3.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.C3.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.C3.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), dim=1))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.C3TR"><code class="flex name class">
<span>class <span class="ident">C3TR</span></span>
<span>(</span><span>c1, c2, n=1, shortcut=True, g=1, e=0.5)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class C3TR(C3):
    # C3 module with TransformerBlock()
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):
        super().__init__(c1, c2, n, shortcut, g, e)
        c_ = int(c2 * e)
        self.m = TransformerBlock(c_, c_, 4, n)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="pancake.models.common.C3" href="#pancake.models.common.C3">C3</a></li>
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.C3TR.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.C3TR.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="pancake.models.common.C3" href="#pancake.models.common.C3">C3</a></b></code>:
<ul class="hlist">
<li><code><a title="pancake.models.common.C3.forward" href="#pancake.models.common.C3.forward">forward</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="pancake.models.common.Classify"><code class="flex name class">
<span>class <span class="ident">Classify</span></span>
<span>(</span><span>c1, c2, k=1, s=1, p=None, g=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Classify(nn.Module):
    # Classification head, i.e. x(b,c1,20,20) to x(b,c2)
    def __init__(
        self, c1, c2, k=1, s=1, p=None, g=1
    ):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Classify, self).__init__()
        self.aap = nn.AdaptiveAvgPool2d(1)  # to x(b,c1,1,1)
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g)  # to x(b,c2,1,1)
        self.flat = nn.Flatten()

    def forward(self, x):
        z = torch.cat(
            [self.aap(y) for y in (x if isinstance(x, list) else [x])], 1
        )  # cat if list
        return self.flat(self.conv(z))  # flatten to x(b,c2)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.Classify.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.Classify.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.Classify.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    z = torch.cat(
        [self.aap(y) for y in (x if isinstance(x, list) else [x])], 1
    )  # cat if list
    return self.flat(self.conv(z))  # flatten to x(b,c2)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.Concat"><code class="flex name class">
<span>class <span class="ident">Concat</span></span>
<span>(</span><span>dimension=1)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Concat(nn.Module):
    # Concatenate a list of tensors along dimension
    def __init__(self, dimension=1):
        super(Concat, self).__init__()
        self.d = dimension

    def forward(self, x):
        return torch.cat(x, self.d)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.Concat.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.Concat.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.Concat.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    return torch.cat(x, self.d)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.Contract"><code class="flex name class">
<span>class <span class="ident">Contract</span></span>
<span>(</span><span>gain=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Contract(nn.Module):
    # Contract width-height into channels, i.e. x(1,64,80,80) to x(1,256,40,40)
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        (
            N,
            C,
            H,
            W,
        ) = x.size()  # assert (H / s == 0) and (W / s == 0), &#39;Indivisible gain&#39;
        s = self.gain
        x = x.view(N, C, H // s, s, W // s, s)  # x(1,64,40,2,40,2)
        x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # x(1,2,2,64,40,40)
        return x.view(N, C * s * s, H // s, W // s)  # x(1,256,40,40)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.Contract.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.Contract.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.Contract.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    (
        N,
        C,
        H,
        W,
    ) = x.size()  # assert (H / s == 0) and (W / s == 0), &#39;Indivisible gain&#39;
    s = self.gain
    x = x.view(N, C, H // s, s, W // s, s)  # x(1,64,40,2,40,2)
    x = x.permute(0, 3, 5, 1, 2, 4).contiguous()  # x(1,2,2,64,40,40)
    return x.view(N, C * s * s, H // s, W // s)  # x(1,256,40,40)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.Conv"><code class="flex name class">
<span>class <span class="ident">Conv</span></span>
<span>(</span><span>c1, c2, k=1, s=1, p=None, g=1, act=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Conv(nn.Module):
    # Standard convolution
    def __init__(
        self, c1, c2, k=1, s=1, p=None, g=1, act=True
    ):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Conv, self).__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = (
            nn.SiLU()
            if act is True
            else (act if isinstance(act, nn.Module) else nn.Identity())
        )

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def fuseforward(self, x):
        return self.act(self.conv(x))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.Conv.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.Conv.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.Conv.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    return self.act(self.bn(self.conv(x)))</code></pre>
</details>
</dd>
<dt id="pancake.models.common.Conv.fuseforward"><code class="name flex">
<span>def <span class="ident">fuseforward</span></span>(<span>self, x)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fuseforward(self, x):
    return self.act(self.conv(x))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.Detections"><code class="flex name class">
<span>class <span class="ident">Detections</span></span>
<span>(</span><span>imgs, pred, files, times=None, names=None, shape=None)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Detections:
    # detections class for YOLOv5 inference results
    def __init__(self, imgs, pred, files, times=None, names=None, shape=None):
        super(Detections, self).__init__()
        d = pred[0].device  # device
        gn = [
            torch.tensor([*[im.shape[i] for i in [1, 0, 1, 0]], 1.0, 1.0], device=d)
            for im in imgs
        ]  # normalizations
        self.imgs = imgs  # list of images as numpy arrays
        self.pred = pred  # list of tensors pred[0] = (xyxy, conf, cls)
        self.names = names  # class names
        self.files = files  # image filenames
        self.xyxy = pred  # xyxy pixels
        self.xywh = [xyxy2xywh(x) for x in pred]  # xywh pixels
        self.xyxyn = [x / g for x, g in zip(self.xyxy, gn)]  # xyxy normalized
        self.xywhn = [x / g for x, g in zip(self.xywh, gn)]  # xywh normalized
        self.n = len(self.pred)  # number of images (batch size)
        self.t = tuple(
            (times[i + 1] - times[i]) * 1000 / self.n for i in range(3)
        )  # timestamps (ms)
        self.s = shape  # inference BCHW shape

    def display(
        self,
        pprint=False,
        show=False,
        save=False,
        crop=False,
        render=False,
        save_dir=Path(&#34;&#34;),
    ):
        for i, (im, pred) in enumerate(zip(self.imgs, self.pred)):
            str = f&#34;image {i + 1}/{len(self.pred)}: {im.shape[0]}x{im.shape[1]} &#34;
            if pred is not None:
                for c in pred[:, -1].unique():
                    n = (pred[:, -1] == c).sum()  # detections per class
                    str += f&#34;{n} {self.names[int(c)]}{&#39;s&#39; * (n &gt; 1)}, &#34;  # add to string
                if show or save or render or crop:
                    for *box, conf, cls in pred:  # xyxy, confidence, class
                        label = f&#34;{self.names[int(cls)]} {conf:.2f}&#34;
                        if crop:
                            save_one_box(
                                box,
                                im,
                                file=save_dir
                                / &#34;crops&#34;
                                / self.names[int(cls)]
                                / self.files[i],
                            )
                        else:  # all others
                            plot_one_box(box, im, label=label, color=colors(cls))

            im = (
                Image.fromarray(im.astype(np.uint8))
                if isinstance(im, np.ndarray)
                else im
            )  # from np
            if pprint:
                print(str.rstrip(&#34;, &#34;))
            if show:
                im.show(self.files[i])  # show
            if save:
                f = self.files[i]
                im.save(save_dir / f)  # save
                print(
                    f&#34;{&#39;Saved&#39; * (i == 0)} {f}&#34;,
                    end=&#34;,&#34; if i &lt; self.n - 1 else f&#34; to {save_dir}\n&#34;,
                )
            if render:
                self.imgs[i] = np.asarray(im)

    def print(self):
        self.display(pprint=True)  # print results
        print(
            f&#34;Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {tuple(self.s)}&#34;
            % self.t
        )

    def show(self):
        self.display(show=True)  # show results

    def save(self, save_dir=&#34;runs/hub/exp&#34;):
        save_dir = increment_path(
            save_dir, exist_ok=save_dir != &#34;runs/hub/exp&#34;, mkdir=True
        )  # increment save_dir
        self.display(save=True, save_dir=save_dir)  # save results

    def crop(self, save_dir=&#34;runs/hub/exp&#34;):
        save_dir = increment_path(
            save_dir, exist_ok=save_dir != &#34;runs/hub/exp&#34;, mkdir=True
        )  # increment save_dir
        self.display(crop=True, save_dir=save_dir)  # crop results
        print(f&#34;Saved results to {save_dir}\n&#34;)

    def render(self):
        self.display(render=True)  # render results
        return self.imgs

    def pandas(self):
        # return detections as pandas DataFrames, i.e. print(results.pandas().xyxy[0])
        new = copy(self)  # return copy
        ca = (
            &#34;xmin&#34;,
            &#34;ymin&#34;,
            &#34;xmax&#34;,
            &#34;ymax&#34;,
            &#34;confidence&#34;,
            &#34;class&#34;,
            &#34;name&#34;,
        )  # xyxy columns
        cb = (
            &#34;xcenter&#34;,
            &#34;ycenter&#34;,
            &#34;width&#34;,
            &#34;height&#34;,
            &#34;confidence&#34;,
            &#34;class&#34;,
            &#34;name&#34;,
        )  # xywh columns
        for k, c in zip([&#34;xyxy&#34;, &#34;xyxyn&#34;, &#34;xywh&#34;, &#34;xywhn&#34;], [ca, ca, cb, cb]):
            a = [
                [x[:5] + [int(x[5]), self.names[int(x[5])]] for x in x.tolist()]
                for x in getattr(self, k)
            ]  # update
            setattr(new, k, [pd.DataFrame(x, columns=c) for x in a])
        return new

    def tolist(self):
        # return a list of Detections objects, i.e. &#39;for result in results.tolist():&#39;
        x = [
            Detections([self.imgs[i]], [self.pred[i]], self.names, self.s)
            for i in range(self.n)
        ]
        for d in x:
            for k in [&#34;imgs&#34;, &#34;pred&#34;, &#34;xyxy&#34;, &#34;xyxyn&#34;, &#34;xywh&#34;, &#34;xywhn&#34;]:
                setattr(d, k, getattr(d, k)[0])  # pop out of list
        return x

    def __len__(self):
        return self.n</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.Detections.crop"><code class="name flex">
<span>def <span class="ident">crop</span></span>(<span>self, save_dir='runs/hub/exp')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def crop(self, save_dir=&#34;runs/hub/exp&#34;):
    save_dir = increment_path(
        save_dir, exist_ok=save_dir != &#34;runs/hub/exp&#34;, mkdir=True
    )  # increment save_dir
    self.display(crop=True, save_dir=save_dir)  # crop results
    print(f&#34;Saved results to {save_dir}\n&#34;)</code></pre>
</details>
</dd>
<dt id="pancake.models.common.Detections.display"><code class="name flex">
<span>def <span class="ident">display</span></span>(<span>self, pprint=False, show=False, save=False, crop=False, render=False, save_dir=PosixPath('.'))</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def display(
    self,
    pprint=False,
    show=False,
    save=False,
    crop=False,
    render=False,
    save_dir=Path(&#34;&#34;),
):
    for i, (im, pred) in enumerate(zip(self.imgs, self.pred)):
        str = f&#34;image {i + 1}/{len(self.pred)}: {im.shape[0]}x{im.shape[1]} &#34;
        if pred is not None:
            for c in pred[:, -1].unique():
                n = (pred[:, -1] == c).sum()  # detections per class
                str += f&#34;{n} {self.names[int(c)]}{&#39;s&#39; * (n &gt; 1)}, &#34;  # add to string
            if show or save or render or crop:
                for *box, conf, cls in pred:  # xyxy, confidence, class
                    label = f&#34;{self.names[int(cls)]} {conf:.2f}&#34;
                    if crop:
                        save_one_box(
                            box,
                            im,
                            file=save_dir
                            / &#34;crops&#34;
                            / self.names[int(cls)]
                            / self.files[i],
                        )
                    else:  # all others
                        plot_one_box(box, im, label=label, color=colors(cls))

        im = (
            Image.fromarray(im.astype(np.uint8))
            if isinstance(im, np.ndarray)
            else im
        )  # from np
        if pprint:
            print(str.rstrip(&#34;, &#34;))
        if show:
            im.show(self.files[i])  # show
        if save:
            f = self.files[i]
            im.save(save_dir / f)  # save
            print(
                f&#34;{&#39;Saved&#39; * (i == 0)} {f}&#34;,
                end=&#34;,&#34; if i &lt; self.n - 1 else f&#34; to {save_dir}\n&#34;,
            )
        if render:
            self.imgs[i] = np.asarray(im)</code></pre>
</details>
</dd>
<dt id="pancake.models.common.Detections.pandas"><code class="name flex">
<span>def <span class="ident">pandas</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pandas(self):
    # return detections as pandas DataFrames, i.e. print(results.pandas().xyxy[0])
    new = copy(self)  # return copy
    ca = (
        &#34;xmin&#34;,
        &#34;ymin&#34;,
        &#34;xmax&#34;,
        &#34;ymax&#34;,
        &#34;confidence&#34;,
        &#34;class&#34;,
        &#34;name&#34;,
    )  # xyxy columns
    cb = (
        &#34;xcenter&#34;,
        &#34;ycenter&#34;,
        &#34;width&#34;,
        &#34;height&#34;,
        &#34;confidence&#34;,
        &#34;class&#34;,
        &#34;name&#34;,
    )  # xywh columns
    for k, c in zip([&#34;xyxy&#34;, &#34;xyxyn&#34;, &#34;xywh&#34;, &#34;xywhn&#34;], [ca, ca, cb, cb]):
        a = [
            [x[:5] + [int(x[5]), self.names[int(x[5])]] for x in x.tolist()]
            for x in getattr(self, k)
        ]  # update
        setattr(new, k, [pd.DataFrame(x, columns=c) for x in a])
    return new</code></pre>
</details>
</dd>
<dt id="pancake.models.common.Detections.print"><code class="name flex">
<span>def <span class="ident">print</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def print(self):
    self.display(pprint=True)  # print results
    print(
        f&#34;Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {tuple(self.s)}&#34;
        % self.t
    )</code></pre>
</details>
</dd>
<dt id="pancake.models.common.Detections.render"><code class="name flex">
<span>def <span class="ident">render</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def render(self):
    self.display(render=True)  # render results
    return self.imgs</code></pre>
</details>
</dd>
<dt id="pancake.models.common.Detections.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>self, save_dir='runs/hub/exp')</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(self, save_dir=&#34;runs/hub/exp&#34;):
    save_dir = increment_path(
        save_dir, exist_ok=save_dir != &#34;runs/hub/exp&#34;, mkdir=True
    )  # increment save_dir
    self.display(save=True, save_dir=save_dir)  # save results</code></pre>
</details>
</dd>
<dt id="pancake.models.common.Detections.show"><code class="name flex">
<span>def <span class="ident">show</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def show(self):
    self.display(show=True)  # show results</code></pre>
</details>
</dd>
<dt id="pancake.models.common.Detections.tolist"><code class="name flex">
<span>def <span class="ident">tolist</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def tolist(self):
    # return a list of Detections objects, i.e. &#39;for result in results.tolist():&#39;
    x = [
        Detections([self.imgs[i]], [self.pred[i]], self.names, self.s)
        for i in range(self.n)
    ]
    for d in x:
        for k in [&#34;imgs&#34;, &#34;pred&#34;, &#34;xyxy&#34;, &#34;xyxyn&#34;, &#34;xywh&#34;, &#34;xywhn&#34;]:
            setattr(d, k, getattr(d, k)[0])  # pop out of list
    return x</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.Expand"><code class="flex name class">
<span>class <span class="ident">Expand</span></span>
<span>(</span><span>gain=2)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Expand(nn.Module):
    # Expand channels into width-height, i.e. x(1,64,80,80) to x(1,16,160,160)
    def __init__(self, gain=2):
        super().__init__()
        self.gain = gain

    def forward(self, x):
        N, C, H, W = x.size()  # assert C / s ** 2 == 0, &#39;Indivisible gain&#39;
        s = self.gain
        x = x.view(N, s, s, C // s ** 2, H, W)  # x(1,2,2,16,80,80)
        x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # x(1,16,80,2,80,2)
        return x.view(N, C // s ** 2, H * s, W * s)  # x(1,16,160,160)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.Expand.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.Expand.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.Expand.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    N, C, H, W = x.size()  # assert C / s ** 2 == 0, &#39;Indivisible gain&#39;
    s = self.gain
    x = x.view(N, s, s, C // s ** 2, H, W)  # x(1,2,2,16,80,80)
    x = x.permute(0, 3, 4, 1, 5, 2).contiguous()  # x(1,16,80,2,80,2)
    return x.view(N, C // s ** 2, H * s, W * s)  # x(1,16,160,160)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.Focus"><code class="flex name class">
<span>class <span class="ident">Focus</span></span>
<span>(</span><span>c1, c2, k=1, s=1, p=None, g=1, act=True)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Focus(nn.Module):
    # Focus wh information into c-space
    def __init__(
        self, c1, c2, k=1, s=1, p=None, g=1, act=True
    ):  # ch_in, ch_out, kernel, stride, padding, groups
        super(Focus, self).__init__()
        self.conv = Conv(c1 * 4, c2, k, s, p, g, act)
        # self.contract = Contract(gain=2)

    def forward(self, x):  # x(b,c,w,h) -&gt; y(b,4c,w/2,h/2)
        return self.conv(
            torch.cat(
                [
                    x[..., ::2, ::2],
                    x[..., 1::2, ::2],
                    x[..., ::2, 1::2],
                    x[..., 1::2, 1::2],
                ],
                1,
            )
        )
        # return self.conv(self.contract(x))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.Focus.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.Focus.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.Focus.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):  # x(b,c,w,h) -&gt; y(b,4c,w/2,h/2)
    return self.conv(
        torch.cat(
            [
                x[..., ::2, ::2],
                x[..., 1::2, ::2],
                x[..., ::2, 1::2],
                x[..., 1::2, 1::2],
            ],
            1,
        )
    )
    # return self.conv(self.contract(x))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.NMS"><code class="flex name class">
<span>class <span class="ident">NMS</span></span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NMS(nn.Module):
    # Non-Maximum Suppression (NMS) module
    conf = 0.25  # confidence threshold
    iou = 0.45  # IoU threshold
    classes = None  # (optional list) filter by class

    def __init__(self):
        super(NMS, self).__init__()

    def forward(self, x):
        return non_max_suppression(
            x[0], conf_thres=self.conf, iou_thres=self.iou, classes=self.classes
        )</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.NMS.classes"><code class="name">var <span class="ident">classes</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.NMS.conf"><code class="name">var <span class="ident">conf</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.NMS.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.NMS.iou"><code class="name">var <span class="ident">iou</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.NMS.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.NMS.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    return non_max_suppression(
        x[0], conf_thres=self.conf, iou_thres=self.iou, classes=self.classes
    )</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.SPP"><code class="flex name class">
<span>class <span class="ident">SPP</span></span>
<span>(</span><span>c1, c2, k=(5, 9, 13))</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class SPP(nn.Module):
    # Spatial pyramid pooling layer used in YOLOv3-SPP
    def __init__(self, c1, c2, k=(5, 9, 13)):
        super(SPP, self).__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * (len(k) + 1), c2, 1, 1)
        self.m = nn.ModuleList(
            [nn.MaxPool2d(kernel_size=x, stride=1, padding=x // 2) for x in k]
        )

    def forward(self, x):
        x = self.cv1(x)
        return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.SPP.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.SPP.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.SPP.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    x = self.cv1(x)
    return self.cv2(torch.cat([x] + [m(x) for m in self.m], 1))</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.TransformerBlock"><code class="flex name class">
<span>class <span class="ident">TransformerBlock</span></span>
<span>(</span><span>c1, c2, num_heads, num_layers)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TransformerBlock(nn.Module):
    # Vision Transformer https://arxiv.org/abs/2010.11929
    def __init__(self, c1, c2, num_heads, num_layers):
        super().__init__()
        self.conv = None
        if c1 != c2:
            self.conv = Conv(c1, c2)
        self.linear = nn.Linear(c2, c2)  # learnable position embedding
        self.tr = nn.Sequential(
            *[TransformerLayer(c2, num_heads) for _ in range(num_layers)]
        )
        self.c2 = c2

    def forward(self, x):
        if self.conv is not None:
            x = self.conv(x)
        b, _, w, h = x.shape
        p = x.flatten(2)
        p = p.unsqueeze(0)
        p = p.transpose(0, 3)
        p = p.squeeze(3)
        e = self.linear(p)
        x = p + e

        x = self.tr(x)
        x = x.unsqueeze(3)
        x = x.transpose(0, 3)
        x = x.reshape(b, self.c2, w, h)
        return x</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.TransformerBlock.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.TransformerBlock.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.TransformerBlock.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    if self.conv is not None:
        x = self.conv(x)
    b, _, w, h = x.shape
    p = x.flatten(2)
    p = p.unsqueeze(0)
    p = p.transpose(0, 3)
    p = p.squeeze(3)
    e = self.linear(p)
    x = p + e

    x = self.tr(x)
    x = x.unsqueeze(3)
    x = x.transpose(0, 3)
    x = x.reshape(b, self.c2, w, h)
    return x</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.TransformerLayer"><code class="flex name class">
<span>class <span class="ident">TransformerLayer</span></span>
<span>(</span><span>c, num_heads)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TransformerLayer(nn.Module):
    # Transformer layer https://arxiv.org/abs/2010.11929 (LayerNorm layers removed for better performance)
    def __init__(self, c, num_heads):
        super().__init__()
        self.q = nn.Linear(c, c, bias=False)
        self.k = nn.Linear(c, c, bias=False)
        self.v = nn.Linear(c, c, bias=False)
        self.ma = nn.MultiheadAttention(embed_dim=c, num_heads=num_heads)
        self.fc1 = nn.Linear(c, c, bias=False)
        self.fc2 = nn.Linear(c, c, bias=False)

    def forward(self, x):
        x = self.ma(self.q(x), self.k(x), self.v(x))[0] + x
        x = self.fc2(self.fc1(x)) + x
        return x</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.TransformerLayer.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.TransformerLayer.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.TransformerLayer.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, x) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the :class:<code>Module</code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def forward(self, x):
    x = self.ma(self.q(x), self.k(x), self.v(x))[0] + x
    x = self.fc2(self.fc1(x)) + x
    return x</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="pancake.models.common.autoShape"><code class="flex name class">
<span>class <span class="ident">autoShape</span></span>
<span>(</span><span>model)</span>
</code></dt>
<dd>
<div class="desc"><p>Base class for all neural network modules.</p>
<p>Your models should also subclass this class.</p>
<p>Modules can also contain other Modules, allowing to nest them in
a tree structure. You can assign the submodules as regular attributes::</p>
<pre><code>import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super(Model, self).__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
</code></pre>
<p>Submodules assigned in this way will be registered, and will have their
parameters converted too when you call :meth:<code>to</code>, etc.</p>
<p>:ivar training: Boolean represents whether this module is in training or
evaluation mode.
:vartype training: bool</p>
<p>Initializes internal Module state, shared by both nn.Module and ScriptModule.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class autoShape(nn.Module):
    # input-robust model wrapper for passing cv2/np/PIL/torch inputs. Includes preprocessing, inference and NMS
    conf = 0.25  # NMS confidence threshold
    iou = 0.45  # NMS IoU threshold
    classes = None  # (optional list) filter by class

    def __init__(self, model):
        super(autoShape, self).__init__()
        self.model = model.eval()

    def autoshape(self):
        print(
            &#34;autoShape already enabled, skipping... &#34;
        )  # model already converted to model.autoshape()
        return self

    @torch.no_grad()
    def forward(self, imgs, size=640, augment=False, profile=False):
        # Inference from various sources. For height=640, width=1280, RGB images example inputs are:
        #   filename:   imgs = &#39;data/images/zidane.jpg&#39;
        #   URI:             = &#39;https://github.com/ultralytics/yolov5/releases/download/v1.0/zidane.jpg&#39;
        #   OpenCV:          = cv2.imread(&#39;image.jpg&#39;)[:,:,::-1]  # HWC BGR to RGB x(640,1280,3)
        #   PIL:             = Image.open(&#39;image.jpg&#39;)  # HWC x(640,1280,3)
        #   numpy:           = np.zeros((640,1280,3))  # HWC
        #   torch:           = torch.zeros(16,3,320,640)  # BCHW (scaled to size=640, 0-1 values)
        #   multiple:        = [Image.open(&#39;image1.jpg&#39;), Image.open(&#39;image2.jpg&#39;), ...]  # list of images

        t = [time_synchronized()]
        p = next(self.model.parameters())  # for device and type
        if isinstance(imgs, torch.Tensor):  # torch
            with amp.autocast(enabled=p.device.type != &#34;cpu&#34;):
                return self.model(
                    imgs.to(p.device).type_as(p), augment, profile
                )  # inference

        # Pre-process
        n, imgs = (
            (len(imgs), imgs) if isinstance(imgs, list) else (1, [imgs])
        )  # number of images, list of images
        shape0, shape1, files = [], [], []  # image and inference shapes, filenames
        for i, im in enumerate(imgs):
            f = f&#34;image{i}&#34;  # filename
            if isinstance(im, str):  # filename or uri
                im, f = (
                    np.asarray(
                        Image.open(
                            requests.get(im, stream=True).raw
                            if im.startswith(&#34;http&#34;)
                            else im
                        )
                    ),
                    im,
                )
            elif isinstance(im, Image.Image):  # PIL Image
                im, f = np.asarray(im), getattr(im, &#34;filename&#34;, f) or f
            files.append(Path(f).with_suffix(&#34;.jpg&#34;).name)
            if im.shape[0] &lt; 5:  # image in CHW
                im = im.transpose((1, 2, 0))  # reverse dataloader .transpose(2, 0, 1)
            im = (
                im[:, :, :3] if im.ndim == 3 else np.tile(im[:, :, None], 3)
            )  # enforce 3ch input
            s = im.shape[:2]  # HWC
            shape0.append(s)  # image shape
            g = size / max(s)  # gain
            shape1.append([y * g for y in s])
            imgs[i] = im if im.data.contiguous else np.ascontiguousarray(im)  # update
        shape1 = [
            make_divisible(x, int(self.stride.max()))
            for x in np.stack(shape1, 0).max(0)
        ]  # inference shape
        x = [letterbox(im, new_shape=shape1, auto=False)[0] for im in imgs]  # pad
        x = np.stack(x, 0) if n &gt; 1 else x[0][None]  # stack
        x = np.ascontiguousarray(x.transpose((0, 3, 1, 2)))  # BHWC to BCHW
        x = torch.from_numpy(x).to(p.device).type_as(p) / 255.0  # uint8 to fp16/32
        t.append(time_synchronized())

        with amp.autocast(enabled=p.device.type != &#34;cpu&#34;):
            # Inference
            y = self.model(x, augment, profile)[0]  # forward
            t.append(time_synchronized())

            # Post-process
            y = non_max_suppression(
                y, conf_thres=self.conf, iou_thres=self.iou, classes=self.classes
            )  # NMS
            for i in range(n):
                scale_coords(shape1, y[i][:, :4], shape0[i])

            t.append(time_synchronized())
            return Detections(imgs, y, files, t, self.names, x.shape)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>torch.nn.modules.module.Module</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="pancake.models.common.autoShape.classes"><code class="name">var <span class="ident">classes</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.autoShape.conf"><code class="name">var <span class="ident">conf</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.autoShape.dump_patches"><code class="name">var <span class="ident">dump_patches</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.autoShape.iou"><code class="name">var <span class="ident">iou</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="pancake.models.common.autoShape.training"><code class="name">var <span class="ident">training</span> : bool</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="pancake.models.common.autoShape.autoshape"><code class="name flex">
<span>def <span class="ident">autoshape</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def autoshape(self):
    print(
        &#34;autoShape already enabled, skipping... &#34;
    )  # model already converted to model.autoshape()
    return self</code></pre>
</details>
</dd>
<dt id="pancake.models.common.autoShape.forward"><code class="name flex">
<span>def <span class="ident">forward</span></span>(<span>self, imgs, size=640, augment=False, profile=False) ‑> Callable[..., Any]</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@torch.no_grad()
def forward(self, imgs, size=640, augment=False, profile=False):
    # Inference from various sources. For height=640, width=1280, RGB images example inputs are:
    #   filename:   imgs = &#39;data/images/zidane.jpg&#39;
    #   URI:             = &#39;https://github.com/ultralytics/yolov5/releases/download/v1.0/zidane.jpg&#39;
    #   OpenCV:          = cv2.imread(&#39;image.jpg&#39;)[:,:,::-1]  # HWC BGR to RGB x(640,1280,3)
    #   PIL:             = Image.open(&#39;image.jpg&#39;)  # HWC x(640,1280,3)
    #   numpy:           = np.zeros((640,1280,3))  # HWC
    #   torch:           = torch.zeros(16,3,320,640)  # BCHW (scaled to size=640, 0-1 values)
    #   multiple:        = [Image.open(&#39;image1.jpg&#39;), Image.open(&#39;image2.jpg&#39;), ...]  # list of images

    t = [time_synchronized()]
    p = next(self.model.parameters())  # for device and type
    if isinstance(imgs, torch.Tensor):  # torch
        with amp.autocast(enabled=p.device.type != &#34;cpu&#34;):
            return self.model(
                imgs.to(p.device).type_as(p), augment, profile
            )  # inference

    # Pre-process
    n, imgs = (
        (len(imgs), imgs) if isinstance(imgs, list) else (1, [imgs])
    )  # number of images, list of images
    shape0, shape1, files = [], [], []  # image and inference shapes, filenames
    for i, im in enumerate(imgs):
        f = f&#34;image{i}&#34;  # filename
        if isinstance(im, str):  # filename or uri
            im, f = (
                np.asarray(
                    Image.open(
                        requests.get(im, stream=True).raw
                        if im.startswith(&#34;http&#34;)
                        else im
                    )
                ),
                im,
            )
        elif isinstance(im, Image.Image):  # PIL Image
            im, f = np.asarray(im), getattr(im, &#34;filename&#34;, f) or f
        files.append(Path(f).with_suffix(&#34;.jpg&#34;).name)
        if im.shape[0] &lt; 5:  # image in CHW
            im = im.transpose((1, 2, 0))  # reverse dataloader .transpose(2, 0, 1)
        im = (
            im[:, :, :3] if im.ndim == 3 else np.tile(im[:, :, None], 3)
        )  # enforce 3ch input
        s = im.shape[:2]  # HWC
        shape0.append(s)  # image shape
        g = size / max(s)  # gain
        shape1.append([y * g for y in s])
        imgs[i] = im if im.data.contiguous else np.ascontiguousarray(im)  # update
    shape1 = [
        make_divisible(x, int(self.stride.max()))
        for x in np.stack(shape1, 0).max(0)
    ]  # inference shape
    x = [letterbox(im, new_shape=shape1, auto=False)[0] for im in imgs]  # pad
    x = np.stack(x, 0) if n &gt; 1 else x[0][None]  # stack
    x = np.ascontiguousarray(x.transpose((0, 3, 1, 2)))  # BHWC to BCHW
    x = torch.from_numpy(x).to(p.device).type_as(p) / 255.0  # uint8 to fp16/32
    t.append(time_synchronized())

    with amp.autocast(enabled=p.device.type != &#34;cpu&#34;):
        # Inference
        y = self.model(x, augment, profile)[0]  # forward
        t.append(time_synchronized())

        # Post-process
        y = non_max_suppression(
            y, conf_thres=self.conf, iou_thres=self.iou, classes=self.classes
        )  # NMS
        for i in range(n):
            scale_coords(shape1, y[i][:, :4], shape0[i])

        t.append(time_synchronized())
        return Detections(imgs, y, files, t, self.names, x.shape)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pancake.models" href="index.html">pancake.models</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pancake.models.common.DWConv" href="#pancake.models.common.DWConv">DWConv</a></code></li>
<li><code><a title="pancake.models.common.autopad" href="#pancake.models.common.autopad">autopad</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pancake.models.common.Bottleneck" href="#pancake.models.common.Bottleneck">Bottleneck</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.Bottleneck.dump_patches" href="#pancake.models.common.Bottleneck.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.Bottleneck.forward" href="#pancake.models.common.Bottleneck.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.Bottleneck.training" href="#pancake.models.common.Bottleneck.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.BottleneckCSP" href="#pancake.models.common.BottleneckCSP">BottleneckCSP</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.BottleneckCSP.dump_patches" href="#pancake.models.common.BottleneckCSP.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.BottleneckCSP.forward" href="#pancake.models.common.BottleneckCSP.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.BottleneckCSP.training" href="#pancake.models.common.BottleneckCSP.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.C3" href="#pancake.models.common.C3">C3</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.C3.dump_patches" href="#pancake.models.common.C3.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.C3.forward" href="#pancake.models.common.C3.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.C3.training" href="#pancake.models.common.C3.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.C3TR" href="#pancake.models.common.C3TR">C3TR</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.C3TR.dump_patches" href="#pancake.models.common.C3TR.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.C3TR.training" href="#pancake.models.common.C3TR.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.Classify" href="#pancake.models.common.Classify">Classify</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.Classify.dump_patches" href="#pancake.models.common.Classify.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.Classify.forward" href="#pancake.models.common.Classify.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.Classify.training" href="#pancake.models.common.Classify.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.Concat" href="#pancake.models.common.Concat">Concat</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.Concat.dump_patches" href="#pancake.models.common.Concat.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.Concat.forward" href="#pancake.models.common.Concat.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.Concat.training" href="#pancake.models.common.Concat.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.Contract" href="#pancake.models.common.Contract">Contract</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.Contract.dump_patches" href="#pancake.models.common.Contract.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.Contract.forward" href="#pancake.models.common.Contract.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.Contract.training" href="#pancake.models.common.Contract.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.Conv" href="#pancake.models.common.Conv">Conv</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.Conv.dump_patches" href="#pancake.models.common.Conv.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.Conv.forward" href="#pancake.models.common.Conv.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.Conv.fuseforward" href="#pancake.models.common.Conv.fuseforward">fuseforward</a></code></li>
<li><code><a title="pancake.models.common.Conv.training" href="#pancake.models.common.Conv.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.Detections" href="#pancake.models.common.Detections">Detections</a></code></h4>
<ul class="two-column">
<li><code><a title="pancake.models.common.Detections.crop" href="#pancake.models.common.Detections.crop">crop</a></code></li>
<li><code><a title="pancake.models.common.Detections.display" href="#pancake.models.common.Detections.display">display</a></code></li>
<li><code><a title="pancake.models.common.Detections.pandas" href="#pancake.models.common.Detections.pandas">pandas</a></code></li>
<li><code><a title="pancake.models.common.Detections.print" href="#pancake.models.common.Detections.print">print</a></code></li>
<li><code><a title="pancake.models.common.Detections.render" href="#pancake.models.common.Detections.render">render</a></code></li>
<li><code><a title="pancake.models.common.Detections.save" href="#pancake.models.common.Detections.save">save</a></code></li>
<li><code><a title="pancake.models.common.Detections.show" href="#pancake.models.common.Detections.show">show</a></code></li>
<li><code><a title="pancake.models.common.Detections.tolist" href="#pancake.models.common.Detections.tolist">tolist</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.Expand" href="#pancake.models.common.Expand">Expand</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.Expand.dump_patches" href="#pancake.models.common.Expand.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.Expand.forward" href="#pancake.models.common.Expand.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.Expand.training" href="#pancake.models.common.Expand.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.Focus" href="#pancake.models.common.Focus">Focus</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.Focus.dump_patches" href="#pancake.models.common.Focus.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.Focus.forward" href="#pancake.models.common.Focus.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.Focus.training" href="#pancake.models.common.Focus.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.NMS" href="#pancake.models.common.NMS">NMS</a></code></h4>
<ul class="two-column">
<li><code><a title="pancake.models.common.NMS.classes" href="#pancake.models.common.NMS.classes">classes</a></code></li>
<li><code><a title="pancake.models.common.NMS.conf" href="#pancake.models.common.NMS.conf">conf</a></code></li>
<li><code><a title="pancake.models.common.NMS.dump_patches" href="#pancake.models.common.NMS.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.NMS.forward" href="#pancake.models.common.NMS.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.NMS.iou" href="#pancake.models.common.NMS.iou">iou</a></code></li>
<li><code><a title="pancake.models.common.NMS.training" href="#pancake.models.common.NMS.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.SPP" href="#pancake.models.common.SPP">SPP</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.SPP.dump_patches" href="#pancake.models.common.SPP.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.SPP.forward" href="#pancake.models.common.SPP.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.SPP.training" href="#pancake.models.common.SPP.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.TransformerBlock" href="#pancake.models.common.TransformerBlock">TransformerBlock</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.TransformerBlock.dump_patches" href="#pancake.models.common.TransformerBlock.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.TransformerBlock.forward" href="#pancake.models.common.TransformerBlock.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.TransformerBlock.training" href="#pancake.models.common.TransformerBlock.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.TransformerLayer" href="#pancake.models.common.TransformerLayer">TransformerLayer</a></code></h4>
<ul class="">
<li><code><a title="pancake.models.common.TransformerLayer.dump_patches" href="#pancake.models.common.TransformerLayer.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.TransformerLayer.forward" href="#pancake.models.common.TransformerLayer.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.TransformerLayer.training" href="#pancake.models.common.TransformerLayer.training">training</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="pancake.models.common.autoShape" href="#pancake.models.common.autoShape">autoShape</a></code></h4>
<ul class="two-column">
<li><code><a title="pancake.models.common.autoShape.autoshape" href="#pancake.models.common.autoShape.autoshape">autoshape</a></code></li>
<li><code><a title="pancake.models.common.autoShape.classes" href="#pancake.models.common.autoShape.classes">classes</a></code></li>
<li><code><a title="pancake.models.common.autoShape.conf" href="#pancake.models.common.autoShape.conf">conf</a></code></li>
<li><code><a title="pancake.models.common.autoShape.dump_patches" href="#pancake.models.common.autoShape.dump_patches">dump_patches</a></code></li>
<li><code><a title="pancake.models.common.autoShape.forward" href="#pancake.models.common.autoShape.forward">forward</a></code></li>
<li><code><a title="pancake.models.common.autoShape.iou" href="#pancake.models.common.autoShape.iou">iou</a></code></li>
<li><code><a title="pancake.models.common.autoShape.training" href="#pancake.models.common.autoShape.training">training</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>