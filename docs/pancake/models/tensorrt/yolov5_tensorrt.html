<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pancake.models.tensorrt.yolov5_tensorrt API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pancake.models.tensorrt.yolov5_tensorrt</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python"># import numpy as np
# import os
# import pkg_resources

# import pycuda.driver as cuda
# import pycuda.autoinit
# import torch
# import torch.nn as nn
# from typing import Type


# from pancake.logger import setup_logger
# from pancake.models.base_class import BaseModel
# from pancake.utils.general import export_onnx, check_requirements

# l = setup_logger(__name__)

# for package in [&#34;tensorrt&#34;]:
#     try:
#         dist = pkg_resources.get_distribution(package)
#         l.info(&#34;\u2713 &#34; + &#34;{} ({}) is installed&#34;.format(dist.key, dist.version))
#         import tensorrt as trt

#         trt_installed = True

#         TRT_LOGGER = trt.Logger(trt.Logger.ERROR)
#         EXPLICIT_BATCH = 1 &lt;&lt; (int)(trt.NetworkDefinitionCreationFlag.EXPLICIT_BATCH)
#     except pkg_resources.DistributionNotFound:
#         l.info(&#34;\u2620 &#34; + &#34;{} is NOT installed&#34;.format(package))
#         trt_installed = False


# class Yolov5TRT(BaseModel):
#     def __init__(self, yolov5, weights_path):
#         # if trt not available return standard yolov5 model
#         if not trt_installed:
#             l.info(&#34;TensorRT not installed, using standard Yolov5..&#34;)
#             return yolov5

#         self.yolov5 = yolov5
#         self._required_img_size = self.yolov5._required_img_size
#         self._stride = self.yolov5._stride

#         # TRT currently only supports non-batch inference
#         self._batch_size = 1
#         x = self._required_img_size

#         input_tensor = (
#             torch.zeros(self._batch_size, 3, x, x).float().to(self.yolov5._device)
#         )

#         onnx_path = (
#             weights_path.replace(&#34;.pt&#34;, &#34;.onnx&#34;)
#             if type(weights_path) is str
#             else weights_path[0].replace(&#34;.pt&#34;, &#34;.onnx&#34;)
#         )

#         weights_name = onnx_path.split(&#34;/&#34;)[-1].split(&#34;.&#34;)[0]

#         l.info(f&#34;Converting PyTorch model from weights {weights_name} to ONNX&#34;)

#         if not export_onnx(
#             self._init_export(), onnx_path, input_tensor, dynamic_axes=False
#         ):
#             l.info(&#34;Couldn&#39;t convert to ONNX, using standard Yolov5..&#34;)
#             return self.yolov5

#         # TRT init

#         # NMS on GPU
#         # max supported is 4096, if conf_thres is low, such as 0.001, use larger number.
#         self._topK = 512
#         self._keepTopK = 300  # max detections on nms

#         check_requirements([&#34;pycuda&#34;])

#         self.build_engine(onnx_path)
#         self.allocate_buffers()

#         # warm up
#         img = Yolov5TRT.prep_image_infer(input_tensor)
#         import time

#         for _ in range(10):
#             t1 = time.time()
#             self.infer(img)
#             print(f&#34;Inf time: {time.time()-t1:.2f}&#34;)

#     def _init_export(self):
#         from pancake.utils.activations import Hardswish, SiLU
#         from pancake.models.yolo import Detect
#         from pancake.models.common import Conv

#         assert self.yolov5
#         model = self.yolov5.model.float()

#         for k, m in model.named_modules():
#             m._non_persistent_buffers_set = set()  # pytorch 1.6.0 compatibility
#             if isinstance(m, Conv):  # assign export-friendly activations
#                 if isinstance(m.act, nn.Hardswish):
#                     m.act = Hardswish()
#                 elif isinstance(m.act, nn.SiLU):
#                     m.act = SiLU()
#             elif isinstance(m, Detect):
#                 m.inplace = opt.inplace
#                 m.onnx_dynamic = opt.dynamic

#         return model

#     def _init_infer(self, img_size):
#         pass

#     @staticmethod
#     def prep_image_infer(img: Type[np.array]) -&gt; Type[np.array]:
#         &#34;&#34;&#34;
#         Preprocesses images for inference (expanded dim (,4), half precision (fp16), normalized)

#         :param img: padded and resized image
#         :return prep_img: preprocessed image
#         &#34;&#34;&#34;
#         if type(img) is torch.Tensor:
#             img = img.cpu().numpy()
#         img = img.astype(np.float32)
#         img /= 255.0
#         if len(img.shape) &lt; 4:
#             img = np.expand_dims(img, axis=0)
#         img = np.ascontiguousarray(img)
#         return img

#     def infer(self, img: Type[np.array]) -&gt; Type[np.array]:
#         &#34;&#34;&#34;
#         :param img (np.array): resized and padded image [bs, 3, width, height]

#         :return pred (tensor): list of detections, on (,6) tensor [xyxy, conf, cls]
#                 img (tensor): preprocessed image 4d tensor [, R, G, B] (on device,
#                               expanded dim (,4), half precision (fp16))
#         &#34;&#34;&#34;
#         # Prepare img for inference
#         img = Yolov5TRT.prep_image_infer(img)
#         # img = torch.from_numpy(img).float().numpy()

#         assert self.engine, &#34;TRT engine hasn&#39;t been initialized yet!&#34;

#         stream = cuda.Stream()
#         with self.engine.create_execution_context() as context:
#             self.inputs[0].host = img

#             [  # put data on gpu
#                 cuda.memcpy_htod_async(inp.device, inp.host, stream)
#                 for inp in self.inputs
#             ]
#             stream.synchronize()

#             # actual inference
#             context.execute_async_v2(
#                 bindings=self.bindings, stream_handle=stream.handle
#             )
#             stream.synchronize()

#             [  # retrieve results
#                 cuda.memcpy_dtoh_async(out.host, out.device, stream)
#                 for out in self.outputs
#             ]
#             stream.synchronize()

#             num_det = int(self.outputs[0].host[0, ...])
#             boxes = np.array(self.outputs[1].host).reshape(self._batch_size, -1, 4)[
#                 0, 0:num_det, 0:4
#             ]
#             scores = np.array(self.outputs[2].host).reshape(self._batch_size, -1, 1)[
#                 0, 0:num_det, 0:1
#             ]
#             classes = np.array(self.outputs[3].host).reshape(self._batch_size, -1, 1)[
#                 0, 0:num_det, 0:1
#             ]

#             return [np.concatenate([boxes, scores, classes], -1)], img

#     def build_engine(self, onnx_path, using_half: bool = True):
#         trt.init_libnvinfer_plugins(None, &#34;&#34;)
#         engine_file = onnx_path.replace(&#34;.onnx&#34;, &#34;.trt&#34;)
#         num_classes = len(self.yolov5.names)

#         # read existing trt engine
#         if os.path.exists(engine_file):
#             engine_exists = True
#             l.info(f&#34;Found a corresponding TRT engine at {engine_file}&#34;)
#             with open(engine_file, &#34;rb&#34;) as f, trt.Runtime(TRT_LOGGER) as runtime:
#                 self.engine = runtime.deserialize_cuda_engine(f.read())
#                 return

#         with trt.Builder(TRT_LOGGER) as builder, builder.create_network(
#             EXPLICIT_BATCH
#         ) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:
#             builder.max_batch_size = 1  # always 1 for explicit batch
#             config = builder.create_builder_config()
#             config.max_workspace_size = 1 * 1 &lt;&lt; 30
#             if using_half:
#                 config.set_flag(trt.BuilderFlag.FP16)

#             # Load the Onnx model and parse it in order to populate the TensorRT network.
#             with open(onnx_path, &#34;rb&#34;) as model:
#                 if not parser.parse(model.read()):
#                     l.info(
#                         &#34;ERROR: Failed to parse the ONNX file, using standard Yolov5..&#34;
#                     )
#                     for error in range(parser.num_errors):
#                         l.info(parser.get_error(error))
#                     return self.yolov5

#             previous_output = network.get_output(0)
#             network.unmark_output(previous_output)

#             # slice boxes, obj_score, class_scores
#             strides = trt.Dims([1, 1, 1])
#             starts = trt.Dims([0, 0, 0])
#             bs, num_boxes, _ = previous_output.shape
#             shapes = trt.Dims([bs, num_boxes, 4])
#             boxes = network.add_slice(previous_output, starts, shapes, strides)
#             starts[2] = 4
#             shapes[2] = 1
#             obj_score = network.add_slice(previous_output, starts, shapes, strides)
#             starts[2] = 5
#             shapes[2] = num_classes
#             scores = network.add_slice(previous_output, starts, shapes, strides)

#             indices = network.add_constant(
#                 trt.Dims([num_classes]), trt.Weights(np.zeros(num_classes, np.int32))
#             )
#             gather_layer = network.add_gather(
#                 obj_score.get_output(0), indices.get_output(0), 2
#             )

#             # scores = obj_score * class_scores =&gt; [bs, num_boxes, nc]
#             updated_scores = network.add_elementwise(
#                 gather_layer.get_output(0),
#                 scores.get_output(0),
#                 trt.ElementWiseOperation.PROD,
#             )

#             # reshape box to [bs, num_boxes, 1, 4]
#             reshaped_boxes = network.add_shuffle(boxes.get_output(0))
#             reshaped_boxes.reshape_dims = trt.Dims([0, 0, 1, 4])

#             # add batchedNMSPlugin, inputs:[boxes:(bs, num, 1, 4), scores:(bs, num, 1)]
#             trt.init_libnvinfer_plugins(TRT_LOGGER, &#34;&#34;)
#             registry = trt.get_plugin_registry()
#             assert registry
#             creator = registry.get_plugin_creator(&#34;BatchedNMS_TRT&#34;, &#34;1&#34;)
#             assert creator
#             fc = []
#             fc.append(
#                 trt.PluginField(
#                     &#34;shareLocation&#34;,
#                     np.array([1], dtype=np.int),
#                     trt.PluginFieldType.INT32,
#                 )
#             )
#             fc.append(
#                 trt.PluginField(
#                     &#34;backgroundLabelId&#34;,
#                     np.array([-1], dtype=np.int),
#                     trt.PluginFieldType.INT32,
#                 )
#             )
#             fc.append(
#                 trt.PluginField(
#                     &#34;numClasses&#34;,
#                     np.array([num_classes], dtype=np.int),
#                     trt.PluginFieldType.INT32,
#                 )
#             )
#             fc.append(
#                 trt.PluginField(
#                     &#34;topK&#34;,
#                     np.array([self._topK], dtype=np.int),
#                     trt.PluginFieldType.INT32,
#                 )
#             )
#             fc.append(
#                 trt.PluginField(
#                     &#34;keepTopK&#34;,
#                     np.array([self._keepTopK], dtype=np.int),
#                     trt.PluginFieldType.INT32,
#                 )
#             )
#             fc.append(
#                 trt.PluginField(
#                     &#34;scoreThreshold&#34;,
#                     np.array([self.yolov5._conf_thres], dtype=np.float32),
#                     trt.PluginFieldType.FLOAT32,
#                 )
#             )
#             fc.append(
#                 trt.PluginField(
#                     &#34;iouThreshold&#34;,
#                     np.array([self.yolov5._iou_thres], dtype=np.float32),
#                     trt.PluginFieldType.FLOAT32,
#                 )
#             )
#             fc.append(
#                 trt.PluginField(
#                     &#34;isNormalized&#34;,
#                     np.array([0], dtype=np.int),
#                     trt.PluginFieldType.INT32,
#                 )
#             )
#             fc.append(
#                 trt.PluginField(
#                     &#34;clipBoxes&#34;, np.array([0], dtype=np.int), trt.PluginFieldType.INT32
#                 )
#             )

#             fc = trt.PluginFieldCollection(fc)
#             nms_layer = creator.create_plugin(&#34;nms_layer&#34;, fc)

#             layer = network.add_plugin_v2(
#                 [reshaped_boxes.get_output(0), updated_scores.get_output(0)], nms_layer
#             )
#             layer.get_output(0).name = &#34;num_detections&#34;
#             layer.get_output(1).name = &#34;nmsed_boxes&#34;
#             layer.get_output(2).name = &#34;nmsed_scores&#34;
#             layer.get_output(3).name = &#34;nmsed_classes&#34;
#             for i in range(4):
#                 network.mark_output(layer.get_output(i))

#             # build new trt engine
#             self.engine = builder.build_engine(network, config)

#             # serialize and store the engine
#             with open(engine_file, &#34;wb&#34;) as f:
#                 f.write(self.engine.serialize())

#                 from pancake.utils.general import file_size

#                 l.info(
#                     f&#34;TRT engine export success, saved as {engine_file} ({file_size(engine_file):.1f} MB)&#34;
#                 )

#     def allocate_buffers(self, is_explicit_batch=True, dynamic_shapes=[]):
#         self.inputs = []
#         self.outputs = []
#         self.bindings = []

#         class HostDeviceMem(object):
#             def __init__(self, host_mem, device_mem):
#                 self.host = host_mem
#                 self.device = device_mem

#             def __str__(self):
#                 return &#34;Host:\n&#34; + str(self.host) + &#34;\nDevice:\n&#34; + str(self.device)

#             def __repr__(self):
#                 return self.__str__()

#         for binding in self.engine:
#             dims = self.engine.get_binding_shape(binding)
#             l.debug(f&#34;Layer &#39;{binding}&#39; dim: {dims}&#34;)
#             if dims[0] == -1:
#                 assert len(dynamic_shapes) &gt; 0
#                 dims[0] = dynamic_shapes[0]
#             size = trt.volume(dims) * self.engine.max_batch_size
#             dtype = trt.nptype(self.engine.get_binding_dtype(binding))
#             # Allocate host and device buffers
#             host_mem = cuda.pagelocked_empty(size, dtype)
#             device_mem = cuda.mem_alloc(host_mem.nbytes)
#             # Append the device buffer to device bindings.
#             self.bindings.append(int(device_mem))
#             # Append to the appropriate list.
#             if self.engine.binding_is_input(binding):
#                 self.inputs.append(HostDeviceMem(host_mem, device_mem))
#             else:
#                 self.outputs.append(HostDeviceMem(host_mem, device_mem))</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pancake.models.tensorrt" href="index.html">pancake.models.tensorrt</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>