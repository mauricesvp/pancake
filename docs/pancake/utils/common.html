<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>pancake.utils.common API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>pancake.utils.common</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os
import sys
from datetime import datetime
from typing import Type, List, Union

import cv2
import numpy as np
import torch

from pancake.models.base_class import BaseModel

from .datasets import LoadStreams, LoadImages, LoadWebcam, LoadImageDirs
from .general import (
    check_img_size,
    scale_coords,
    check_imshow,
    resize_aspectratio,
    check_requirements,
)
from .plots import colors, plot_one_box
from .torch_utils import time_synchronized


def load_data(source: str) -&gt; Union[LoadStreams, LoadImages, LoadImageDirs]:
    &#34;&#34;&#34;
    :param source (str): data source (webcam, image, video, directory, glob, youtube video, HTTP stream)
    &#34;&#34;&#34;
    try:
        is_webcam = (
            source.isnumeric()
            or source.endswith(&#34;.txt&#34;)
            or source.lower().startswith((&#34;rtsp://&#34;, &#34;rtmp://&#34;, &#34;http://&#34;, &#34;https://&#34;))
        )
    except AttributeError:
        is_webcam = False

    finally:
        if is_webcam:
            return (
                LoadStreams(source),
                True,
            )
        elif type(source) is list:
            return (
                LoadImageDirs(source),
                False,
            )
        else:
            return (
                LoadImages(source),
                False,
            )


def setup_result_processor(config: dict, labels: list):
    return ResultProcessor(
        show_res=config.VIEW_RES,
        save_res=config.SAVE_RES,
        draw_det=config.DRAW_DET,
        draw_tracks=config.DRAW_TRACKS,
        draw_track_hist=config.DRAW_TRACK_HIST,
        track_hist_size=config.MAX_TRACK_HIST_LEN,
        labels=labels,
        hide_labels=config.HIDE_LABELS,
        hide_conf=config.HIDE_CONF,
        line_thickness=config.LINE_THICKNESS,
        save_mode=config.MODE,
        path=config.PATH,
        subdir=config.SUBDIR,
        exist_ok=config.EXIST_OK,
        vid_fps=config.VID_FPS,
        async_processing=config.ASYNC_PROC,
        async_queue_size=config.Q_SIZE,
        async_put_blocked=config.PUT_BLOCKED,
        async_put_timeout=config.PUT_TIMEOUT,
        debug=config.DEBUG,
    )


class ResultProcessor:
    def __init__(
        self,
        show_res: bool,
        save_res: bool,
        draw_det: bool,
        draw_tracks: bool,
        draw_track_hist: bool,
        track_hist_size: int,
        labels: list,
        hide_labels: bool,
        hide_conf: bool,
        line_thickness: int,
        save_mode: str,
        path: str,
        subdir: str,
        exist_ok: bool,
        async_processing: bool,
        async_queue_size: int,
        async_put_blocked: bool,
        async_put_timeout: float,
        debug: bool,
        *args,
        **kwargs,
    ):
        &#34;&#34;&#34;
        :param show_res (bool):         if resulting images should be visualized live
        :param save_res (bool):         if resulting images should be saved
        :param draw_det (bool):         if detection bbox&#39; should be visualized
        :param draw_tracks (bool):      if tracked object bbox&#39; should be visualized
        :param draw_track_hist (bool):  if track histories should be saved and visualized
        :param track_hist_size (int):   maximum size of the track hist container
        :param labels (list):           list of model specific class labels
        :param hide_labels (bool):      if labels should be visualized
        :param hide_conf (bool):        if confidences should be visualized
        :param line_thickness (int):    line thickness
        :param save_mode (str):         &#34;image&#34; or &#34;video&#34;
        :param path (str):              parent target directory
        :param subdir (str):            target subdirectory
        :param exist_ok (str):          save in results in already existing dir
                                        do not increment automatically
        :param async_processing (bool): (non-blocking) asynchronous result processing in a
                                        seperate slave process
        :param async_queue_size (int):  queue size for results sent by .process() to subprocess
        :param async_put_blocked (bool): blocks .process() for timeout sec until free slot
                                         available, if False skip the current frame without
                                         blocking
        :param async_put_timeout (float): raise exception after timeout s waiting for free slot
        :param debug (bool):            manual skipping when visualizing results
        &#34;&#34;&#34;
        from pancake.run import setup_logger

        self.l = setup_logger(__name__)

        # GENERAL
        self._show_res, self._save_res, self._debug, self._async = (
            False,
            save_res,
            debug,
            async_processing,
        )
        if show_res:
            self._show_res = True if check_imshow() else False

        # DRAW OPTIONS
        self._show_det, self._show_tracks, self._show_track_hist = (
            draw_det,
            draw_tracks,
            draw_track_hist,
        )
        # DRAW DETAILS
        self._hide_labels, self._hide_conf = hide_labels, hide_conf
        self._line_thickness = line_thickness
        # CLASS LABELS
        self._labels = labels

        # NEITHER SHOW RES OR SAVE RES IS ENABLED
        if not self._show_res and not self._save_res:
            self.l.info(&#34;No result processing procedure will be taking place&#34;)

            def nop(*args, **kwargs):
                return

            self.process = nop
            self.kill_worker = nop
            return

        # INIT TRACK HISTORY
        if self._show_track_hist:

            class TrackHistory:
                &#34;&#34;&#34;Track History Wrapper
                - store the latest tracking results
                - assign each tracked ID its center positions (x, y)
                &#34;&#34;&#34;

                def __init__(self, max_hist_len: int):
                    self.tracks = []
                    self.ids = {}
                    self._max_hist_len = max_hist_len

                def update(self, tracks):
                    if len(self.tracks) &gt; self._max_hist_len:
                        self.tracks = []
                        self.ids = {}

                    self.tracks.append(tracks)
                    curr_ids = []
                    for *_, x, y, id, _ in tracks:
                        if id not in self.ids.keys():
                            self.ids.update({id: [(x, y)]})
                        else:
                            self.ids[id].append((x, y))
                        curr_ids.append(id)

            self.track_history = TrackHistory(max_hist_len=track_hist_size)

        # INIT SAVING
        if self._save_res:
            assert save_mode == &#34;video&#34; or save_mode == &#34;image&#34;
            from .general import increment_path
            from pathlib import Path

            self._mode = save_mode

            self._save_dir = increment_path(Path(path) / subdir, exist_ok, sep=&#34;_&#34;)
            self._save_dir.mkdir(parents=True, exist_ok=True)

            self.vid_path, self.vid_writer, self._fps = (
                None,
                None,
                kwargs[&#34;vid_fps&#34;] if &#34;vid_fps&#34; in kwargs.keys() else None,
            )

        # INIT ASYNC RESULT PROCESSING
        if self._async:
            import multiprocessing

            check_requirements([&#34;pathos&#34;])
            from pathos.helpers import mp

            assert (
                not self._show_res and self._async
            ), &#34;Results can&#39;t be visualized from slave process, disable &#39;VIEW_IMG&#39; or &#39;ASYNC_PROC&#39;!&#34;
            assert (
                multiprocessing.cpu_count() &gt; 1
            ), &#34;Only 1 CPU core available, might not be able to leverage multiprocessing module!&#34;

            self._queue_size = async_queue_size
            self._put_blocked = async_put_blocked
            self._put_timeout = async_put_timeout

            # Queue to put and pull results
            self.queue = mp.Queue(maxsize=self._queue_size)

            # init and start worker process
            self.l.info(&#34;Starting slave process to work on the results&#34;)
            self.worker_process = mp.Process(target=self.async_update_worker, args=())
            self.worker_process.start()

    def process(
        self,
        det: Type[torch.Tensor],
        tracks: Type[np.array],
        im0: Type[np.array],
        vid_cap: Type[cv2.VideoCapture] = None,
    ):
        &#34;&#34;&#34;
        Wraps the procedure for asynchronous and synchronous result processing.

        :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
        :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
        :param im0 (array): image in BGR (,3) [3, w, h]
        :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
        &#34;&#34;&#34;
        if self._async:
            assert self.worker_process.is_alive(), &#34;Worker process died!&#34;

            if round(self.queue.qsize() / self._queue_size, 1) == 0.9:
                self.l.warn(
                    &#34;Queue size capacity almost full.. &#34;
                    f&#34;({(self.queue.qsize()/self._queue_size) * 100:.2f})&#34;
                )

            if not self._put_blocked and self.queue.full():
                return

            # self.queue.put([det, tracks, im0, vid_cap])
            self.queue.put(
                [det, tracks, im0], block=self._put_blocked, timeout=self._put_timeout
            )
        else:
            # self.update(det, tracks, im0, vid_cap)
            self.update(det, tracks, im0)

    def update(
        self,
        det: Type[torch.Tensor],
        tracks: Type[np.array],
        im0: Type[np.array],
        vid_cap: Type[cv2.VideoCapture] = None,
    ):
        &#34;&#34;&#34;
        Takes the provided results from a detector and tracker in order to visualize
        them according to user config. Subsequently, visualizes and/or stores the
        enriched image/video.

        :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
        :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
        :param im0 (array): image in BGR (,3) [3, w, h]
        :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
        &#34;&#34;&#34;
        if self._show_det:
            im0 = self.draw_detec_boxes(det, im0)
        if self._show_tracks:
            im0 = self.draw_track_boxes(tracks, im0)
        if self._show_track_hist:
            im0 = self.draw_track_hist(tracks, im0)

        if self._show_res:
            self.visualize(im0)

        if self._save_res:
            if self._mode == &#34;image&#34;:
                self.save_img(im0)
            else:
                self.save_vid(im0)

    def async_update_worker(self):
        &#34;&#34;&#34;
        Main loop of the slave process
        &#34;&#34;&#34;
        assert self.queue, &#34;Queue is not initialized!&#34;
        import traceback

        try:
            while 1:
                try:
                    data = self.queue.get()
                except:
                    self.reset_vid_writer()
                    self.queue.close()
                    break

                # deserialize data, data: list, [detections, tracks, image, vid cap]
                # det, tracks, im0, vid_cap = data[0], data[1], data[2], data[3]
                det, tracks, im0 = data[0], data[1], data[2]

                self.update(det, tracks, im0)
        except:
            self.l.fatal(&#34;Exception in subprocess occured!&#34;)
            traceback.print_exc()

    def kill_worker(self):
        &#34;&#34;&#34;
        Procedure for cleanly closing the communication pipes and terminating
        the worker process.
        &#34;&#34;&#34;
        self.queue.close()
        self.worker_process.terminate()

    def draw_detec_boxes(self, det: Type[torch.Tensor], im0: Type[np.array]):
        &#34;&#34;&#34;
        Draws bounding boxes, class labels and confidences according to a
        detection matix on the provided image.

        :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
        :param im0 (ndarray): image in BGR [3, w, h]
        &#34;&#34;&#34;
        for *xyxy, conf, cls in reversed(det):
            # Add bbox to image
            c = int(cls)  # integer class
            label = (
                None
                if self._hide_labels
                else (
                    self._labels[c]
                    if self._hide_conf
                    else f&#34;{self._labels[c]} {conf:.2f}&#34;
                )
            )

            plot_one_box(
                xyxy,
                im0,
                label=label,
                color=colors(c, True),
                line_thickness=self._line_thickness,
            )
        return im0

    def draw_track_boxes(self, tracks: Type[np.array], im0: Type[np.array]):
        &#34;&#34;&#34;
        Draws bounding boxes, tracking ids according to &#39;tracks&#39; matix on the provided image.

        :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id, cls]
        :param im0 (array): image in BGR [3, px, px]
        &#34;&#34;&#34;
        for *xyxy, _, _, id, _ in tracks:
            id = None if self._hide_labels else str(id)
            plot_one_box(
                xyxy,
                im0,
                label=id,
                color=colors(int(id), True),
                line_thickness=self._line_thickness,
            )
        return im0

    def draw_track_hist(self, tracks: Type[np.array], im0: Type[np.array]):
        &#34;&#34;&#34;
        Draws a line for each tracked ID according to the stored history.

        :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id, cls]
        :param im0 (array): image in BGR [3, px, px]
        &#34;&#34;&#34;
        assert self.track_history, &#34;No track history object initialized!&#34;
        self.track_history.update(tracks)

        for id in self.track_history.ids:
            points = self.track_history.ids[id]
            x0, y0 = points[0]
            for x, y in points[1:]:
                cv2.line(im0, (x0, y0), (x, y), colors(id, True), self._line_thickness)
                x0, y0 = x, y
        return im0

    def save_img(self, im0: Type[np.array]):
        &#34;&#34;&#34;
        :param im0 (ndarray): image in BGR [3, px, px]
        &#34;&#34;&#34;
        now = datetime.now().strftime(&#34;%Y-%m-%d %H:%M:%S.%f&#34;)[:-3]

        # image named after current timestamp
        save_path = str(self._save_dir / now)
        save_path += &#34;.jpg&#34;

        cv2.imwrite(save_path, im0)

    def save_vid(self, im0: Type[np.array], vid_cap: Type[cv2.VideoCapture] = None):
        &#34;&#34;&#34;
        :param im0 (ndarray): image in BGR [3, px, px]
        :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
        &#34;&#34;&#34;
        # resize frame if its too large for .avi
        if im0.shape[1] &gt; 3200:
            im0 = resize_aspectratio(im0, width=3200)

        if not self.vid_path:  # new video
            now = datetime.now().strftime(&#34;%Y-%m-%d %H:%M:%S.%f&#34;)[:-3]
            self.vid_path = str(self._save_dir / now)

            if isinstance(self.vid_writer, cv2.VideoWriter):
                self.vid_writer.release()  # release previous video writer

            # take w, h from input video
            # if vid_cap:  # video
            #     fps = vid_cap.get(cv2.CAP_PROP_FPS)
            #     w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            #     h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            # else:  # images, stream

            # take user defined fps
            fps, w, h = self._fps, im0.shape[1], im0.shape[0]
            self.vid_path += &#34;.avi&#34;

            self.vid_writer = cv2.VideoWriter(
                self.vid_path, cv2.VideoWriter_fourcc(*&#34;XVID&#34;), fps, (w, h)
            )

        self.vid_writer.write(im0)

    def visualize(self, im0: Type[np.array]):
        &#34;&#34;&#34;
        :param im0 (ndarray): image in BGR [3, px, px]
        &#34;&#34;&#34;
        cv2.namedWindow(&#34;Pancake&#34;, cv2.WINDOW_NORMAL)
        cv2.imshow(&#34;Pancake&#34;, im0)
        cv2.waitKey(0 if self._debug else 1)

    def reset_vid_writer(self):
        self.vid_writer.release()
        self.vid_path, self.vid_writer = None, None


def draw_boxes(
    show_det: bool,
    show_tracks: bool,
    im0: Type[np.array],
    hide_labels: bool,
    hide_conf: bool,
    line_thickness: int,
    labels: List = None,
    det: Type[torch.Tensor] = None,
    tracks: Type[np.ndarray] = [],
    track_history: Type[list] = [],
    show_track_history: bool = False,
) -&gt; Type[np.array]:
    &#34;&#34;&#34;
    :param show_det (bool): if detection bbox&#39; should be visualized
    :param show_tracks (bool): if tracked object bbox&#39; should be visualized
    :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
    :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
    :param im0 (array): original image
    :param labels (list): list of model specific class labels
    :param hide_labels (bool): if labels should be visualized
    :param hide_conf (bool): if confidences should be visualized
    :param line_thickness (int): line thickness

    :return (ndarray) image enriched with provided boxes
    &#34;&#34;&#34;
    # Draw boxes
    if show_det:
        for *xyxy, conf, cls in reversed(det):
            # Add bbox to image
            c = int(cls)  # integer class
            label = (
                None
                if hide_labels
                else (labels[c] if hide_conf else f&#34;{labels[c]} {conf:.2f}&#34;)
            )

            plot_one_box(
                xyxy,
                im0,
                label=label,
                color=colors(c, True),
                line_thickness=line_thickness,
            )

    if show_tracks:
        for *xyxy, _, _, id in tracks:
            plot_one_box(
                xyxy,
                im0,
                label=str(id),
                color=colors(int(id), True),
                line_thickness=line_thickness,
            )
    if show_track_history:
        id_hist = {}
        init = True
        for state in track_history:
            for *_, x, y, id in state:
                if init:
                    id_hist.update({id: [(x, y)]})
                elif id not in id_hist:
                    continue
                else:
                    id_hist[id].append((x, y))
            init = False
        for id in id_hist:
            points = id_hist[id]
            x0, y0 = points.pop(0)
            for x, y in points:
                cv2.line(im0, (x0, y0), (x, y), colors(id, True), 5)
                x0, y0 = x, y
    return im0


def visualize(im0: Type[np.array], debug: bool = False) -&gt; None:
    &#34;&#34;&#34;
    :param im0 (array): original image
    :param debug (bool): enables debug stepping
    &#34;&#34;&#34;
    cv2.namedWindow(&#34;Pancake&#34;, cv2.WINDOW_NORMAL)
    cv2.imshow(&#34;Pancake&#34;, im0)
    cv2.waitKey(0 if debug else 1)


def save(
    im0: Type[np.array],
    vid_cap: Type[cv2.VideoCapture] = None,
    vid_fps: int = 30,
    mode: str = &#34;image&#34;,
    path: str = &#34;../pancake_results&#34;,
) -&gt; None:
    &#34;&#34;&#34;
    :param im0 (array): image to save
    :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
    :param vid_fps (int): fixed video frame rate when in video mode
    :param mode (str): &#34;image&#34; or &#34;video&#34;
    :param path (str): target directory
    &#34;&#34;&#34;
    now = datetime.now().strftime(&#34;%Y-%m-%d %H:%M:%S.%f&#34;)[:-3]

    # image named after timestamp
    save_path = str(path / now)

    if mode.lower() == &#34;image&#34;:
        save_path += &#34;.jpg&#34;
        cv2.imwrite(save_path, im0)
    else:  # &#39;video&#39; or &#39;stream&#39;
        if not &#34;vid_path&#34; in globals() or not &#34;vid_writer&#34; in globals():
            globals()[&#34;vid_path&#34;], globals()[&#34;vid_writer&#34;] = None, None

        if im0.shape[1] &gt; 3200:
            im0 = resize_aspectratio(im0, width=3200)

        if not vid_path:  # new video
            globals()[&#34;vid_path&#34;] = save_path

            if isinstance(vid_writer, cv2.VideoWriter):
                vid_writer.release()  # release previous video writer

            if vid_cap:  # video
                fps = vid_cap.get(cv2.CAP_PROP_FPS)
                w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            else:  # images, stream
                fps, w, h = vid_fps, im0.shape[1], im0.shape[0]
                save_path += &#34;.avi&#34;

            globals()[&#34;vid_writer&#34;] = cv2.VideoWriter(
                save_path, cv2.VideoWriter_fourcc(*&#34;XVID&#34;), fps, (w, h)
            )
        vid_writer.write(im0)


def fix_path(path: Union[str, list]) -&gt; str:
    &#34;&#34;&#34;Adjust relative path.&#34;&#34;&#34;
    if type(path) is list:
        return list(map(lambda p: fix_path(p), path))
    return os.path.join(os.path.dirname(__file__), &#34;..&#34;, path)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="pancake.utils.common.draw_boxes"><code class="name flex">
<span>def <span class="ident">draw_boxes</span></span>(<span>show_det: bool, show_tracks: bool, im0: Type[<built-in function array>], hide_labels: bool, hide_conf: bool, line_thickness: int, labels: List = None, det: Type[torch.Tensor] = None, tracks: Type[numpy.ndarray] = [], track_history: Type[list] = [], show_track_history: bool = False) ‑> Type[<built-in function array>]</span>
</code></dt>
<dd>
<div class="desc"><p>:param show_det (bool): if detection bbox' should be visualized
:param show_tracks (bool): if tracked object bbox' should be visualized
:param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
:param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
:param im0 (array): original image
:param labels (list): list of model specific class labels
:param hide_labels (bool): if labels should be visualized
:param hide_conf (bool): if confidences should be visualized
:param line_thickness (int): line thickness</p>
<p>:return (ndarray) image enriched with provided boxes</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def draw_boxes(
    show_det: bool,
    show_tracks: bool,
    im0: Type[np.array],
    hide_labels: bool,
    hide_conf: bool,
    line_thickness: int,
    labels: List = None,
    det: Type[torch.Tensor] = None,
    tracks: Type[np.ndarray] = [],
    track_history: Type[list] = [],
    show_track_history: bool = False,
) -&gt; Type[np.array]:
    &#34;&#34;&#34;
    :param show_det (bool): if detection bbox&#39; should be visualized
    :param show_tracks (bool): if tracked object bbox&#39; should be visualized
    :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
    :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
    :param im0 (array): original image
    :param labels (list): list of model specific class labels
    :param hide_labels (bool): if labels should be visualized
    :param hide_conf (bool): if confidences should be visualized
    :param line_thickness (int): line thickness

    :return (ndarray) image enriched with provided boxes
    &#34;&#34;&#34;
    # Draw boxes
    if show_det:
        for *xyxy, conf, cls in reversed(det):
            # Add bbox to image
            c = int(cls)  # integer class
            label = (
                None
                if hide_labels
                else (labels[c] if hide_conf else f&#34;{labels[c]} {conf:.2f}&#34;)
            )

            plot_one_box(
                xyxy,
                im0,
                label=label,
                color=colors(c, True),
                line_thickness=line_thickness,
            )

    if show_tracks:
        for *xyxy, _, _, id in tracks:
            plot_one_box(
                xyxy,
                im0,
                label=str(id),
                color=colors(int(id), True),
                line_thickness=line_thickness,
            )
    if show_track_history:
        id_hist = {}
        init = True
        for state in track_history:
            for *_, x, y, id in state:
                if init:
                    id_hist.update({id: [(x, y)]})
                elif id not in id_hist:
                    continue
                else:
                    id_hist[id].append((x, y))
            init = False
        for id in id_hist:
            points = id_hist[id]
            x0, y0 = points.pop(0)
            for x, y in points:
                cv2.line(im0, (x0, y0), (x, y), colors(id, True), 5)
                x0, y0 = x, y
    return im0</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.fix_path"><code class="name flex">
<span>def <span class="ident">fix_path</span></span>(<span>path: Union[str, list]) ‑> str</span>
</code></dt>
<dd>
<div class="desc"><p>Adjust relative path.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def fix_path(path: Union[str, list]) -&gt; str:
    &#34;&#34;&#34;Adjust relative path.&#34;&#34;&#34;
    if type(path) is list:
        return list(map(lambda p: fix_path(p), path))
    return os.path.join(os.path.dirname(__file__), &#34;..&#34;, path)</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.load_data"><code class="name flex">
<span>def <span class="ident">load_data</span></span>(<span>source: str) ‑> Union[<a title="pancake.utils.datasets.LoadStreams" href="datasets.html#pancake.utils.datasets.LoadStreams">LoadStreams</a>, <a title="pancake.utils.datasets.LoadImages" href="datasets.html#pancake.utils.datasets.LoadImages">LoadImages</a>, <a title="pancake.utils.datasets.LoadImageDirs" href="datasets.html#pancake.utils.datasets.LoadImageDirs">LoadImageDirs</a>]</span>
</code></dt>
<dd>
<div class="desc"><p>:param source (str): data source (webcam, image, video, directory, glob, youtube video, HTTP stream)</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_data(source: str) -&gt; Union[LoadStreams, LoadImages, LoadImageDirs]:
    &#34;&#34;&#34;
    :param source (str): data source (webcam, image, video, directory, glob, youtube video, HTTP stream)
    &#34;&#34;&#34;
    try:
        is_webcam = (
            source.isnumeric()
            or source.endswith(&#34;.txt&#34;)
            or source.lower().startswith((&#34;rtsp://&#34;, &#34;rtmp://&#34;, &#34;http://&#34;, &#34;https://&#34;))
        )
    except AttributeError:
        is_webcam = False

    finally:
        if is_webcam:
            return (
                LoadStreams(source),
                True,
            )
        elif type(source) is list:
            return (
                LoadImageDirs(source),
                False,
            )
        else:
            return (
                LoadImages(source),
                False,
            )</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.save"><code class="name flex">
<span>def <span class="ident">save</span></span>(<span>im0: Type[<built-in function array>], vid_cap: Type[cv2.VideoCapture] = None, vid_fps: int = 30, mode: str = 'image', path: str = '../pancake_results') ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>:param im0 (array): image to save
:param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
:param vid_fps (int): fixed video frame rate when in video mode
:param mode (str): "image" or "video"
:param path (str): target directory</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save(
    im0: Type[np.array],
    vid_cap: Type[cv2.VideoCapture] = None,
    vid_fps: int = 30,
    mode: str = &#34;image&#34;,
    path: str = &#34;../pancake_results&#34;,
) -&gt; None:
    &#34;&#34;&#34;
    :param im0 (array): image to save
    :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
    :param vid_fps (int): fixed video frame rate when in video mode
    :param mode (str): &#34;image&#34; or &#34;video&#34;
    :param path (str): target directory
    &#34;&#34;&#34;
    now = datetime.now().strftime(&#34;%Y-%m-%d %H:%M:%S.%f&#34;)[:-3]

    # image named after timestamp
    save_path = str(path / now)

    if mode.lower() == &#34;image&#34;:
        save_path += &#34;.jpg&#34;
        cv2.imwrite(save_path, im0)
    else:  # &#39;video&#39; or &#39;stream&#39;
        if not &#34;vid_path&#34; in globals() or not &#34;vid_writer&#34; in globals():
            globals()[&#34;vid_path&#34;], globals()[&#34;vid_writer&#34;] = None, None

        if im0.shape[1] &gt; 3200:
            im0 = resize_aspectratio(im0, width=3200)

        if not vid_path:  # new video
            globals()[&#34;vid_path&#34;] = save_path

            if isinstance(vid_writer, cv2.VideoWriter):
                vid_writer.release()  # release previous video writer

            if vid_cap:  # video
                fps = vid_cap.get(cv2.CAP_PROP_FPS)
                w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            else:  # images, stream
                fps, w, h = vid_fps, im0.shape[1], im0.shape[0]
                save_path += &#34;.avi&#34;

            globals()[&#34;vid_writer&#34;] = cv2.VideoWriter(
                save_path, cv2.VideoWriter_fourcc(*&#34;XVID&#34;), fps, (w, h)
            )
        vid_writer.write(im0)</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.setup_result_processor"><code class="name flex">
<span>def <span class="ident">setup_result_processor</span></span>(<span>config: dict, labels: list)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def setup_result_processor(config: dict, labels: list):
    return ResultProcessor(
        show_res=config.VIEW_RES,
        save_res=config.SAVE_RES,
        draw_det=config.DRAW_DET,
        draw_tracks=config.DRAW_TRACKS,
        draw_track_hist=config.DRAW_TRACK_HIST,
        track_hist_size=config.MAX_TRACK_HIST_LEN,
        labels=labels,
        hide_labels=config.HIDE_LABELS,
        hide_conf=config.HIDE_CONF,
        line_thickness=config.LINE_THICKNESS,
        save_mode=config.MODE,
        path=config.PATH,
        subdir=config.SUBDIR,
        exist_ok=config.EXIST_OK,
        vid_fps=config.VID_FPS,
        async_processing=config.ASYNC_PROC,
        async_queue_size=config.Q_SIZE,
        async_put_blocked=config.PUT_BLOCKED,
        async_put_timeout=config.PUT_TIMEOUT,
        debug=config.DEBUG,
    )</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.visualize"><code class="name flex">
<span>def <span class="ident">visualize</span></span>(<span>im0: Type[<built-in function array>], debug: bool = False) ‑> NoneType</span>
</code></dt>
<dd>
<div class="desc"><p>:param im0 (array): original image
:param debug (bool): enables debug stepping</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def visualize(im0: Type[np.array], debug: bool = False) -&gt; None:
    &#34;&#34;&#34;
    :param im0 (array): original image
    :param debug (bool): enables debug stepping
    &#34;&#34;&#34;
    cv2.namedWindow(&#34;Pancake&#34;, cv2.WINDOW_NORMAL)
    cv2.imshow(&#34;Pancake&#34;, im0)
    cv2.waitKey(0 if debug else 1)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="pancake.utils.common.ResultProcessor"><code class="flex name class">
<span>class <span class="ident">ResultProcessor</span></span>
<span>(</span><span>show_res: bool, save_res: bool, draw_det: bool, draw_tracks: bool, draw_track_hist: bool, track_hist_size: int, labels: list, hide_labels: bool, hide_conf: bool, line_thickness: int, save_mode: str, path: str, subdir: str, exist_ok: bool, async_processing: bool, async_queue_size: int, async_put_blocked: bool, async_put_timeout: float, debug: bool, *args, **kwargs)</span>
</code></dt>
<dd>
<div class="desc"><p>:param show_res (bool):
if resulting images should be visualized live
:param save_res (bool):
if resulting images should be saved
:param draw_det (bool):
if detection bbox' should be visualized
:param draw_tracks (bool):
if tracked object bbox' should be visualized
:param draw_track_hist (bool):
if track histories should be saved and visualized
:param track_hist_size (int):
maximum size of the track hist container
:param labels (list):
list of model specific class labels
:param hide_labels (bool):
if labels should be visualized
:param hide_conf (bool):
if confidences should be visualized
:param line_thickness (int):
line thickness
:param save_mode (str):
"image" or "video"
:param path (str):
parent target directory
:param subdir (str):
target subdirectory
:param exist_ok (str):
save in results in already existing dir
do not increment automatically
:param async_processing (bool): (non-blocking) asynchronous result processing in a
seperate slave process
:param async_queue_size (int):
queue size for results sent by .process() to subprocess
:param async_put_blocked (bool): blocks .process() for timeout sec until free slot
available, if False skip the current frame without
blocking
:param async_put_timeout (float): raise exception after timeout s waiting for free slot
:param debug (bool):
manual skipping when visualizing results</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ResultProcessor:
    def __init__(
        self,
        show_res: bool,
        save_res: bool,
        draw_det: bool,
        draw_tracks: bool,
        draw_track_hist: bool,
        track_hist_size: int,
        labels: list,
        hide_labels: bool,
        hide_conf: bool,
        line_thickness: int,
        save_mode: str,
        path: str,
        subdir: str,
        exist_ok: bool,
        async_processing: bool,
        async_queue_size: int,
        async_put_blocked: bool,
        async_put_timeout: float,
        debug: bool,
        *args,
        **kwargs,
    ):
        &#34;&#34;&#34;
        :param show_res (bool):         if resulting images should be visualized live
        :param save_res (bool):         if resulting images should be saved
        :param draw_det (bool):         if detection bbox&#39; should be visualized
        :param draw_tracks (bool):      if tracked object bbox&#39; should be visualized
        :param draw_track_hist (bool):  if track histories should be saved and visualized
        :param track_hist_size (int):   maximum size of the track hist container
        :param labels (list):           list of model specific class labels
        :param hide_labels (bool):      if labels should be visualized
        :param hide_conf (bool):        if confidences should be visualized
        :param line_thickness (int):    line thickness
        :param save_mode (str):         &#34;image&#34; or &#34;video&#34;
        :param path (str):              parent target directory
        :param subdir (str):            target subdirectory
        :param exist_ok (str):          save in results in already existing dir
                                        do not increment automatically
        :param async_processing (bool): (non-blocking) asynchronous result processing in a
                                        seperate slave process
        :param async_queue_size (int):  queue size for results sent by .process() to subprocess
        :param async_put_blocked (bool): blocks .process() for timeout sec until free slot
                                         available, if False skip the current frame without
                                         blocking
        :param async_put_timeout (float): raise exception after timeout s waiting for free slot
        :param debug (bool):            manual skipping when visualizing results
        &#34;&#34;&#34;
        from pancake.run import setup_logger

        self.l = setup_logger(__name__)

        # GENERAL
        self._show_res, self._save_res, self._debug, self._async = (
            False,
            save_res,
            debug,
            async_processing,
        )
        if show_res:
            self._show_res = True if check_imshow() else False

        # DRAW OPTIONS
        self._show_det, self._show_tracks, self._show_track_hist = (
            draw_det,
            draw_tracks,
            draw_track_hist,
        )
        # DRAW DETAILS
        self._hide_labels, self._hide_conf = hide_labels, hide_conf
        self._line_thickness = line_thickness
        # CLASS LABELS
        self._labels = labels

        # NEITHER SHOW RES OR SAVE RES IS ENABLED
        if not self._show_res and not self._save_res:
            self.l.info(&#34;No result processing procedure will be taking place&#34;)

            def nop(*args, **kwargs):
                return

            self.process = nop
            self.kill_worker = nop
            return

        # INIT TRACK HISTORY
        if self._show_track_hist:

            class TrackHistory:
                &#34;&#34;&#34;Track History Wrapper
                - store the latest tracking results
                - assign each tracked ID its center positions (x, y)
                &#34;&#34;&#34;

                def __init__(self, max_hist_len: int):
                    self.tracks = []
                    self.ids = {}
                    self._max_hist_len = max_hist_len

                def update(self, tracks):
                    if len(self.tracks) &gt; self._max_hist_len:
                        self.tracks = []
                        self.ids = {}

                    self.tracks.append(tracks)
                    curr_ids = []
                    for *_, x, y, id, _ in tracks:
                        if id not in self.ids.keys():
                            self.ids.update({id: [(x, y)]})
                        else:
                            self.ids[id].append((x, y))
                        curr_ids.append(id)

            self.track_history = TrackHistory(max_hist_len=track_hist_size)

        # INIT SAVING
        if self._save_res:
            assert save_mode == &#34;video&#34; or save_mode == &#34;image&#34;
            from .general import increment_path
            from pathlib import Path

            self._mode = save_mode

            self._save_dir = increment_path(Path(path) / subdir, exist_ok, sep=&#34;_&#34;)
            self._save_dir.mkdir(parents=True, exist_ok=True)

            self.vid_path, self.vid_writer, self._fps = (
                None,
                None,
                kwargs[&#34;vid_fps&#34;] if &#34;vid_fps&#34; in kwargs.keys() else None,
            )

        # INIT ASYNC RESULT PROCESSING
        if self._async:
            import multiprocessing

            check_requirements([&#34;pathos&#34;])
            from pathos.helpers import mp

            assert (
                not self._show_res and self._async
            ), &#34;Results can&#39;t be visualized from slave process, disable &#39;VIEW_IMG&#39; or &#39;ASYNC_PROC&#39;!&#34;
            assert (
                multiprocessing.cpu_count() &gt; 1
            ), &#34;Only 1 CPU core available, might not be able to leverage multiprocessing module!&#34;

            self._queue_size = async_queue_size
            self._put_blocked = async_put_blocked
            self._put_timeout = async_put_timeout

            # Queue to put and pull results
            self.queue = mp.Queue(maxsize=self._queue_size)

            # init and start worker process
            self.l.info(&#34;Starting slave process to work on the results&#34;)
            self.worker_process = mp.Process(target=self.async_update_worker, args=())
            self.worker_process.start()

    def process(
        self,
        det: Type[torch.Tensor],
        tracks: Type[np.array],
        im0: Type[np.array],
        vid_cap: Type[cv2.VideoCapture] = None,
    ):
        &#34;&#34;&#34;
        Wraps the procedure for asynchronous and synchronous result processing.

        :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
        :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
        :param im0 (array): image in BGR (,3) [3, w, h]
        :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
        &#34;&#34;&#34;
        if self._async:
            assert self.worker_process.is_alive(), &#34;Worker process died!&#34;

            if round(self.queue.qsize() / self._queue_size, 1) == 0.9:
                self.l.warn(
                    &#34;Queue size capacity almost full.. &#34;
                    f&#34;({(self.queue.qsize()/self._queue_size) * 100:.2f})&#34;
                )

            if not self._put_blocked and self.queue.full():
                return

            # self.queue.put([det, tracks, im0, vid_cap])
            self.queue.put(
                [det, tracks, im0], block=self._put_blocked, timeout=self._put_timeout
            )
        else:
            # self.update(det, tracks, im0, vid_cap)
            self.update(det, tracks, im0)

    def update(
        self,
        det: Type[torch.Tensor],
        tracks: Type[np.array],
        im0: Type[np.array],
        vid_cap: Type[cv2.VideoCapture] = None,
    ):
        &#34;&#34;&#34;
        Takes the provided results from a detector and tracker in order to visualize
        them according to user config. Subsequently, visualizes and/or stores the
        enriched image/video.

        :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
        :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
        :param im0 (array): image in BGR (,3) [3, w, h]
        :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
        &#34;&#34;&#34;
        if self._show_det:
            im0 = self.draw_detec_boxes(det, im0)
        if self._show_tracks:
            im0 = self.draw_track_boxes(tracks, im0)
        if self._show_track_hist:
            im0 = self.draw_track_hist(tracks, im0)

        if self._show_res:
            self.visualize(im0)

        if self._save_res:
            if self._mode == &#34;image&#34;:
                self.save_img(im0)
            else:
                self.save_vid(im0)

    def async_update_worker(self):
        &#34;&#34;&#34;
        Main loop of the slave process
        &#34;&#34;&#34;
        assert self.queue, &#34;Queue is not initialized!&#34;
        import traceback

        try:
            while 1:
                try:
                    data = self.queue.get()
                except:
                    self.reset_vid_writer()
                    self.queue.close()
                    break

                # deserialize data, data: list, [detections, tracks, image, vid cap]
                # det, tracks, im0, vid_cap = data[0], data[1], data[2], data[3]
                det, tracks, im0 = data[0], data[1], data[2]

                self.update(det, tracks, im0)
        except:
            self.l.fatal(&#34;Exception in subprocess occured!&#34;)
            traceback.print_exc()

    def kill_worker(self):
        &#34;&#34;&#34;
        Procedure for cleanly closing the communication pipes and terminating
        the worker process.
        &#34;&#34;&#34;
        self.queue.close()
        self.worker_process.terminate()

    def draw_detec_boxes(self, det: Type[torch.Tensor], im0: Type[np.array]):
        &#34;&#34;&#34;
        Draws bounding boxes, class labels and confidences according to a
        detection matix on the provided image.

        :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
        :param im0 (ndarray): image in BGR [3, w, h]
        &#34;&#34;&#34;
        for *xyxy, conf, cls in reversed(det):
            # Add bbox to image
            c = int(cls)  # integer class
            label = (
                None
                if self._hide_labels
                else (
                    self._labels[c]
                    if self._hide_conf
                    else f&#34;{self._labels[c]} {conf:.2f}&#34;
                )
            )

            plot_one_box(
                xyxy,
                im0,
                label=label,
                color=colors(c, True),
                line_thickness=self._line_thickness,
            )
        return im0

    def draw_track_boxes(self, tracks: Type[np.array], im0: Type[np.array]):
        &#34;&#34;&#34;
        Draws bounding boxes, tracking ids according to &#39;tracks&#39; matix on the provided image.

        :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id, cls]
        :param im0 (array): image in BGR [3, px, px]
        &#34;&#34;&#34;
        for *xyxy, _, _, id, _ in tracks:
            id = None if self._hide_labels else str(id)
            plot_one_box(
                xyxy,
                im0,
                label=id,
                color=colors(int(id), True),
                line_thickness=self._line_thickness,
            )
        return im0

    def draw_track_hist(self, tracks: Type[np.array], im0: Type[np.array]):
        &#34;&#34;&#34;
        Draws a line for each tracked ID according to the stored history.

        :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id, cls]
        :param im0 (array): image in BGR [3, px, px]
        &#34;&#34;&#34;
        assert self.track_history, &#34;No track history object initialized!&#34;
        self.track_history.update(tracks)

        for id in self.track_history.ids:
            points = self.track_history.ids[id]
            x0, y0 = points[0]
            for x, y in points[1:]:
                cv2.line(im0, (x0, y0), (x, y), colors(id, True), self._line_thickness)
                x0, y0 = x, y
        return im0

    def save_img(self, im0: Type[np.array]):
        &#34;&#34;&#34;
        :param im0 (ndarray): image in BGR [3, px, px]
        &#34;&#34;&#34;
        now = datetime.now().strftime(&#34;%Y-%m-%d %H:%M:%S.%f&#34;)[:-3]

        # image named after current timestamp
        save_path = str(self._save_dir / now)
        save_path += &#34;.jpg&#34;

        cv2.imwrite(save_path, im0)

    def save_vid(self, im0: Type[np.array], vid_cap: Type[cv2.VideoCapture] = None):
        &#34;&#34;&#34;
        :param im0 (ndarray): image in BGR [3, px, px]
        :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
        &#34;&#34;&#34;
        # resize frame if its too large for .avi
        if im0.shape[1] &gt; 3200:
            im0 = resize_aspectratio(im0, width=3200)

        if not self.vid_path:  # new video
            now = datetime.now().strftime(&#34;%Y-%m-%d %H:%M:%S.%f&#34;)[:-3]
            self.vid_path = str(self._save_dir / now)

            if isinstance(self.vid_writer, cv2.VideoWriter):
                self.vid_writer.release()  # release previous video writer

            # take w, h from input video
            # if vid_cap:  # video
            #     fps = vid_cap.get(cv2.CAP_PROP_FPS)
            #     w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            #     h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
            # else:  # images, stream

            # take user defined fps
            fps, w, h = self._fps, im0.shape[1], im0.shape[0]
            self.vid_path += &#34;.avi&#34;

            self.vid_writer = cv2.VideoWriter(
                self.vid_path, cv2.VideoWriter_fourcc(*&#34;XVID&#34;), fps, (w, h)
            )

        self.vid_writer.write(im0)

    def visualize(self, im0: Type[np.array]):
        &#34;&#34;&#34;
        :param im0 (ndarray): image in BGR [3, px, px]
        &#34;&#34;&#34;
        cv2.namedWindow(&#34;Pancake&#34;, cv2.WINDOW_NORMAL)
        cv2.imshow(&#34;Pancake&#34;, im0)
        cv2.waitKey(0 if self._debug else 1)

    def reset_vid_writer(self):
        self.vid_writer.release()
        self.vid_path, self.vid_writer = None, None</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="pancake.utils.common.ResultProcessor.async_update_worker"><code class="name flex">
<span>def <span class="ident">async_update_worker</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Main loop of the slave process</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def async_update_worker(self):
    &#34;&#34;&#34;
    Main loop of the slave process
    &#34;&#34;&#34;
    assert self.queue, &#34;Queue is not initialized!&#34;
    import traceback

    try:
        while 1:
            try:
                data = self.queue.get()
            except:
                self.reset_vid_writer()
                self.queue.close()
                break

            # deserialize data, data: list, [detections, tracks, image, vid cap]
            # det, tracks, im0, vid_cap = data[0], data[1], data[2], data[3]
            det, tracks, im0 = data[0], data[1], data[2]

            self.update(det, tracks, im0)
    except:
        self.l.fatal(&#34;Exception in subprocess occured!&#34;)
        traceback.print_exc()</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.ResultProcessor.draw_detec_boxes"><code class="name flex">
<span>def <span class="ident">draw_detec_boxes</span></span>(<span>self, det: Type[torch.Tensor], im0: Type[<built-in function array>])</span>
</code></dt>
<dd>
<div class="desc"><p>Draws bounding boxes, class labels and confidences according to a
detection matix on the provided image.</p>
<p>:param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
:param im0 (ndarray): image in BGR [3, w, h]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def draw_detec_boxes(self, det: Type[torch.Tensor], im0: Type[np.array]):
    &#34;&#34;&#34;
    Draws bounding boxes, class labels and confidences according to a
    detection matix on the provided image.

    :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
    :param im0 (ndarray): image in BGR [3, w, h]
    &#34;&#34;&#34;
    for *xyxy, conf, cls in reversed(det):
        # Add bbox to image
        c = int(cls)  # integer class
        label = (
            None
            if self._hide_labels
            else (
                self._labels[c]
                if self._hide_conf
                else f&#34;{self._labels[c]} {conf:.2f}&#34;
            )
        )

        plot_one_box(
            xyxy,
            im0,
            label=label,
            color=colors(c, True),
            line_thickness=self._line_thickness,
        )
    return im0</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.ResultProcessor.draw_track_boxes"><code class="name flex">
<span>def <span class="ident">draw_track_boxes</span></span>(<span>self, tracks: Type[<built-in function array>], im0: Type[<built-in function array>])</span>
</code></dt>
<dd>
<div class="desc"><p>Draws bounding boxes, tracking ids according to 'tracks' matix on the provided image.</p>
<p>:param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id, cls]
:param im0 (array): image in BGR [3, px, px]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def draw_track_boxes(self, tracks: Type[np.array], im0: Type[np.array]):
    &#34;&#34;&#34;
    Draws bounding boxes, tracking ids according to &#39;tracks&#39; matix on the provided image.

    :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id, cls]
    :param im0 (array): image in BGR [3, px, px]
    &#34;&#34;&#34;
    for *xyxy, _, _, id, _ in tracks:
        id = None if self._hide_labels else str(id)
        plot_one_box(
            xyxy,
            im0,
            label=id,
            color=colors(int(id), True),
            line_thickness=self._line_thickness,
        )
    return im0</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.ResultProcessor.draw_track_hist"><code class="name flex">
<span>def <span class="ident">draw_track_hist</span></span>(<span>self, tracks: Type[<built-in function array>], im0: Type[<built-in function array>])</span>
</code></dt>
<dd>
<div class="desc"><p>Draws a line for each tracked ID according to the stored history.</p>
<p>:param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id, cls]
:param im0 (array): image in BGR [3, px, px]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def draw_track_hist(self, tracks: Type[np.array], im0: Type[np.array]):
    &#34;&#34;&#34;
    Draws a line for each tracked ID according to the stored history.

    :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id, cls]
    :param im0 (array): image in BGR [3, px, px]
    &#34;&#34;&#34;
    assert self.track_history, &#34;No track history object initialized!&#34;
    self.track_history.update(tracks)

    for id in self.track_history.ids:
        points = self.track_history.ids[id]
        x0, y0 = points[0]
        for x, y in points[1:]:
            cv2.line(im0, (x0, y0), (x, y), colors(id, True), self._line_thickness)
            x0, y0 = x, y
    return im0</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.ResultProcessor.kill_worker"><code class="name flex">
<span>def <span class="ident">kill_worker</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"><p>Procedure for cleanly closing the communication pipes and terminating
the worker process.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def kill_worker(self):
    &#34;&#34;&#34;
    Procedure for cleanly closing the communication pipes and terminating
    the worker process.
    &#34;&#34;&#34;
    self.queue.close()
    self.worker_process.terminate()</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.ResultProcessor.process"><code class="name flex">
<span>def <span class="ident">process</span></span>(<span>self, det: Type[torch.Tensor], tracks: Type[<built-in function array>], im0: Type[<built-in function array>], vid_cap: Type[cv2.VideoCapture] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Wraps the procedure for asynchronous and synchronous result processing.</p>
<p>:param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
:param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
:param im0 (array): image in BGR (,3) [3, w, h]
:param vid_cap (cv2.VideoCapture): cv2.VideoCapture object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def process(
    self,
    det: Type[torch.Tensor],
    tracks: Type[np.array],
    im0: Type[np.array],
    vid_cap: Type[cv2.VideoCapture] = None,
):
    &#34;&#34;&#34;
    Wraps the procedure for asynchronous and synchronous result processing.

    :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
    :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
    :param im0 (array): image in BGR (,3) [3, w, h]
    :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
    &#34;&#34;&#34;
    if self._async:
        assert self.worker_process.is_alive(), &#34;Worker process died!&#34;

        if round(self.queue.qsize() / self._queue_size, 1) == 0.9:
            self.l.warn(
                &#34;Queue size capacity almost full.. &#34;
                f&#34;({(self.queue.qsize()/self._queue_size) * 100:.2f})&#34;
            )

        if not self._put_blocked and self.queue.full():
            return

        # self.queue.put([det, tracks, im0, vid_cap])
        self.queue.put(
            [det, tracks, im0], block=self._put_blocked, timeout=self._put_timeout
        )
    else:
        # self.update(det, tracks, im0, vid_cap)
        self.update(det, tracks, im0)</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.ResultProcessor.reset_vid_writer"><code class="name flex">
<span>def <span class="ident">reset_vid_writer</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def reset_vid_writer(self):
    self.vid_writer.release()
    self.vid_path, self.vid_writer = None, None</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.ResultProcessor.save_img"><code class="name flex">
<span>def <span class="ident">save_img</span></span>(<span>self, im0: Type[<built-in function array>])</span>
</code></dt>
<dd>
<div class="desc"><p>:param im0 (ndarray): image in BGR [3, px, px]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_img(self, im0: Type[np.array]):
    &#34;&#34;&#34;
    :param im0 (ndarray): image in BGR [3, px, px]
    &#34;&#34;&#34;
    now = datetime.now().strftime(&#34;%Y-%m-%d %H:%M:%S.%f&#34;)[:-3]

    # image named after current timestamp
    save_path = str(self._save_dir / now)
    save_path += &#34;.jpg&#34;

    cv2.imwrite(save_path, im0)</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.ResultProcessor.save_vid"><code class="name flex">
<span>def <span class="ident">save_vid</span></span>(<span>self, im0: Type[<built-in function array>], vid_cap: Type[cv2.VideoCapture] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>:param im0 (ndarray): image in BGR [3, px, px]
:param vid_cap (cv2.VideoCapture): cv2.VideoCapture object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def save_vid(self, im0: Type[np.array], vid_cap: Type[cv2.VideoCapture] = None):
    &#34;&#34;&#34;
    :param im0 (ndarray): image in BGR [3, px, px]
    :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
    &#34;&#34;&#34;
    # resize frame if its too large for .avi
    if im0.shape[1] &gt; 3200:
        im0 = resize_aspectratio(im0, width=3200)

    if not self.vid_path:  # new video
        now = datetime.now().strftime(&#34;%Y-%m-%d %H:%M:%S.%f&#34;)[:-3]
        self.vid_path = str(self._save_dir / now)

        if isinstance(self.vid_writer, cv2.VideoWriter):
            self.vid_writer.release()  # release previous video writer

        # take w, h from input video
        # if vid_cap:  # video
        #     fps = vid_cap.get(cv2.CAP_PROP_FPS)
        #     w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        #     h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        # else:  # images, stream

        # take user defined fps
        fps, w, h = self._fps, im0.shape[1], im0.shape[0]
        self.vid_path += &#34;.avi&#34;

        self.vid_writer = cv2.VideoWriter(
            self.vid_path, cv2.VideoWriter_fourcc(*&#34;XVID&#34;), fps, (w, h)
        )

    self.vid_writer.write(im0)</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.ResultProcessor.update"><code class="name flex">
<span>def <span class="ident">update</span></span>(<span>self, det: Type[torch.Tensor], tracks: Type[<built-in function array>], im0: Type[<built-in function array>], vid_cap: Type[cv2.VideoCapture] = None)</span>
</code></dt>
<dd>
<div class="desc"><p>Takes the provided results from a detector and tracker in order to visualize
them according to user config. Subsequently, visualizes and/or stores the
enriched image/video.</p>
<p>:param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
:param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
:param im0 (array): image in BGR (,3) [3, w, h]
:param vid_cap (cv2.VideoCapture): cv2.VideoCapture object</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def update(
    self,
    det: Type[torch.Tensor],
    tracks: Type[np.array],
    im0: Type[np.array],
    vid_cap: Type[cv2.VideoCapture] = None,
):
    &#34;&#34;&#34;
    Takes the provided results from a detector and tracker in order to visualize
    them according to user config. Subsequently, visualizes and/or stores the
    enriched image/video.

    :param det (tensor): detections on (,6) tensor [xyxy, conf, cls]
    :param tracks (np.ndarray): track ids on (,7) array [xyxy, center x, center y, id]
    :param im0 (array): image in BGR (,3) [3, w, h]
    :param vid_cap (cv2.VideoCapture): cv2.VideoCapture object
    &#34;&#34;&#34;
    if self._show_det:
        im0 = self.draw_detec_boxes(det, im0)
    if self._show_tracks:
        im0 = self.draw_track_boxes(tracks, im0)
    if self._show_track_hist:
        im0 = self.draw_track_hist(tracks, im0)

    if self._show_res:
        self.visualize(im0)

    if self._save_res:
        if self._mode == &#34;image&#34;:
            self.save_img(im0)
        else:
            self.save_vid(im0)</code></pre>
</details>
</dd>
<dt id="pancake.utils.common.ResultProcessor.visualize"><code class="name flex">
<span>def <span class="ident">visualize</span></span>(<span>self, im0: Type[<built-in function array>])</span>
</code></dt>
<dd>
<div class="desc"><p>:param im0 (ndarray): image in BGR [3, px, px]</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def visualize(self, im0: Type[np.array]):
    &#34;&#34;&#34;
    :param im0 (ndarray): image in BGR [3, px, px]
    &#34;&#34;&#34;
    cv2.namedWindow(&#34;Pancake&#34;, cv2.WINDOW_NORMAL)
    cv2.imshow(&#34;Pancake&#34;, im0)
    cv2.waitKey(0 if self._debug else 1)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="pancake.utils" href="index.html">pancake.utils</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="pancake.utils.common.draw_boxes" href="#pancake.utils.common.draw_boxes">draw_boxes</a></code></li>
<li><code><a title="pancake.utils.common.fix_path" href="#pancake.utils.common.fix_path">fix_path</a></code></li>
<li><code><a title="pancake.utils.common.load_data" href="#pancake.utils.common.load_data">load_data</a></code></li>
<li><code><a title="pancake.utils.common.save" href="#pancake.utils.common.save">save</a></code></li>
<li><code><a title="pancake.utils.common.setup_result_processor" href="#pancake.utils.common.setup_result_processor">setup_result_processor</a></code></li>
<li><code><a title="pancake.utils.common.visualize" href="#pancake.utils.common.visualize">visualize</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="pancake.utils.common.ResultProcessor" href="#pancake.utils.common.ResultProcessor">ResultProcessor</a></code></h4>
<ul class="two-column">
<li><code><a title="pancake.utils.common.ResultProcessor.async_update_worker" href="#pancake.utils.common.ResultProcessor.async_update_worker">async_update_worker</a></code></li>
<li><code><a title="pancake.utils.common.ResultProcessor.draw_detec_boxes" href="#pancake.utils.common.ResultProcessor.draw_detec_boxes">draw_detec_boxes</a></code></li>
<li><code><a title="pancake.utils.common.ResultProcessor.draw_track_boxes" href="#pancake.utils.common.ResultProcessor.draw_track_boxes">draw_track_boxes</a></code></li>
<li><code><a title="pancake.utils.common.ResultProcessor.draw_track_hist" href="#pancake.utils.common.ResultProcessor.draw_track_hist">draw_track_hist</a></code></li>
<li><code><a title="pancake.utils.common.ResultProcessor.kill_worker" href="#pancake.utils.common.ResultProcessor.kill_worker">kill_worker</a></code></li>
<li><code><a title="pancake.utils.common.ResultProcessor.process" href="#pancake.utils.common.ResultProcessor.process">process</a></code></li>
<li><code><a title="pancake.utils.common.ResultProcessor.reset_vid_writer" href="#pancake.utils.common.ResultProcessor.reset_vid_writer">reset_vid_writer</a></code></li>
<li><code><a title="pancake.utils.common.ResultProcessor.save_img" href="#pancake.utils.common.ResultProcessor.save_img">save_img</a></code></li>
<li><code><a title="pancake.utils.common.ResultProcessor.save_vid" href="#pancake.utils.common.ResultProcessor.save_vid">save_vid</a></code></li>
<li><code><a title="pancake.utils.common.ResultProcessor.update" href="#pancake.utils.common.ResultProcessor.update">update</a></code></li>
<li><code><a title="pancake.utils.common.ResultProcessor.visualize" href="#pancake.utils.common.ResultProcessor.visualize">visualize</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>